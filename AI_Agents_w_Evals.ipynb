{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjleece/AI-Agents/blob/main/AI_Agents_w_Evals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install anthropic\n",
        "#%pip install openai\n",
        "%pip install -q -U google-generativeai\n",
        "%pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDKcVFI7PAJ5",
        "outputId": "34e2b643-ef01-4a67-be10-92a3e6eb56bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.51.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.0)\n",
            "Downloading anthropic-0.51.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.51.0\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup and Imports\n",
        "import anthropic\n",
        "import google.generativeai as gemini\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import glob # For finding files matching a pattern\n",
        "import uuid # For generating unique learning IDs in RAG\n",
        "from google.colab import userdata\n",
        "#from openai import OpenAI\n",
        "from google.colab import drive # For Google Drive mounting\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional, Union, Tuple\n",
        "from fuzzywuzzy import process, fuzz\n",
        "\n",
        "# LLM API Keys\n",
        "ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "#OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "#openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "gemini.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "ANTHROPIC_MODEL_NAME = \"claude-3-5-sonnet-latest\"\n",
        "#OPENAI_MODEL_NAME = \"gpt-4.1\" # Or your preferred GPT-4 class model\n",
        "EVAL_MODEL_NAME = \"gemini-2.5-pro-preview-05-06\" # Or your preferred Gemini model\n",
        "\n",
        "\n",
        "DRIVE_MOUNT_PATH = '/content/drive'\n",
        "\n",
        "try:\n",
        "    drive.mount(DRIVE_MOUNT_PATH)\n",
        "    print(f\"Google Drive mounted successfully at {DRIVE_MOUNT_PATH}.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}. RAG features will not work.\")\n",
        "\n",
        "# Set up the default learnings path\n",
        "DEFAULT_LEARNINGS_DRIVE_SUBPATH = \"My Drive/AI/Knowledgebases\"  # Your default path\n",
        "LEARNINGS_DRIVE_BASE_PATH = os.path.join(DRIVE_MOUNT_PATH, DEFAULT_LEARNINGS_DRIVE_SUBPATH)\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(LEARNINGS_DRIVE_BASE_PATH):\n",
        "    try:\n",
        "        os.makedirs(LEARNINGS_DRIVE_BASE_PATH)\n",
        "        print(f\"Created learnings directory: {LEARNINGS_DRIVE_BASE_PATH}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating learnings directory {LEARNINGS_DRIVE_BASE_PATH}: {e}\")\n",
        "else:\n",
        "    print(f\"Using existing learnings directory: {LEARNINGS_DRIVE_BASE_PATH}\")\n",
        "\n",
        "print(\"Imports and LLM clients initialized. Drive RAG configuration variables set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoQ4L2N6o339",
        "outputId": "a73e40b0-6af6-4ff1-82e6-af826f3dd515"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully at /content/drive.\n",
            "Using existing learnings directory: /content/drive/My Drive/AI/Knowledgebases\n",
            "Imports and LLM clients initialized. Drive RAG configuration variables set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODIFIED System Prompts\n",
        "worker_system_prompt = \"\"\"\n",
        "You are a helpful customer service assistant for an e-commerce system.\n",
        "\n",
        "Your overriding goal is to be helpful by answering questions and performing actions as requested by a human user.\n",
        "\n",
        "When responding to the user, use the conversation context to maintain continuity.\n",
        "- If a user refers to \"my order\" or similar, use the context to determine which order they're talking about.\n",
        "- If they mention \"that product\" or use other references, check the context to determine what they're referring to.\n",
        "- Always prioritize recent context over older context when resolving references.\n",
        "\n",
        "The conversation context will be provided to you with each message. This includes:\n",
        "- Previous questions and answers\n",
        "- Recently viewed customers, products, and orders\n",
        "- Recent actions taken (like creating orders, updating products, etc.)\n",
        "- Relevant Learnings from a knowledge base.\n",
        "\n",
        "REQUESTING CLARIFICATION FROM THE USER:\n",
        "If you determine that you absolutely need more information from the user to accurately and efficiently fulfill their request or use a tool correctly, you MUST:\n",
        "1. Formulate a clear, concise question for the user.\n",
        "2. Prefix your entire response with the exact tag: `CLARIFICATION_REQUESTED:`\n",
        "   Example: `CLARIFICATION_REQUESTED: To update the order, could you please provide the Order ID?`\n",
        "3. Do NOT use any tools in the same turn you are requesting clarification. Wait for the user's response.\n",
        "\n",
        "Keep all other responses friendly, concise, and helpful.\n",
        "\"\"\"\n",
        "\n",
        "evaluator_system_prompt = \"\"\"\n",
        "You are Google Gemini, an impartial evaluator assessing the quality of responses from an AI assistant to customer service queries.\n",
        "\n",
        "You will be provided with:\n",
        "\n",
        "- The user's query.\n",
        "- The conversation context (including RAG learnings) that was available to the AI assistant.\n",
        "- The AI assistant's final response.\n",
        "- **A snapshot of the 'Data Store State *Before* AI Action' (customers, products, orders). This represents the state of the world when the AI assistant decided on its actions.**\n",
        "- **A snapshot of the 'Data Store State *After* AI Action' (customers, products, orders). This represents the state after the AI assistant's actions were executed (e.g., after tool calls).**\n",
        "- Details of any clarification questions the AI assistant asked the user.\n",
        "\n",
        "For each interaction, evaluate the assistant's response based on:\n",
        "1.  **Accuracy**:\n",
        "    * How correct and factual is the AI's textual response?\n",
        "    * Did the AI's actions (tool calls) correctly modify the datastore as intended and as claimed in its response?\n",
        "    * Verify factual claims (prices, inventory, statuses, IDs) by comparing the AI's response and its actions against the 'Data Store State *Before* AI Action' (for what it should have known) and the 'Data Store State *After* AI Action' (for what actually happened).\n",
        "    * Specifically check if any new entities (orders, customers, products) were created with correct IDs and if existing entities were updated correctly. Note any discrepancies in IDs or values.\n",
        "\n",
        "2.  **Efficiency**:\n",
        "    * Did the assistant get to the correct answer and perform the correct actions with minimal clarifying questions?\n",
        "    * Consider if any questions asked were necessary by checking if the information was available in the 'Data Store State *Before* AI Action', the conversation context, or RAG learnings.\n",
        "    * Were tool calls used appropriately, or could the AI have inferred information without a tool call?\n",
        "\n",
        "3.  **Context Awareness**:\n",
        "    * Did the assistant correctly use the conversation context (history, entities, RAG learnings) to understand references and intent?\n",
        "\n",
        "4.  **Helpfulness**:\n",
        "    * How well did the assistant address the user's needs, both in its textual response and through its actions?\n",
        "    * Was the response clear, and did it provide all relevant information related to the outcome of the user's request?\n",
        "\n",
        "Score the response on a scale of 1-10 for each criterion, and provide an overall score. Provide detailed reasoning for your scores, explicitly referencing the 'Before' and 'After' data store states when discussing accuracy of actions and information.\n",
        "\n",
        "EVALUATING CLARIFICATION QUESTIONS ASKED BY THE WORKER AI:\n",
        "If the worker AI asked for clarification from the user:\n",
        "- Assess the *necessity* of the question using the 'Data Store State *Before* AI Action' and context.\n",
        "- Assess the *quality* of the question.\n",
        "- If the question was necessary and well-phrased, it should NOT negatively impact the Efficiency score.\n",
        "- If the question was unnecessary, this SHOULD negatively impact the Efficiency score.\n",
        "\n",
        "If you, the evaluator, still have questions *after* reviewing all provided information, you can ask the human admin for clarification using \"CLARIFICATION NEEDED_EVALUATOR:\".\n",
        "\n",
        "DATA STORE CONSISTENCY CHECK (as part of overall evaluation):\n",
        "Your main evaluation should inherently perform a consistency check. When assessing Accuracy, explicitly compare the AI's stated actions and its textual response with the changes (or lack thereof) between the 'Data Store State *Before* AI Action' and the 'Data Store State *After* AI Action'.\n",
        "- Does the 'Data Store State *After* AI Action' accurately reflect the outcomes of any tool calls the AI Assistant made (or should have made based on its response)?\n",
        "- Are there any inconsistencies between the agent's textual response and the 'Data Store State *After* AI Action'?\n",
        "- Clearly state if your review of the 'Before' and 'After' states causes you to adjust scores, and explain why.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "zMWjRsv3QNc1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize stuff to prevent possible caching issues\n",
        "\n",
        "human_feedback_learnings = {}\n",
        "tools_schemas_list = []"
      ],
      "metadata": {
        "id": "YgO9bnabVWZC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gemini models have different structure than Anthropic and need to be called this way before use to enable generate_content(prompt),\n",
        "#whereas Anthropic allows model definition + system instructions within messages.create(prompt)\n",
        "\n",
        "eval_model_instance = gemini.GenerativeModel(\n",
        "    model_name=EVAL_MODEL_NAME,\n",
        "    system_instruction=evaluator_system_prompt\n",
        ")\n",
        "print(\"Gemini Evaluator model instance initialized.\")\n",
        "\n",
        "#this instance of Gemini is to get \"ground truth\" answers by running queries in parallel with Anthropic. The evaluator instance then evaluates the \"ground truth\" against Anthropic's response.\n",
        "gemini_actor_model_instance = gemini.GenerativeModel(\n",
        "    model_name=EVAL_MODEL_NAME, # Using the same underlying model\n",
        "    system_instruction=worker_system_prompt # But with the worker's system prompt\n",
        ")\n",
        "print(\"Gemini Actor model instance initialized.\")"
      ],
      "metadata": {
        "id": "lHWwoW0JQRS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483b33fe-9be6-4f85-eb22-8763fad1105b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Evaluator model instance initialized.\n",
            "Gemini Actor model instance initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Data Stores (Initial data - will be managed by the Storage class instance)\n",
        "# These are initial values. The Storage class will manage them.\n",
        "initial_customers = {\n",
        "    \"C1\": {\"name\": \"John Doe\", \"email\": \"john@example.com\", \"phone\": \"123-456-7890\"},\n",
        "    \"C2\": {\"name\": \"Jane Smith\", \"email\": \"jane@example.com\", \"phone\": \"987-654-3210\"}\n",
        "}\n",
        "\n",
        "initial_products = {\n",
        "    \"P1\": {\"name\": \"Widget A\", \"description\": \"A simple widget. Very compact.\", \"price\": 19.99, \"inventory_count\": 999},\n",
        "    \"P2\": {\"name\": \"Gadget B\", \"description\": \"A powerful gadget. It spins.\", \"price\": 49.99, \"inventory_count\": 200},\n",
        "    \"P3\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1483}\n",
        "}\n",
        "\n",
        "initial_orders = {\n",
        "    \"O1\": {\"id\": \"O1\", \"product_id\": \"P1\", \"product_name\": \"Widget A\", \"quantity\": 2, \"price\": 19.99, \"status\": \"Shipped\"},\n",
        "    \"O2\": {\"id\": \"O2\", \"product_id\": \"P2\", \"product_name\": \"Gadget B\", \"quantity\": 1, \"price\": 49.99, \"status\": \"Processing\"}\n",
        "}\n"
      ],
      "metadata": {
        "id": "5G9rP40vQXdU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standalone Anthropic Completion Function (for basic tests)\n",
        "def get_completion_anthropic_standalone(prompt: str):\n",
        "    message = anthropic_client.messages.create(\n",
        "        model=ANTHROPIC_MODEL_NAME,\n",
        "        max_tokens=2000,\n",
        "        temperature=0.0,\n",
        "        system=worker_system_prompt,\n",
        "        tools=tools_schemas_list,\n",
        "        messages=[\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return message.content[0].text"
      ],
      "metadata": {
        "id": "_ADM0bBpQlVK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_test_anthropic = \"Hey there, which AI model do you use for answering questions?\"\n",
        "print(f\"Anthropic Standalone Test: {get_completion_anthropic_standalone(prompt_test_anthropic)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPOq1s0SQqk_",
        "outputId": "f0f9fafc-4772-4667-fb76-fab8a48ae86a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anthropic Standalone Test: I am a customer service assistant designed to help with e-commerce related questions and tasks. I aim to be helpful by answering questions and performing actions related to orders, products, customers, and other e-commerce functions. I don't actually have information about which specific AI model I use - I focus on helping users with their e-commerce needs.\n",
            "\n",
            "Is there something specific about your orders, products, or other e-commerce matters that I can help you with today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def get_completion_openai_standalone(prompt: str):\n",
        "#    response = openai_client.chat.completions.create(\n",
        "#        model=OPENAI_MODEL_NAME,\n",
        "#        max_tokens=2000,\n",
        "#        temperature=0.0,\n",
        "#        tools=tools_schemas_list,\n",
        "#        messages=[\n",
        "#            {\"role\": \"system\", \"content\": worker_system_prompt},\n",
        "#            {\"role\": \"user\", \"content\": prompt}\n",
        "#        ]\n",
        "#    )\n",
        "#    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Y5c_bv3qQwWV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt_test_openai = \"Hey there, which AI model do you use for answering questions?\"\n",
        "#print(f\"OpenAI Standalone Test: {get_completion_openai_standalone(prompt_test_openai)}\")"
      ],
      "metadata": {
        "id": "b_LaDQ74Q1Lp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_eval_standalone(prompt: str):\n",
        "    # Uses the eval_model_instance which has the system prompt\n",
        "        response = eval_model_instance.generate_content(prompt)\n",
        "        return response.text"
      ],
      "metadata": {
        "id": "XjcV5GcaQ6aT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_test_eval = \"Hey there, can you tell me which AI you are and what your key tasks are?\"\n",
        "print(f\"Gemini Eval Standalone Test:\\n{get_completion_eval_standalone(prompt_test_eval)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "Cu8doX53RE0Z",
        "outputId": "dbaf163f-8094-41ac-ebdb-1d1825021906"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Eval Standalone Test:\n",
            "Okay, I can help with that!\n",
            "\n",
            "I am a friendly AI assistant here to help with your customer service needs. My key tasks include:\n",
            "*   Answering questions about our products and services.\n",
            "*   Helping you place new orders.\n",
            "*   Checking the status of your existing orders.\n",
            "*   Processing returns and exchanges.\n",
            "*   Updating your account information.\n",
            "\n",
            "Is there anything specific I can help you with today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storage Class\n",
        "class Storage:\n",
        "    def __init__(self):\n",
        "        self.customers = copy.deepcopy(initial_customers)\n",
        "        self.products = copy.deepcopy(initial_products)\n",
        "        self.orders = copy.deepcopy(initial_orders)\n",
        "        self.human_feedback_learnings = human_feedback_learnings\n",
        "\n",
        "    def get_full_datastore_copy(self) -> Dict[str, Any]:\n",
        "        \"\"\"Returns a deep copy of the current datastore.\"\"\"\n",
        "        return {\n",
        "            \"customers\": copy.deepcopy(self.customers),\n",
        "            \"products\": copy.deepcopy(self.products),\n",
        "            \"orders\": copy.deepcopy(self.orders)\n",
        "        }\n",
        "\n",
        "print(\"Storage class defined with deepcopy for initial data and get_full_datastore_copy method.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpVJLbF6ROgf",
        "outputId": "985ef9c6-cbfa-4e1d-87e0-05d6b7297f91"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Storage class defined with deepcopy for initial data and get_full_datastore_copy method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definitive list of tool schemas.\n",
        "tools_schemas_list = [\n",
        "    {\n",
        "        \"name\": \"create_customer\",\n",
        "        \"description\": \"Adds a new customer to the database. Includes customer name, email, and (optional) phone number.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The name of the customer.\"},\n",
        "                \"email\": {\"type\": \"string\", \"description\": \"The email address of the customer.\"},\n",
        "                \"phone\": {\"type\": \"string\", \"description\": \"The phone number of the customer (optional).\"}\n",
        "            },\n",
        "            \"required\": [\"name\", \"email\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_customer_info\",\n",
        "        \"description\": \"Retrieves customer information based on their customer ID. Returns the customer's name, email, and (optional) phone number.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"customer_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the customer.\"}\n",
        "            },\n",
        "            \"required\": [\"customer_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"create_product\",\n",
        "        \"description\": \"Adds a new product to the product database. Includes name, description, price, and initial inventory count.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The name of the product.\"},\n",
        "                \"description\": {\"type\": \"string\", \"description\": \"A description of the product.\"},\n",
        "                \"price\": {\"type\": \"number\", \"description\": \"The price of the product.\"},\n",
        "                \"inventory_count\": {\"type\": \"integer\", \"description\": \"The amount of the product that is currently in inventory.\"}\n",
        "            },\n",
        "            \"required\": [\"name\", \"description\", \"price\", \"inventory_count\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"update_product\",\n",
        "        \"description\": \"Updates an existing product with new information. Only fields that are provided will be updated; other fields remain unchanged.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the product to update.\"},\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The new name for the product (optional).\"},\n",
        "                \"description\": {\"type\": \"string\", \"description\": \"The new description for the product (optional).\"},\n",
        "                \"price\": {\"type\": \"number\", \"description\": \"The new price for the product (optional).\"},\n",
        "                \"inventory_count\": {\"type\": \"integer\", \"description\": \"The new inventory count for the product (optional).\"}\n",
        "            },\n",
        "            \"required\": [\"product_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_product_info\",\n",
        "        \"description\": \"Retrieves product information based on product ID or product name (with fuzzy matching for misspellings). Returns product details including name, description, price, and inventory count.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id_or_name\": {\"type\": \"string\", \"description\": \"The product ID or name (can be approximate).\"}\n",
        "            },\n",
        "            \"required\": [\"product_id_or_name\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"list_all_products\",\n",
        "        \"description\": \"Lists all available products in the inventory.\",\n",
        "        \"input_schema\": { \"type\": \"object\", \"properties\": {}, \"required\": [] }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"create_order\",\n",
        "        \"description\": \"Creates an order using the product's current price. If requested quantity exceeds available inventory, no order is created and available quantity is returned. Orders can only be created for products that are in stock. Supports specifying products by either ID or name with fuzzy matching for misspellings.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id_or_name\": {\"type\": \"string\", \"description\": \"The ID or name of the product to order (supports fuzzy matching).\"},\n",
        "                \"quantity\": {\"type\": \"integer\", \"description\": \"The quantity of the product in the order.\"},\n",
        "                \"status\": {\"type\": \"string\", \"description\": \"The initial status of the order (e.g., 'Processing', 'Shipped').\"}\n",
        "            },\n",
        "            \"required\": [\"product_id_or_name\", \"quantity\", \"status\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_order_details\",\n",
        "        \"description\": \"Retrieves the details of a specific order based on the order ID. Returns the order ID, product name, quantity, price, and order status.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the order.\"}\n",
        "            },\n",
        "            \"required\": [\"order_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"update_order_status\",\n",
        "        \"description\": \"Updates the status of an order and adjusts inventory accordingly. Changing to \\\"Shipped\\\" decreases inventory. Changing to \\\"Returned\\\" or \\\"Canceled\\\" from \\\"Shipped\\\" increases inventory. Status can be \\\"Processing\\\", \\\"Shipped\\\", \\\"Delivered\\\", \\\"Returned\\\", or \\\"Canceled\\\".\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the order.\"},\n",
        "                \"new_status\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The new status to set for the order.\",\n",
        "                    \"enum\": [\"Processing\", \"Shipped\", \"Delivered\", \"Returned\", \"Canceled\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"order_id\", \"new_status\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "print(f\"Defined {len(tools_schemas_list)} tool schemas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgk-hLUBRTCY",
        "outputId": "a9b4d50c-6aca-4272-8a1f-6511c688964d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined 9 tool schemas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool Function Definitions\n",
        "# These tool functions now accept a 'current_storage' argument to operate on a specific Storage instance.\n",
        "\n",
        "# Customer functions\n",
        "def create_customer(current_storage: Storage, name: str, email: str, phone: Optional[str] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Creates a new customer and adds them to the customer database.\"\"\"\n",
        "    new_id = f\"C{len(current_storage.customers) + 1}\"\n",
        "    current_storage.customers[new_id] = {\"name\": name, \"email\": email, \"phone\": phone}\n",
        "    print(f\"[Tool Executed] create_customer: ID {new_id}, Name: {name} (in {type(current_storage).__name__})\")\n",
        "    return {\"status\": \"success\", \"customer_id\": new_id, \"customer\": current_storage.customers[new_id]}\n",
        "\n",
        "def get_customer_info(current_storage: Storage, customer_id: str) -> Dict[str, Any]:\n",
        "    \"\"\"Retrieves information about a customer based on their ID.\"\"\"\n",
        "    customer = current_storage.customers.get(customer_id)\n",
        "    if customer:\n",
        "        print(f\"[Tool Executed] get_customer_info: ID {customer_id} found (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"success\", \"customer_id\": customer_id, \"customer\": customer}\n",
        "    print(f\"[Tool Executed] get_customer_info: ID {customer_id} not found (in {type(current_storage).__name__}).\")\n",
        "    return {\"status\": \"error\", \"message\": \"Customer not found\"}\n",
        "\n",
        "# Product functions\n",
        "def create_product(current_storage: Storage, name: str, description: str, price: float, inventory_count: int) -> Dict[str, Any]:\n",
        "    \"\"\"Creates a new product and adds it to the product database.\"\"\"\n",
        "    new_id = f\"P{len(current_storage.products) + 1}\"\n",
        "    current_storage.products[new_id] = {\n",
        "        \"name\": name,\n",
        "        \"description\": description,\n",
        "        \"price\": float(price),\n",
        "        \"inventory_count\": int(inventory_count)\n",
        "    }\n",
        "    print(f\"[Tool Executed] create_product: ID {new_id}, Name: {name} (in {type(current_storage).__name__})\")\n",
        "    return {\"status\": \"success\", \"product_id\": new_id, \"product\": current_storage.products[new_id]}\n",
        "\n",
        "def update_product(current_storage: Storage, product_id: str, name: Optional[str] = None, description: Optional[str] = None,\n",
        "                   price: Optional[float] = None, inventory_count: Optional[int] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Updates a product with the provided parameters.\"\"\"\n",
        "    if product_id not in current_storage.products:\n",
        "        print(f\"[Tool Executed] update_product: ID {product_id} not found (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"error\", \"message\": f\"Product {product_id} not found\"}\n",
        "\n",
        "    product = current_storage.products[product_id]\n",
        "    updated_fields = []\n",
        "\n",
        "    if name is not None:\n",
        "        product[\"name\"] = name\n",
        "        updated_fields.append(\"name\")\n",
        "    if description is not None:\n",
        "        product[\"description\"] = description\n",
        "        updated_fields.append(\"description\")\n",
        "    if price is not None:\n",
        "        product[\"price\"] = float(price)\n",
        "        updated_fields.append(\"price\")\n",
        "    if inventory_count is not None:\n",
        "        product[\"inventory_count\"] = int(inventory_count)\n",
        "        updated_fields.append(\"inventory_count\")\n",
        "\n",
        "    if not updated_fields:\n",
        "        print(f\"[Tool Executed] update_product: ID {product_id}, no fields updated (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"warning\", \"message\": \"No fields were updated.\", \"product\": product}\n",
        "\n",
        "    print(f\"[Tool Executed] update_product: ID {product_id}, Updated fields: {', '.join(updated_fields)} (in {type(current_storage).__name__})\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"message\": f\"Product {product_id} updated. Fields: {', '.join(updated_fields)}\",\n",
        "        \"product_id\": product_id,\n",
        "        \"updated_fields\": updated_fields,\n",
        "        \"product\": product\n",
        "    }\n",
        "\n",
        "def find_product_by_name(current_storage: Storage, product_name: str, min_similarity: int = 70) -> Tuple[Optional[str], Optional[Dict[str, Any]]]:\n",
        "    \"\"\"Find a product by name using fuzzy string matching.\"\"\"\n",
        "    if not product_name: return None, None\n",
        "\n",
        "    name_id_list = [(p_data[\"name\"], p_id) for p_id, p_data in current_storage.products.items()]\n",
        "    if not name_id_list: return None, None\n",
        "\n",
        "    best_match_name_score = process.extractOne(\n",
        "        product_name,\n",
        "        [item[0] for item in name_id_list],\n",
        "        scorer=fuzz.token_sort_ratio\n",
        "    )\n",
        "\n",
        "    if best_match_name_score and best_match_name_score[1] >= min_similarity:\n",
        "        matched_name = best_match_name_score[0]\n",
        "        for name, pid_val in name_id_list:\n",
        "            if name == matched_name:\n",
        "                print(f\"[Tool Helper] find_product_by_name: Matched '{product_name}' to '{matched_name}' (ID: {pid_val}) with score {best_match_name_score[1]} (in {type(current_storage).__name__})\")\n",
        "                return pid_val, current_storage.products[pid_val]\n",
        "\n",
        "    print(f\"[Tool Helper] find_product_by_name: No good match for '{product_name}' (min_similarity: {min_similarity}, Best match: {best_match_name_score}) (in {type(current_storage).__name__})\")\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def get_product_id(current_storage: Storage, product_identifier: str) -> Optional[str]:\n",
        "    \"\"\"Get product ID either directly or by fuzzy matching the name.\"\"\"\n",
        "    if product_identifier in current_storage.products:\n",
        "        return product_identifier\n",
        "    product_id, _ = find_product_by_name(current_storage, product_identifier)\n",
        "    return product_id\n",
        "\n",
        "def get_product_info(current_storage: Storage, product_id_or_name: str) -> Dict[str, Any]:\n",
        "    \"\"\"Get information about a product by its ID or name.\"\"\"\n",
        "    if product_id_or_name in current_storage.products:\n",
        "        product = current_storage.products[product_id_or_name]\n",
        "        print(f\"[Tool Executed] get_product_info: Found by ID '{product_id_or_name}' (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"success\", \"product_id\": product_id_or_name, \"product\": product}\n",
        "\n",
        "    # Use the modified find_product_by_name that takes current_storage\n",
        "    product_id_found, product_data = find_product_by_name(current_storage, product_id_or_name)\n",
        "    if product_id_found and product_data:\n",
        "        print(f\"[Tool Executed] get_product_info: Found by name (fuzzy) '{product_id_or_name}' as ID '{product_id_found}' (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"success\", \"message\": f\"Found product matching '{product_id_or_name}'\", \"product_id\": product_id_found, \"product\": product_data}\n",
        "\n",
        "    print(f\"[Tool Executed] get_product_info: No product found for '{product_id_or_name}' (in {type(current_storage).__name__}).\")\n",
        "    return {\"status\": \"error\", \"message\": f\"No product found matching '{product_id_or_name}'\"}\n",
        "\n",
        "\n",
        "def list_all_products(current_storage: Storage) -> Dict[str, Any]:\n",
        "    \"\"\"List all available products in the inventory.\"\"\"\n",
        "    print(f\"[Tool Executed] list_all_products: Found {len(current_storage.products)} products (in {type(current_storage).__name__}).\")\n",
        "    return {\"status\": \"success\", \"count\": len(current_storage.products), \"products\": dict(current_storage.products)}\n",
        "\n",
        "# Order functions\n",
        "def create_order(current_storage: Storage, product_id_or_name: str, quantity: int, status: str) -> Dict[str, Any]:\n",
        "    \"\"\"Creates an order using the product's stored price.\"\"\"\n",
        "    actual_product_id = get_product_id(current_storage, product_id_or_name) # Pass current_storage\n",
        "\n",
        "    if not actual_product_id:\n",
        "        print(f\"[Tool Executed] create_order: Product '{product_id_or_name}' not found (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"error\", \"message\": f\"Product '{product_id_or_name}' not found.\"}\n",
        "\n",
        "    product = current_storage.products[actual_product_id]\n",
        "    price = product[\"price\"]\n",
        "\n",
        "    if product[\"inventory_count\"] == 0:\n",
        "        print(f\"[Tool Executed] create_order: Product ID {actual_product_id} is out of stock (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"error\", \"message\": f\"{product['name']} is out of stock.\"}\n",
        "    if quantity <= 0:\n",
        "        print(f\"[Tool Executed] create_order: Quantity must be positive. Requested: {quantity} (in {type(current_storage).__name__})\")\n",
        "        return {\"status\": \"error\", \"message\": \"Quantity must be a positive number.\"}\n",
        "    if quantity > product[\"inventory_count\"]:\n",
        "        print(f\"[Tool Executed] create_order: Insufficient inventory for {product['name']} (ID: {actual_product_id}). Available: {product['inventory_count']}, Requested: {quantity} (in {type(current_storage).__name__})\")\n",
        "        return {\n",
        "            \"status\": \"partial_availability\",\n",
        "            \"message\": f\"Insufficient inventory. Only {product['inventory_count']} units of {product['name']} are available.\",\n",
        "            \"available_quantity\": product[\"inventory_count\"],\n",
        "            \"requested_quantity\": quantity,\n",
        "            \"product_name\": product['name']\n",
        "        }\n",
        "\n",
        "    if status == \"Shipped\":\n",
        "        product[\"inventory_count\"] -= quantity\n",
        "        print(f\"[Tool Executed] create_order: Inventory for {product['name']} (ID: {actual_product_id}) reduced by {quantity} due to 'Shipped' status on creation (in {type(current_storage).__name__}).\")\n",
        "\n",
        "    new_id = f\"O{len(current_storage.orders) + 1}\"\n",
        "    current_storage.orders[new_id] = {\n",
        "        \"id\": new_id,\n",
        "        \"product_id\": actual_product_id,\n",
        "        \"product_name\": product[\"name\"],\n",
        "        \"quantity\": quantity,\n",
        "        \"price\": price,\n",
        "        \"status\": status\n",
        "    }\n",
        "    print(f\"[Tool Executed] create_order: Order {new_id} created for {quantity} of {product['name']} (ID: {actual_product_id}). Status: {status}. Remaining inv: {product['inventory_count']} (in {type(current_storage).__name__})\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"order_id\": new_id,\n",
        "        \"order_details\": current_storage.orders[new_id],\n",
        "        \"remaining_inventory\": product[\"inventory_count\"]\n",
        "    }\n",
        "\n",
        "def get_order_details(current_storage: Storage, order_id: str) -> Dict[str, Any]:\n",
        "    \"\"\"Get details of a specific order.\"\"\"\n",
        "    order = current_storage.orders.get(order_id)\n",
        "    if order:\n",
        "        print(f\"[Tool Executed] get_order_details: Order {order_id} found (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"success\", \"order_id\": order_id, \"order_details\": dict(order)}\n",
        "    print(f\"[Tool Executed] get_order_details: Order {order_id} not found (in {type(current_storage).__name__}).\")\n",
        "    return {\"status\": \"error\", \"message\": \"Order not found\"}\n",
        "\n",
        "def update_order_status(current_storage: Storage, order_id: str, new_status: str) -> Dict[str, Any]:\n",
        "    \"\"\"Updates the status of an order and adjusts inventory accordingly.\"\"\"\n",
        "    if order_id not in current_storage.orders:\n",
        "        print(f\"[Tool Executed] update_order_status: Order {order_id} not found (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"error\", \"message\": \"Order not found\"}\n",
        "\n",
        "    order = current_storage.orders[order_id]\n",
        "    old_status = order[\"status\"]\n",
        "    product_id = order[\"product_id\"]\n",
        "    quantity = order[\"quantity\"]\n",
        "\n",
        "    if old_status == new_status:\n",
        "        print(f\"[Tool Executed] update_order_status: Order {order_id} status unchanged ({old_status}) (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"unchanged\", \"message\": f\"Order {order_id} status is already {old_status}\", \"order_details\": dict(order)}\n",
        "\n",
        "    inventory_adjusted = False\n",
        "    current_inventory_val = \"unknown\" # Default if product not found (should not happen if order is valid)\n",
        "\n",
        "    if product_id in current_storage.products:\n",
        "        product = current_storage.products[product_id]\n",
        "        current_inventory_val = product[\"inventory_count\"]\n",
        "\n",
        "        if new_status == \"Shipped\" and old_status not in [\"Shipped\", \"Delivered\"]:\n",
        "            if current_inventory_val < quantity:\n",
        "                print(f\"[Tool Executed] update_order_status: Insufficient inventory to ship order {order_id}. Have {current_inventory_val}, need {quantity} (in {type(current_storage).__name__}).\")\n",
        "                return {\"status\": \"error\", \"message\": f\"Insufficient inventory to ship. Available: {current_inventory_val}, Required: {quantity}\"}\n",
        "            product[\"inventory_count\"] -= quantity\n",
        "            inventory_adjusted = True\n",
        "            current_inventory_val = product[\"inventory_count\"]\n",
        "            print(f\"[Tool Executed] update_order_status: Order {order_id} Shipped. Inv for {product_id} reduced by {quantity} to {current_inventory_val} (in {type(current_storage).__name__}).\")\n",
        "        elif new_status in [\"Returned\", \"Canceled\"] and old_status in [\"Shipped\", \"Delivered\"]:\n",
        "            product[\"inventory_count\"] += quantity\n",
        "            inventory_adjusted = True\n",
        "            current_inventory_val = product[\"inventory_count\"]\n",
        "            print(f\"[Tool Executed] update_order_status: Order {order_id} {new_status}. Inv for {product_id} increased by {quantity} to {current_inventory_val} (in {type(current_storage).__name__}).\")\n",
        "    else:\n",
        "        print(f\"[Tool Executed] update_order_status: Product {product_id} for order {order_id} not found for inventory adjustment (in {type(current_storage).__name__}).\")\n",
        "\n",
        "    order[\"status\"] = new_status\n",
        "    print(f\"[Tool Executed] update_order_status: Order {order_id} status updated from {old_status} to {new_status} (in {type(current_storage).__name__}).\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"message\": f\"Order {order_id} status updated from {old_status} to {new_status}.\",\n",
        "        \"order_id\": order_id,\n",
        "        \"product_id\": product_id,\n",
        "        \"old_status\": old_status,\n",
        "        \"new_status\": new_status,\n",
        "        \"inventory_adjusted\": inventory_adjusted,\n",
        "        \"current_inventory\": current_inventory_val,\n",
        "        \"order_details\": dict(order)\n",
        "    }\n",
        "\n",
        "print(\"Tool functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RZI6SGzRf6j",
        "outputId": "6e95ec07-671e-4028-993e-7dc130a80fdb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationContext:\n",
        "    def __init__(self):\n",
        "        self.messages: List[Dict[str, Any]] = []\n",
        "        self.context_data: Dict[str, Any] = {\n",
        "            \"customers\": {}, \"products\": {}, \"orders\": {}, \"last_action\": None\n",
        "        }\n",
        "        self.session_start_time = datetime.now()\n",
        "\n",
        "    def add_user_message(self, message: str) -> None:\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    def add_assistant_message(self, message_content: Union[str, List[Dict[str, Any]]]) -> None:\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": message_content})\n",
        "\n",
        "    def update_entity_in_context(self, entity_type: str, entity_id: str, data: Any) -> None:\n",
        "        if entity_type in self.context_data:\n",
        "            self.context_data[entity_type][entity_id] = data # Store the actual data\n",
        "            print(f\"[Context Updated] Entity: {entity_type}, ID: {entity_id}, Data (type): {type(data)}\")\n",
        "\n",
        "    def set_last_action(self, action_type: str, action_details: Any) -> None:\n",
        "        self.context_data[\"last_action\"] = {\n",
        "            \"type\": action_type,\n",
        "            \"details\": action_details,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "        print(f\"[Context Updated] Last Action: {action_type}, Details: {json.dumps(action_details, default=str)}\")\n",
        "\n",
        "\n",
        "    def get_full_conversation_for_api(self) -> List[Dict[str, Any]]:\n",
        "        return self.messages.copy()\n",
        "\n",
        "    def get_context_summary(self) -> str:\n",
        "        summary_parts = []\n",
        "        if self.context_data[\"customers\"]:\n",
        "            customers_str = \", \".join([f\"ID: {cid} (Name: {c.get('name', 'N/A') if isinstance(c, dict) else 'N/A'})\" for cid, c in self.context_data[\"customers\"].items()])\n",
        "            summary_parts.append(f\"Recent customers: {customers_str}\")\n",
        "        if self.context_data[\"products\"]:\n",
        "            products_str = \", \".join([f\"ID: {pid} (Name: {p.get('name', 'N/A') if isinstance(p, dict) else 'N/A'})\" for pid, p in self.context_data[\"products\"].items()])\n",
        "            summary_parts.append(f\"Recent products: {products_str}\")\n",
        "        if self.context_data[\"orders\"]:\n",
        "            orders_str = \", \".join([f\"ID: {oid} (Product: {o.get('product_name', 'N/A') if isinstance(o, dict) else 'N/A'}, Status: {o.get('status', 'N/A') if isinstance(o, dict) else 'N/A'})\" for oid, o in self.context_data[\"orders\"].items()])\n",
        "            summary_parts.append(f\"Recent orders: {orders_str}\")\n",
        "\n",
        "        last_action = self.context_data[\"last_action\"]\n",
        "        if last_action:\n",
        "            action_type = last_action['type']\n",
        "            action_details_summary = \"...\" # Default summary\n",
        "            if isinstance(last_action.get('details'), dict):\n",
        "                action_input = last_action['details'].get('input', {})\n",
        "                action_result_status = last_action['details'].get('result', {}).get('status')\n",
        "                action_details_summary = f\"Input: {action_input}, Result Status: {action_result_status}\"\n",
        "                if action_result_status == \"success\":\n",
        "                    if \"order_id\" in last_action['details'].get('result', {}):\n",
        "                         action_details_summary += f\", OrderID: {last_action['details']['result']['order_id']}\"\n",
        "                    elif \"product_id\" in last_action['details'].get('result', {}):\n",
        "                         action_details_summary += f\", ProductID: {last_action['details']['result']['product_id']}\"\n",
        "\n",
        "\n",
        "            summary_parts.append(f\"Last action: {action_type} at {last_action['timestamp']} ({action_details_summary})\")\n",
        "\n",
        "        if not summary_parts: return \"No specific context items set yet.\"\n",
        "        return \"\\n\".join(summary_parts)\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        self.messages = []\n",
        "        self.context_data = {\"customers\": {}, \"products\": {}, \"orders\": {}, \"last_action\": None}\n",
        "        self.session_start_time = datetime.now()\n",
        "        print(\"[Context Cleared]\")\n",
        "\n",
        "print(\"ConversationContext class defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFpBL_-HSGPY",
        "outputId": "a101474a-b2c8-4269-9bdd-286d2a2a7730"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConversationContext class defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODIFIED AgentEvaluator Class\n",
        "class AgentEvaluator:\n",
        "    def __init__(self):\n",
        "        if 'tools_schemas_list' not in globals() or not tools_schemas_list:\n",
        "            raise NameError(\"ERROR: Global 'tools_schemas_list' not found or empty. Please ensure the cell defining it is executed before creating an AgentEvaluator instance.\")\n",
        "\n",
        "        self.conversation_context = ConversationContext()\n",
        "        self.evaluation_results = []\n",
        "        self.anthropic_storage = Storage() # Worker agent's e-commerce data\n",
        "        print(\"AgentEvaluator initialized with new Storage for Anthropic agent.\")\n",
        "\n",
        "        self.anthropic_tools_schemas = tools_schemas_list\n",
        "\n",
        "        self.available_tool_functions = {\n",
        "            \"create_customer\": create_customer, \"get_customer_info\": get_customer_info,\n",
        "            \"create_product\": create_product, \"update_product\": update_product,\n",
        "            \"get_product_info\": get_product_info, \"list_all_products\": list_all_products,\n",
        "            \"create_order\": create_order, \"get_order_details\": get_order_details,\n",
        "            \"update_order_status\": update_order_status,\n",
        "        }\n",
        "        self.active_learnings_cache: List[Dict] = self._load_initial_learnings_from_drive()\n",
        "        self.learnings_updated_this_session_flag: bool = False\n",
        "        print(f\"AgentEvaluator initialized. Learnings path: {LEARNINGS_DRIVE_BASE_PATH}. Loaded {len(self.active_learnings_cache)} initial learnings.\")\n",
        "\n",
        "    def _mount_drive_if_needed(self):\n",
        "        if not os.path.exists(DRIVE_MOUNT_PATH) or not os.listdir(DRIVE_MOUNT_PATH):\n",
        "            try:\n",
        "                drive.mount(DRIVE_MOUNT_PATH, force_remount=True)\n",
        "                print(f\"Google Drive mounted successfully at {DRIVE_MOUNT_PATH}.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error mounting Google Drive: {e}. RAG features will not work.\")\n",
        "        # else: print(f\"Google Drive already mounted at {DRIVE_MOUNT_PATH}.\") # Less verbose\n",
        "\n",
        "    def _initialize_learnings_path(self): # Simplified as path is now set globally earlier\n",
        "        global LEARNINGS_DRIVE_BASE_PATH\n",
        "        if not LEARNINGS_DRIVE_BASE_PATH: # Fallback if somehow not set\n",
        "             LEARNINGS_DRIVE_BASE_PATH = os.path.join(DRIVE_MOUNT_PATH, DEFAULT_LEARNINGS_DRIVE_SUBPATH)\n",
        "\n",
        "        if not os.path.exists(LEARNINGS_DRIVE_BASE_PATH):\n",
        "            try:\n",
        "                os.makedirs(LEARNINGS_DRIVE_BASE_PATH)\n",
        "                print(f\"Created learnings directory: {LEARNINGS_DRIVE_BASE_PATH}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error creating learnings directory {LEARNINGS_DRIVE_BASE_PATH}: {e}\")\n",
        "        # else: print(f\"Learnings directory found: {LEARNINGS_DRIVE_BASE_PATH}\") # Less verbose\n",
        "\n",
        "    def _get_latest_learnings_filepath_from_drive(self) -> Optional[str]:\n",
        "        self._mount_drive_if_needed() # Ensure drive is mounted before access\n",
        "        self._initialize_learnings_path() # Ensure path exists\n",
        "        if not os.path.isdir(LEARNINGS_DRIVE_BASE_PATH): return None\n",
        "        list_of_files = glob.glob(os.path.join(LEARNINGS_DRIVE_BASE_PATH, 'learnings_*.json'))\n",
        "        if not list_of_files: return None\n",
        "        return max(list_of_files, key=os.path.getctime)\n",
        "\n",
        "    def _read_learnings_from_drive_file(self, filepath: str) -> List[Dict]:\n",
        "        if not filepath or not os.path.exists(filepath): return []\n",
        "        try:\n",
        "            with open(filepath, 'r') as f: learnings_list = json.load(f)\n",
        "            return learnings_list if isinstance(learnings_list, list) else []\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading/decoding learnings file {filepath}: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _load_initial_learnings_from_drive(self) -> List[Dict]:\n",
        "        print(\"[RAG Cache] Initializing: Loading latest learnings from Drive...\")\n",
        "        latest_filepath = self._get_latest_learnings_filepath_from_drive()\n",
        "        if latest_filepath:\n",
        "            print(f\"[RAG Cache] Loading initial learnings from: {latest_filepath}\")\n",
        "            return self._read_learnings_from_drive_file(latest_filepath)\n",
        "        print(\"[RAG Cache] No existing learnings file found on Drive for initial load.\")\n",
        "        return []\n",
        "\n",
        "    def _persist_active_learnings_to_drive(self):\n",
        "        self._mount_drive_if_needed()\n",
        "        self._initialize_learnings_path()\n",
        "        if not os.path.isdir(LEARNINGS_DRIVE_BASE_PATH):\n",
        "            print(\"CRITICAL: Learnings directory not available. Aborting RAG persistence.\")\n",
        "            return\n",
        "        if not self.active_learnings_cache:\n",
        "            print(\"[RAG Cache] Active learnings cache is empty. Nothing to persist.\")\n",
        "            self.learnings_updated_this_session_flag = False\n",
        "            return\n",
        "        timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
        "        new_filepath = os.path.join(LEARNINGS_DRIVE_BASE_PATH, f'learnings_{timestamp_str}.json')\n",
        "        try:\n",
        "            with open(new_filepath, 'w') as f: json.dump(self.active_learnings_cache, f, indent=4)\n",
        "            print(f\"[RAG Cache] Successfully persisted {len(self.active_learnings_cache)} active learnings to: {new_filepath}\")\n",
        "            self.learnings_updated_this_session_flag = False\n",
        "        except Exception as e:\n",
        "            print(f\"Error persisting active learnings to {new_filepath}: {e}\")\n",
        "\n",
        "    def check_relevant_learnings(self, query: str, count: int = 5) -> Optional[str]:\n",
        "        if not self.active_learnings_cache: return None\n",
        "        keywords_from_query = self.extract_keywords(query)\n",
        "        relevant_learning_objects = []\n",
        "        for entry in self.active_learnings_cache:\n",
        "            text_to_search = entry.get(\"final_learning_statement\", \"\") + \" \" + entry.get(\"original_human_input\", \"\") + \" \" + \" \".join(entry.get(\"keywords\", []))\n",
        "            if any(kw.lower() in text_to_search.lower() for kw in keywords_from_query):\n",
        "                relevant_learning_objects.append(entry)\n",
        "        relevant_learning_objects.sort(key=lambda x: x.get('timestamp_created', ''), reverse=True)\n",
        "        formatted_learnings = [f\"- Learning (ID: {entry.get('learning_id', 'N/A')[:8]}, Time: {entry.get('timestamp_created', 'N/A')}): {entry.get('final_learning_statement', str(entry))}\" for entry in relevant_learning_objects[:count]]\n",
        "        return \"\\\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\\\n\" + \"\\\\n\".join(formatted_learnings) if formatted_learnings else None\n",
        "\n",
        "    def _update_context_from_tool_results(self, tool_name: str, tool_input: Dict, tool_result: Dict):\n",
        "        agent_name = \"Anthropic\" # Assuming only Anthropic for now\n",
        "        if not isinstance(tool_result, dict):\n",
        "            print(f\"[Context Update Error] Tool result for {tool_name} ({agent_name}) is not a dict: {tool_result}\")\n",
        "            self.conversation_context.set_last_action(f\"tool_{tool_name}_{agent_name}\", {\"input\": tool_input, \"result\": {\"status\": \"error\", \"message\": \"Tool result was not a dictionary.\"}})\n",
        "            return\n",
        "        if tool_result.get(\"status\") == \"success\":\n",
        "            if \"customer_id\" in tool_result and \"customer\" in tool_result and isinstance(tool_result[\"customer\"], dict):\n",
        "                self.conversation_context.update_entity_in_context(\"customers\", tool_result[\"customer_id\"], tool_result[\"customer\"])\n",
        "            elif \"product_id\" in tool_result and \"product\" in tool_result and isinstance(tool_result[\"product\"], dict):\n",
        "                self.conversation_context.update_entity_in_context(\"products\", tool_result[\"product_id\"], tool_result[\"product\"])\n",
        "            elif \"order_id\" in tool_result and \"order_details\" in tool_result and isinstance(tool_result[\"order_details\"], dict):\n",
        "                self.conversation_context.update_entity_in_context(\"orders\", tool_result[\"order_id\"], tool_result[\"order_details\"])\n",
        "            elif tool_name == \"list_all_products\" and \"products\" in tool_result and isinstance(tool_result[\"products\"], dict):\n",
        "                 for pid, pdata in tool_result[\"products\"].items(): self.conversation_context.update_entity_in_context(\"products\", pid, pdata)\n",
        "        self.conversation_context.set_last_action(f\"tool_{tool_name}_{agent_name}\", {\"input\": tool_input, \"result\": tool_result})\n",
        "\n",
        "    def process_tool_call(self, tool_name: str, tool_input: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        target_storage_instance = self.anthropic_storage\n",
        "        print(f\"--- [Tool Dispatcher] Attempting tool: {tool_name} with input: {json.dumps(tool_input, default=str)} for storage: AnthropicStorage ---\")\n",
        "        if tool_name in self.available_tool_functions:\n",
        "            function_to_call = self.available_tool_functions[tool_name]\n",
        "            try:\n",
        "                result = function_to_call(target_storage_instance, **tool_input)\n",
        "                print(f\"--- [Tool Dispatcher] Result for {tool_name} on AnthropicStorage: {json.dumps(result, indent=2, default=str)} ---\")\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                print(f\"--- [Tool Dispatcher] Exception for {tool_name} on AnthropicStorage: {e} (Input: {tool_input}) ---\")\n",
        "                import traceback; traceback.print_exc()\n",
        "                return {\"status\": \"error\", \"message\": f\"Error executing {tool_name}: {str(e)}\"}\n",
        "        else:\n",
        "            print(f\"--- [Tool Dispatcher] Tool {tool_name} not found. ---\")\n",
        "            return {\"status\": \"error\", \"message\": f\"Tool {tool_name} not found.\"}\n",
        "\n",
        "    def get_anthropic_response(self, current_worker_system_prompt: str, conversation_history: List[Dict[str, Any]]) -> str:\n",
        "        messages_for_api = list(conversation_history) # Use a copy\n",
        "        try:\n",
        "            for i in range(5): # Max 5 iterations for tool use\n",
        "                response = anthropic_client.messages.create(\n",
        "                    model=ANTHROPIC_MODEL_NAME, max_tokens=4000, temperature=0.0,\n",
        "                    system=current_worker_system_prompt,\n",
        "                    tools=self.anthropic_tools_schemas,\n",
        "                    messages=messages_for_api\n",
        "                )\n",
        "                assistant_response_blocks = response.content\n",
        "                # Append assistant's attempt (text or tool calls) to the history for the *next* turn\n",
        "                messages_for_api.append({\"role\": \"assistant\", \"content\": assistant_response_blocks})\n",
        "\n",
        "                text_blocks = [block.text for block in assistant_response_blocks if block.type == \"text\"]\n",
        "                final_text_response = \" \".join(text_blocks).strip()\n",
        "\n",
        "                if final_text_response.startswith(\"CLARIFICATION_REQUESTED:\"):\n",
        "                    return final_text_response # Return immediately for clarification\n",
        "\n",
        "                tool_calls_to_process = [block for block in assistant_response_blocks if block.type == \"tool_use\"]\n",
        "                if not tool_calls_to_process: # No tools to call, this is the final text\n",
        "                    return final_text_response if final_text_response else \"No text content in final Anthropic response.\"\n",
        "\n",
        "                tool_results_for_next_call_content = []\n",
        "                for tool_use_block in tool_calls_to_process:\n",
        "                    tool_name, tool_input, tool_use_id = tool_use_block.name, tool_use_block.input, tool_use_block.id\n",
        "                    print(f\"Anthropic Tool Call: {tool_name}, Input: {tool_input}, ID: {tool_use_id}\")\n",
        "                    tool_result_data = self.process_tool_call(tool_name, tool_input)\n",
        "                    self._update_context_from_tool_results(tool_name, tool_input, tool_result_data) # Update context based on this tool call\n",
        "                    tool_results_for_next_call_content.append({\n",
        "                        \"type\": \"tool_result\", \"tool_use_id\": tool_use_id,\n",
        "                        \"content\": json.dumps(tool_result_data) # Ensure result is JSON string\n",
        "                    })\n",
        "                # Append user role message with tool results for the next iteration\n",
        "                messages_for_api.append({\"role\": \"user\", \"content\": tool_results_for_next_call_content})\n",
        "            return \"Max tool iterations reached for Anthropic.\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error in get_anthropic_response: {str(e)}\")\n",
        "            import traceback; traceback.print_exc()\n",
        "            return f\"Error getting Anthropic response: {str(e)}\"\n",
        "\n",
        "    def _handle_worker_clarification(self, agent_question: str, current_prompt: str,\n",
        "                                     agent_specific_history: List[Dict], max_attempts: int = 2) -> Tuple[str, List[Dict]]:\n",
        "        agent_name = \"Anthropic\"\n",
        "        print(f\"\\\\n--- {agent_name} requests clarification ---\")\n",
        "        print(f\"{agent_name}: {agent_question}\")\n",
        "        clarification_turn_details = []\n",
        "        current_history_for_clarification = list(agent_specific_history)\n",
        "\n",
        "        for attempt in range(max_attempts):\n",
        "            user_clarification = input(f\"Your response to {agent_name}: \").strip()\n",
        "            if not user_clarification: user_clarification = \"(User provided no input to clarification)\"\n",
        "\n",
        "            clarification_turn_details.append({\"agent_question\": agent_question, \"user_answer\": user_clarification})\n",
        "            # Add user's clarification to the history for the *next* call to the LLM\n",
        "            current_history_for_clarification.append({\"role\": \"user\", \"content\": user_clarification})\n",
        "\n",
        "            print(f\"Sending clarification back to {agent_name} (Attempt {attempt + 1}/{max_attempts})...\")\n",
        "            # Get new response based on history that *includes* user's clarification\n",
        "            agent_response_text = self.get_anthropic_response(current_prompt, current_history_for_clarification)\n",
        "\n",
        "            # The get_anthropic_response already appends its own assistant message to current_history_for_clarification\n",
        "            # if it makes tool calls or has text. If it asks for clarification again, that's also handled.\n",
        "\n",
        "            if agent_response_text.startswith(\"CLARIFICATION_REQUESTED:\"):\n",
        "                agent_question = agent_response_text.split(\"CLARIFICATION_REQUESTED:\", 1)[-1].strip()\n",
        "                # The assistant's clarification request would have been added to current_history_for_clarification\n",
        "                # by the get_anthropic_response call.\n",
        "                if attempt < max_attempts - 1:\n",
        "                    print(f\"\\\\n--- {agent_name} requests further clarification ---\")\n",
        "                    print(f\"{agent_name}: {agent_question}\")\n",
        "                else:\n",
        "                    print(f\"{agent_name} reached max clarification attempts. Proceeding with last question as response.\")\n",
        "                    return agent_response_text, clarification_turn_details # Return the clarification request itself\n",
        "            else: # AI provided a final response (text or after tool use)\n",
        "                return agent_response_text, clarification_turn_details\n",
        "\n",
        "        return agent_response_text, clarification_turn_details # Should be caught by loop logic\n",
        "\n",
        "    def _get_llm_response_with_clarification_loop(self, system_prompt_with_context_learnings: str,\n",
        "                                                 base_conversation_history: List[Dict]) -> Tuple[str, List[Dict]]:\n",
        "        agent_specific_history = list(base_conversation_history) # Start with a copy\n",
        "\n",
        "        # Initial call to the LLM\n",
        "        final_agent_response = self.get_anthropic_response(system_prompt_with_context_learnings, agent_specific_history)\n",
        "        # Note: get_anthropic_response internally modifies agent_specific_history by appending assistant turns and tool results.\n",
        "\n",
        "        clarification_interactions = []\n",
        "        if final_agent_response.startswith(\"CLARIFICATION_REQUESTED:\"):\n",
        "            agent_question = final_agent_response.split(\"CLARIFICATION_REQUESTED:\", 1)[-1].strip()\n",
        "            # The initial CLARIFICATION_REQUESTED message is already in agent_specific_history (added by get_anthropic_response)\n",
        "\n",
        "            # Handle clarification loop. This will further modify agent_specific_history.\n",
        "            final_agent_response, clarification_interactions = self._handle_worker_clarification(\n",
        "                agent_question, system_prompt_with_context_learnings,\n",
        "                agent_specific_history # Pass the evolving history\n",
        "            )\n",
        "        return final_agent_response, clarification_interactions\n",
        "\n",
        "    def process_user_request(self, user_message: str) -> Dict[str, Any]:\n",
        "        print(f\"\\\\n\\\\n{'='*60}\\\\nUser Message: {user_message}\\\\n{'='*60}\")\n",
        "        self.conversation_context.add_user_message(user_message)\n",
        "        context_summary = self.conversation_context.get_context_summary()\n",
        "        print(f\"Current Context Summary for Agent:\\\\n{context_summary}\\\\n{'-'*60}\")\n",
        "\n",
        "        learnings_for_prompt = self.check_relevant_learnings(user_message)\n",
        "        if learnings_for_prompt: print(f\"Relevant Learnings for this turn:\\\\n{learnings_for_prompt}\")\n",
        "        else: print(\"No specific relevant learnings found for this turn.\")\n",
        "\n",
        "        current_worker_prompt_with_context_and_learnings = f\"{worker_system_prompt}\\\\n\\\\nConversation Context:\\\\n{context_summary}\\\\n\\\\n{learnings_for_prompt if learnings_for_prompt else 'No specific past learnings provided for this query.'}\"\n",
        "        self.learnings_updated_this_session_flag = False\n",
        "\n",
        "        # --- CAPTURE INITIAL DATASTORE STATE ---\n",
        "        initial_datastore_state_for_eval = self.anthropic_storage.get_full_datastore_copy()\n",
        "        print(f\"--- Captured Initial Datastore State for Evaluation (Products count: {len(initial_datastore_state_for_eval['products'])}) ---\")\n",
        "\n",
        "\n",
        "        print(\"\\\\n--- Getting Anthropic's Response ---\")\n",
        "        # Base history for this turn (user message + prior turns)\n",
        "        anthropic_base_history = self.conversation_context.get_full_conversation_for_api()\n",
        "\n",
        "        anthropic_final_response, anthropic_clarifications = self._get_llm_response_with_clarification_loop(\n",
        "            current_worker_prompt_with_context_and_learnings, anthropic_base_history\n",
        "        )\n",
        "        # The conversation_context.messages list is updated by add_user_message and add_assistant_message.\n",
        "        # The anthropic_base_history sent to _get_llm_response_with_clarification_loop is a snapshot.\n",
        "        # The actual LLM calls in get_anthropic_response and _handle_worker_clarification build upon their own\n",
        "        # evolving history copy. We need to ensure the main conversation_context.messages reflects the *final* outcome.\n",
        "\n",
        "        # Add the final assistant response (after all tools and clarifications) to the main context\n",
        "        self.conversation_context.add_assistant_message(f\"[Anthropic Final Text]: {anthropic_final_response}\") # Simplified content for context log\n",
        "\n",
        "        if anthropic_clarifications:\n",
        "            print(f\"[INFO] Anthropic clarification interactions: {json.dumps(anthropic_clarifications, indent=2)}\")\n",
        "            # Log clarifications for learning, if any\n",
        "            for interaction in anthropic_clarifications:\n",
        "                 self.process_and_store_new_learning(\n",
        "                    human_feedback_text=f\"User clarification for Anthropic: '{interaction['user_answer']}' (re: agent question: '{interaction['agent_question']}')\",\n",
        "                    user_query_context=user_message,\n",
        "                    turn_context_summary=context_summary + f\"\\\\nAnthropic asked: {interaction['agent_question']}\"\n",
        "                )\n",
        "\n",
        "        print(f\"\\\\n--- Anthropic Final Response Text (Post-Tool/Clarification) ---\\\\n{anthropic_final_response}\")\n",
        "\n",
        "        # --- CAPTURE FINAL DATASTORE STATE ---\n",
        "        final_datastore_state_for_eval = self.anthropic_storage.get_full_datastore_copy()\n",
        "        print(f\"--- Captured Final Datastore State for Evaluation (Products count: {len(final_datastore_state_for_eval['products'])}) ---\")\n",
        "\n",
        "        evaluation = self.evaluate_responses(\n",
        "            user_message, anthropic_final_response,\n",
        "            context_summary, learnings_for_prompt or \"\",\n",
        "            anthropic_clarifications,\n",
        "            initial_datastore_state_for_eval, # NEW\n",
        "            final_datastore_state_for_eval    # NEW\n",
        "        )\n",
        "        self.evaluation_results.append(evaluation)\n",
        "\n",
        "        # Handle human feedback for learning (evaluator clarification, general learning)\n",
        "        human_feedback_candidate = \"\"\n",
        "        clarif_details_eval = evaluation.get(\"clarification_details\", {})\n",
        "        if clarif_details_eval.get(\"used\") and clarif_details_eval.get(\"provided_input\") not in [\"Skipped by user\", \"Skipped (non-interactive)\"]:\n",
        "            human_feedback_candidate = clarif_details_eval.get(\"provided_input\")\n",
        "            print(f\"[INFO] Candidate learning from *evaluator* clarification: '{human_feedback_candidate}'\")\n",
        "            self.process_and_store_new_learning(human_feedback_text=human_feedback_candidate, user_query_context=user_message, turn_context_summary=context_summary)\n",
        "            human_feedback_candidate = \"\" # Reset after processing\n",
        "\n",
        "        try:\n",
        "            human_general_learning = input(\"Do you want to add any general learnings from this turn? (Type your learning or 'skip'): \").strip()\n",
        "            if human_general_learning.lower() not in ['skip', ''] :\n",
        "                human_feedback_candidate = human_general_learning\n",
        "            elif human_general_learning.lower() == 'skip':\n",
        "                print(\"[INFO] Skipping the addition of general learnings for this turn.\")\n",
        "        except EOFError: print(\"EOFError: Skipping general learning input (non-interactive).\")\n",
        "\n",
        "        if human_feedback_candidate:\n",
        "            self.process_and_store_new_learning(human_feedback_text=human_feedback_candidate, user_query_context=user_message, turn_context_summary=context_summary)\n",
        "\n",
        "        if self.learnings_updated_this_session_flag:\n",
        "            self._persist_active_learnings_to_drive()\n",
        "\n",
        "        return {\"user_message\": user_message, \"anthropic_response\": anthropic_final_response, \"evaluation\": evaluation}\n",
        "\n",
        "    # MODIFIED evaluate_responses method\n",
        "    def evaluate_responses(self, user_message: str, anthropic_response: str,\n",
        "                       context_summary_for_eval: str, learnings_for_eval: str,\n",
        "                       anthropic_clarifications: Optional[List[Dict]],\n",
        "                       initial_datastore_state: Dict[str, Any], # NEW\n",
        "                       final_datastore_state: Dict[str, Any]    # NEW\n",
        "                       ) -> Dict[str, Any]:\n",
        "        print(\"\\\\n--- Starting Evaluation by Gemini (with Before/After States) ---\")\n",
        "\n",
        "        # Prepare datastore states for the prompt\n",
        "        initial_ds_prompt = f\"\\\\nData Store State *Before* AI Action (Initial Ground Truth):\\\\n{json.dumps(initial_datastore_state, indent=2, default=str)}\\\\n\"\n",
        "        final_ds_prompt = f\"\\\\nData Store State *After* AI Action (Final Ground Truth):\\\\n{json.dumps(final_datastore_state, indent=2, default=str)}\\\\n\"\n",
        "\n",
        "        clarification_summary_for_eval = []\n",
        "        if anthropic_clarifications:\n",
        "            clarification_summary_for_eval.append(f\"Anthropic Worker AI Clarification Loop: {len(anthropic_clarifications)} question(s) asked.\")\n",
        "            for i, turn in enumerate(anthropic_clarifications):\n",
        "                clarification_summary_for_eval.append(f\"  A{i+1}: Q: '{turn['agent_question']}' -> User A: '{turn['user_answer']}'\")\n",
        "        clarification_info_for_prompt = \"\\\\n\".join(clarification_summary_for_eval) if clarification_summary_for_eval else \"No clarification questions were asked by the worker AI this turn.\"\n",
        "\n",
        "        try:\n",
        "            eval_prompt_parts = [\n",
        "                f\"User query: {user_message}\",\n",
        "                f\"Current context provided to assistant:\\\\n{context_summary_for_eval}\",\n",
        "                f\"Relevant RAG Learnings provided to assistant:\\\\n{learnings_for_eval if learnings_for_eval else 'None'}\",\n",
        "                initial_ds_prompt, # Use the \"Before\" state for initial context\n",
        "                final_ds_prompt,   # Provide the \"After\" state for verifying outcomes\n",
        "                f\"\\\\nDetails of Worker AI Clarification Interactions this turn:\\\\n{clarification_info_for_prompt}\\\\n\",\n",
        "                f\"Anthropic Claude final textual response:\\\\n{anthropic_response}\",\n",
        "                (\"Please evaluate the response based on accuracy (comparing AI's claims and actions against the changes between 'Before' and 'After' data store states), \"\n",
        "                 \"efficiency (considering necessity of clarifications based on 'Before' state), context awareness, and helpfulness. \"\n",
        "                 \"Provide an overall score (1-10) and detailed reasoning, following your system prompt guidelines. \"\n",
        "                 \"Explicitly reference the 'Before' and 'After' states when discussing data modifications or lack thereof.\")\n",
        "            ]\n",
        "            eval_prompt = \"\\\\n\\\\n\".join(filter(None, eval_prompt_parts))\n",
        "            # print(f\"\\nDEBUG: Full Eval Prompt to Gemini:\\n{eval_prompt[:2000]}...\\n\") # For debugging long prompts\n",
        "\n",
        "            gemini_response_obj = eval_model_instance.generate_content(eval_prompt)\n",
        "            evaluation_text = gemini_response_obj.text\n",
        "            print(f\"Gemini Raw Evaluation (using Before/After states):\\\\n{evaluation_text}\")\n",
        "\n",
        "            clarification_details = {\"used\": False, \"needed\": \"\", \"provided_input\": \"\", \"action_summary\": \"\"}\n",
        "            if \"CLARIFICATION NEEDED_EVALUATOR:\" in evaluation_text.upper():\n",
        "                clarification_details[\"used\"] = True\n",
        "                clarification_details[\"needed\"] = self.extract_clarification_needed(evaluation_text, tag=\"CLARIFICATION NEEDED_EVALUATOR:\")\n",
        "                print(f\"--- Human Clarification Indicated by Evaluator ---\\\\nClarification needed: {clarification_details['needed']}\")\n",
        "                try:\n",
        "                    human_input_for_eval = input(f\"Enter human clarification for EVALUATOR (or 'skip'/'quit'): \")\n",
        "                    if human_input_for_eval.lower() in ['quit', 'exit', 'stop', 'q']: raise SystemExit(\"User requested exit during evaluation\")\n",
        "                    if human_input_for_eval.lower() != 'skip' and human_input_for_eval.strip():\n",
        "                        clarification_details[\"provided_input\"] = human_input_for_eval\n",
        "                        # Note: Actions based on evaluator feedback might need careful consideration of which storage to target.\n",
        "                        # For now, assuming it might affect anthropic_storage if it's a direct data correction.\n",
        "                        action_summary = self.process_human_feedback_actions(human_input_for_eval, self.anthropic_storage)\n",
        "                        clarification_details[\"action_summary\"] = action_summary\n",
        "\n",
        "                        # If evaluator feedback led to data change, the 'final_datastore_state' might be stale.\n",
        "                        # For a re-evaluation, we might need to pass the *new* final state.\n",
        "                        # However, the current prompt structure for re-evaluation is simple.\n",
        "                        updated_final_ds_for_reeval = self.anthropic_storage.get_full_datastore_copy() # Get potentially updated state\n",
        "\n",
        "                        updated_eval_prompt = (f\"{eval_prompt}\\\\n\\\\nHuman clarification provided TO EVALUATOR: {human_input_for_eval}\\\\n\"\n",
        "                                               f\"Action taken based on feedback: {action_summary}\\\\n\"\n",
        "                                               f\"Refreshed Data Store State *After* AI Action (and evaluator feedback action):\\\\n{json.dumps(updated_final_ds_for_reeval, indent=2, default=str)}\\\\n\"\n",
        "                                               f\"Please re-evaluate, considering this new information and the refreshed 'After' state.\")\n",
        "                        updated_gemini_response = eval_model_instance.generate_content(updated_eval_prompt)\n",
        "                        evaluation_text = updated_gemini_response.text # This is now the final evaluation text\n",
        "                        print(f\"Gemini Raw Re-Evaluation:\\\\n{evaluation_text}\")\n",
        "                    else:\n",
        "                        clarification_details[\"provided_input\"] = \"Skipped by user\"\n",
        "                except EOFError: clarification_details[\"provided_input\"] = \"Skipped (non-interactive)\"\n",
        "\n",
        "            # The \"Data Store Consistency Check\" is now integrated into the main evaluation logic\n",
        "            # by providing both before and after states and prompting the evaluator to use them.\n",
        "            # The `evaluation_text` should already contain this comprehensive analysis.\n",
        "            final_evaluation_text = evaluation_text # Use the potentially re-evaluated text\n",
        "\n",
        "            anthropic_score = self.extract_score(final_evaluation_text) # Extract from the final eval text\n",
        "            return {\"anthropic_score\": anthropic_score,\n",
        "                    \"full_evaluation\": final_evaluation_text,\n",
        "                    \"clarification_details\": clarification_details,\n",
        "                    \"initial_datastore_state_provided_to_eval\": initial_datastore_state, # For logging\n",
        "                    \"final_datastore_state_provided_to_eval\": final_datastore_state      # For logging\n",
        "                   }\n",
        "        except Exception as e:\n",
        "            print(f\"Error in evaluation: {str(e)}\")\n",
        "            import traceback; traceback.print_exc()\n",
        "            return {\"error\": f\"Error in evaluation: {str(e)}\", \"anthropic_score\": 0,\n",
        "                    \"full_evaluation\": f\"Evaluation failed: {str(e)}\", \"clarification_details\": {\"used\": False, \"action_summary\": \"\"},\n",
        "                    \"initial_datastore_state_provided_to_eval\": initial_datastore_state,\n",
        "                    \"final_datastore_state_provided_to_eval\": final_datastore_state\n",
        "                   }\n",
        "\n",
        "    def extract_clarification_needed(self, evaluation_text: str, tag: str = \"CLARIFICATION NEEDED:\") -> str:\n",
        "        # (Implementation from notebook - seems okay)\n",
        "        clarification_match = re.search(rf\"{tag.upper()}\\\\s*(.*?)(?:\\\\n|$)\", evaluation_text, re.IGNORECASE | re.DOTALL)\n",
        "        if clarification_match and clarification_match.group(1).strip(): return clarification_match.group(1).strip()\n",
        "        lines = evaluation_text.splitlines();\n",
        "        for i, line in enumerate(lines):\n",
        "            if tag.upper() in line.upper(): return line.upper().split(tag.upper(), 1)[-1].strip() + \"\\\\n\" + \"\\\\n\".join(lines[i+1:i+3])\n",
        "        return \"Evaluator indicated clarification needed, but specific question not formatted as expected.\"\n",
        "\n",
        "    def process_and_store_new_learning(self, human_feedback_text: str, user_query_context: str, turn_context_summary: str):\n",
        "        # (Implementation from notebook - largely unchanged for this fix, ensure it uses eval_model_instance)\n",
        "        print(f\"\\\\n--- Processing New Candidate Learning from Human Feedback: \\\\\\\"{human_feedback_text}\\\\\\\" ---\")\n",
        "        current_learnings_for_conflict_check = list(self.active_learnings_cache)\n",
        "        evaluator_task_prompt_parts = [\n",
        "            \"You are an AI assistant helping to maintain a knowledge base of 'learnings' for a customer service AI agent.\",\n",
        "            f\"The New Human Feedback is: \\\\\\\"{human_feedback_text}\\\\\\\"\",\n",
        "            f\"This feedback was given in the context of the user query: \\\\\\\"{user_query_context}\\\\\\\"\",\n",
        "            \"\\\\nHere are some existing ACTIVE learnings from our knowledge base (last 10, if any):\"\n",
        "        ]\n",
        "        if current_learnings_for_conflict_check:\n",
        "            for i, el_entry in enumerate(current_learnings_for_conflict_check[-10:]):\n",
        "                stmt = el_entry.get('final_learning_statement', el_entry.get('original_human_input', 'N/A'))\n",
        "                evaluator_task_prompt_parts.append(f\"  Existing Learning {i+1} (ID: {el_entry.get('learning_id','N/A')[:8]}): \\\\\\\"{stmt}\\\\\\\"\")\n",
        "        else: evaluator_task_prompt_parts.append(\"  (No existing active learnings found.)\")\n",
        "        evaluator_task_prompt_parts.extend([\n",
        "            \"\\\\nYour Tasks:\",\n",
        "            \"1. Analyze New Human Feedback.\", \"2. Compare with Existing ACTIVE Learnings for CONFLICTS or REDUNDANCY.\",\n",
        "            \"3. If CONFLICT: Output `CONFLICT_DETECTED:`, explain, ask human to resolve. DO NOT provide 'FINALIZED_LEARNING'.\",\n",
        "            \"4. If REDUNDANT: Output `REDUNDANT_LEARNING:`, state which existing learning. DO NOT provide 'FINALIZED_LEARNING'.\",\n",
        "            \"5. If new/refining (no major conflict): Synthesize concise, actionable 'Finalized Learning Statement'. Prefix with `FINALIZED_LEARNING:`.\",\n",
        "            \"6. If vague/unsuitable: Output `NOT_ACTIONABLE:`, explain. DO NOT provide 'FINALIZED_LEARNING'.\"\n",
        "        ])\n",
        "        evaluator_conflict_check_prompt = \"\\\\n\".join(evaluator_task_prompt_parts)\n",
        "        synthesis_response_obj = eval_model_instance.generate_content(evaluator_conflict_check_prompt)\n",
        "        evaluator_synthesis_text = synthesis_response_obj.text\n",
        "        print(f\"\\\\n[RAG Cache] Evaluator response on learning processing:\\\\n{evaluator_synthesis_text}\")\n",
        "\n",
        "        made_change_to_cache = False; final_learning_statement_to_store = None\n",
        "        if \"CONFLICT_DETECTED:\" in evaluator_synthesis_text:\n",
        "            print(f\"\\\\n🛑 CONFLICT DETECTED BY EVALUATOR 🛑\\\\n{evaluator_synthesis_text.split('CONFLICT_DETECTED:', 1)[-1].strip()}\")\n",
        "            # Simplified conflict resolution: default to adding new if user doesn't explicitly discard/merge\n",
        "            human_resolution = input(\"Resolve conflict: 'use new', 'discard new', 'merge: [text]', or 'keep existing': \").strip()\n",
        "            if human_resolution.lower() == \"use new\": final_learning_statement_to_store = human_feedback_text\n",
        "            elif human_resolution.lower().startswith(\"merge:\"): final_learning_statement_to_store = human_resolution.split(\"merge:\", 1)[-1].strip()\n",
        "            elif human_resolution.lower() in [\"discard new\", \"keep existing\"]: final_learning_statement_to_store = None\n",
        "            else: print(\"Resolution unclear. New candidate learning discarded.\"); final_learning_statement_to_store = None\n",
        "        elif \"FINALIZED_LEARNING:\" in evaluator_synthesis_text:\n",
        "            final_learning_statement_to_store = evaluator_synthesis_text.split(\"FINALIZED_LEARNING:\", 1)[-1].strip()\n",
        "            print(f\"\\\\n✅ Finalized Learning by Evaluator: \\\\\\\"{final_learning_statement_to_store}\\\\\\\"\")\n",
        "        elif \"REDUNDANT_LEARNING:\" in evaluator_synthesis_text or \"NOT_ACTIONABLE:\" in evaluator_synthesis_text:\n",
        "            print(f\"\\\\nℹ️ Evaluator: {evaluator_synthesis_text.strip()}\")\n",
        "        else: # Unexpected response\n",
        "            print(\"\\\\n⚠️ Evaluator response format for learning unexpected. Storing raw human feedback.\"); final_learning_statement_to_store = human_feedback_text\n",
        "\n",
        "        if final_learning_statement_to_store:\n",
        "            new_learning_entry = {\"learning_id\": str(uuid.uuid4()), \"timestamp_created\": datetime.now().isoformat(), \"user_query_context_at_feedback\": user_query_context, \"original_human_input\": human_feedback_text, \"final_learning_statement\": final_learning_statement_to_store, \"keywords\": self.extract_keywords(final_learning_statement_to_store + \" \" + human_feedback_text), \"status\": \"active\"}\n",
        "            self.active_learnings_cache.append(new_learning_entry)\n",
        "            made_change_to_cache = True\n",
        "            print(f\"[RAG Cache] Learning processed. Cache now has {len(self.active_learnings_cache)} entries.\")\n",
        "        if made_change_to_cache: self.learnings_updated_this_session_flag = True\n",
        "        else: print(\"[RAG Cache] No changes made to learnings cache from this feedback.\")\n",
        "\n",
        "\n",
        "    def extract_keywords(self, text: str) -> List[str]:\n",
        "        # (Implementation from notebook - seems okay)\n",
        "        if not text: return [\"general\"]\n",
        "        words = re.findall(r'\\\\b\\\\w{4,}\\\\b', text.lower())\n",
        "        stop_words = {\"the\", \"and\", \"is\", \"in\", \"to\", \"a\", \"of\", \"for\", \"with\", \"on\", \"at\", \"what\", \"how\", \"show\", \"tell\", \"please\", \"what's\", \"i'd\", \"like\", \"user\", \"query\", \"this\", \"that\", \"context\", \"claude\", \"anthropic\", \"before\", \"after\", \"state\", \"action\", \"truth\", \"ground\"}\n",
        "        extracted = list(set(word for word in words if word not in stop_words))\n",
        "        return extracted if extracted else [\"generic\"]\n",
        "\n",
        "    def extract_score(self, evaluation_text: str) -> int:\n",
        "        # (Implementation from notebook - seems okay, might need tuning for new eval format)\n",
        "        model_name_pattern = \"Anthropic\" # Or make it more generic if evaluating multiple\n",
        "        # Try to find score in the last part of the text first, assuming summary is at the end\n",
        "        search_text_segments = [evaluation_text]\n",
        "        consistency_check_section_start = evaluation_text.upper().rfind(\"--- DATA STORE CONSISTENCY CHECK ---\") # This marker might be removed from prompt\n",
        "        if consistency_check_section_start != -1: # If old marker exists, search after it first\n",
        "             search_text_segments.insert(0, evaluation_text[consistency_check_section_start:])\n",
        "\n",
        "        patterns = [\n",
        "            rf\"(?:Overall Score|{model_name_pattern}.*?Overall Score).*?[:\\\\s]*(\\\\d+)/10\",\n",
        "            rf\"{model_name_pattern}.*?Overall Score.*?[:\\\\s]*(\\\\d+)\",\n",
        "            rf\"Overall Score.*?{model_name_pattern}.*?[:\\\\s]*(\\\\d+)\",\n",
        "            rf\"{model_name_pattern}.*?score.*[:\\\\s]+(\\\\d+)(?:/10)?\",\n",
        "            rf\"{model_name_pattern}.*?\\\\bscore\\\\b.*?(\\\\d+)\",\n",
        "            rf\"Updated score for {model_name_pattern}.*?[:\\\\s]*(\\\\d+)\",\n",
        "            rf\"{model_name_pattern}.*?updated overall score.*?[:\\\\s]*(\\\\d+)\",\n",
        "            r\"Overall Score[:\\s]*(\\d+)(?:/10)?\",\n",
        "            r\"The AI assistant's overall score is (\\d+)/10\",\n",
        "            r\"Overall[:\\s]*(\\d+)/10\"\n",
        "        ]\n",
        "        for text_segment in search_text_segments: # Prioritize later segments\n",
        "            for p_str in reversed(patterns): # Try more specific patterns first\n",
        "                matches = list(re.finditer(p_str, text_segment, re.IGNORECASE | re.DOTALL))\n",
        "                if matches:\n",
        "                    last_match = matches[-1]\n",
        "                    if last_match.group(1):\n",
        "                        try:\n",
        "                            score = int(last_match.group(1))\n",
        "                            print(f\"Extracted score {score} for '{model_name_pattern}' (or generic) using pattern: {p_str}\")\n",
        "                            return score\n",
        "                        except ValueError: continue\n",
        "        print(f\"Could not extract score for '{model_name_pattern}' from eval text. Review eval output. Defaulting to 0.\")\n",
        "        return 0\n",
        "\n",
        "    def process_human_feedback_actions(self, feedback: str, target_storage_for_action: Optional[Storage]) -> str:\n",
        "        # (Implementation from notebook - ensure it uses self.process_tool_call which now uses self.anthropic_storage)\n",
        "        action_result_summary = \"No specific data action taken based on feedback.\"\n",
        "        if not target_storage_for_action: # Should always be self.anthropic_storage if called from eval\n",
        "            return \"Skipping data action: No target storage specified for feedback.\"\n",
        "\n",
        "        current_storage_name = \"Anthropic's Store\" # Since target_storage_for_action is self.anthropic_storage\n",
        "\n",
        "        # Simplified: Check if feedback is a direct tool call-like instruction\n",
        "        # Example: \"tool:create_order product_id_or_name=P1 quantity=5 status=Shipped\"\n",
        "        if feedback.lower().startswith(\"tool:\"):\n",
        "            try:\n",
        "                parts = feedback.split(\" \", 1)\n",
        "                tool_name = parts[0].split(\":\")[1]\n",
        "                args_str = parts[1] if len(parts) > 1 else \"\"\n",
        "                tool_input = {}\n",
        "                if args_str:\n",
        "                    for arg_pair in args_str.split(\" \"):\n",
        "                        key, value = arg_pair.split(\"=\")\n",
        "                        # Attempt to convert to int/float if possible\n",
        "                        if value.isdigit(): tool_input[key] = int(value)\n",
        "                        elif re.match(r'^\\\\d+\\\\.\\\\d+$', value): tool_input[key] = float(value)\n",
        "                        else: tool_input[key] = value\n",
        "\n",
        "                if tool_name in self.available_tool_functions:\n",
        "                    print(f\"[Human Feedback Action] Attempting tool '{tool_name}' with input: {tool_input} on {current_storage_name}\")\n",
        "                    # Use self.process_tool_call to ensure it uses the correct storage (self.anthropic_storage)\n",
        "                    # and updates conversation context appropriately.\n",
        "                    result = self.process_tool_call(tool_name, tool_input)\n",
        "                    action_result_summary = f\"Action executed on {current_storage_name} via human feedback: Tool '{tool_name}'. Result: {result.get('status', 'N/A')}\"\n",
        "                    # Context update is handled by process_tool_call via _update_context_from_tool_results\n",
        "                else:\n",
        "                    action_result_summary = f\"Tool '{tool_name}' specified in human feedback not found.\"\n",
        "            except Exception as e:\n",
        "                action_result_summary = f\"Failed to parse/execute tool from human feedback '{feedback}': {str(e)}\"\n",
        "            print(f\"[Human Feedback Action] {action_result_summary}\")\n",
        "            return action_result_summary\n",
        "\n",
        "        # Original regex-based parsing (can be kept as fallback or for specific commands)\n",
        "        order_update_match = re.search(r\"update\\\\s+order\\\\s+(\\\\w+)\\\\s+status\\\\s+to\\\\s+(\\\\w+)\", feedback, re.IGNORECASE)\n",
        "        if order_update_match:\n",
        "            order_id, new_status = order_update_match.groups()\n",
        "            tool_input = {\"order_id\": order_id, \"new_status\": new_status}\n",
        "            result = self.process_tool_call(\"update_order_status\", tool_input) # Uses self.anthropic_storage\n",
        "            action_result_summary = f\"Action executed on {current_storage_name}: Updated order {order_id} status to {new_status}. Result: {result.get('status', 'N/A')}\"\n",
        "            print(f\"[Human Feedback Action] {action_result_summary}\")\n",
        "            return action_result_summary\n",
        "\n",
        "        # Add more regexes or a more robust command parser if needed\n",
        "\n",
        "        return action_result_summary\n",
        "\n",
        "print(\"MODIFIED AgentEvaluator class defined with Before/After state handling for evaluation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzLHm8MmSOMC",
        "outputId": "cfd6a84b-c514-4476-b638-2beadf32a562"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODIFIED AgentEvaluator class defined with Before/After state handling for evaluation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"\\\\nStarting Main Execution (Single Agent - Anthropic) with MODIFIED Evaluator...\\\\n\")\n",
        "    try:\n",
        "        agent = AgentEvaluator()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to initialize AgentEvaluator: {e}\")\n",
        "        import traceback; traceback.print_exc()\n",
        "        return\n",
        "\n",
        "    results_log = []\n",
        "    while True:\n",
        "        try:\n",
        "            user_query = input(\"\\\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): \")\n",
        "            if user_query.lower() in ['quit', 'exit', 'stop', 'q']:\n",
        "                print(\"Exiting the system. Goodbye!\")\n",
        "                if agent.learnings_updated_this_session_flag:\n",
        "                    print(\"Persisting final session learnings to Drive...\")\n",
        "                    agent._persist_active_learnings_to_drive()\n",
        "                break\n",
        "            if not user_query.strip(): print(\"Empty query, please enter something.\"); continue\n",
        "\n",
        "            result = agent.process_user_request(user_query)\n",
        "            results_log.append(result)\n",
        "        except SystemExit as se:\n",
        "            print(f\"System exit requested: {se}\")\n",
        "            if agent.learnings_updated_this_session_flag:\n",
        "                print(\"Persisting session learnings to Drive before exiting...\")\n",
        "                agent._persist_active_learnings_to_drive()\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"CRITICAL ERROR processing query '{user_query}': {e}\")\n",
        "            import traceback; traceback.print_exc()\n",
        "            results_log.append({\"user_message\": user_query, \"anthropic_response\": \"ERROR\",\n",
        "                                \"evaluation\": {\"anthropic_score\": 0, \"full_evaluation\": f\"Critical error: {e}\",\n",
        "                                               \"clarification_details\": {\"used\": False, \"action_summary\": \"\"}}})\n",
        "    print(\"\\\\n\\\\n===== EVALUATION SUMMARY =====\")\n",
        "    total_anthropic_score, num_q = 0, 0\n",
        "    for i, res in enumerate(results_log):\n",
        "        if not res: print(f\"\\\\nQuery {i+1}: Skipped (empty result).\"); continue\n",
        "        num_q +=1\n",
        "        print(f\"\\\\nQuery {i+1}: {res.get('user_message', 'N/A')}\")\n",
        "        print(f\"  Anthropic Resp: {str(res.get('anthropic_response', 'N/A'))[:250]}...\")\n",
        "        eval_data = res.get('evaluation', {})\n",
        "        anth_s = eval_data.get('anthropic_score', 0)\n",
        "        total_anthropic_score += anth_s\n",
        "        print(f\"  Score - Anthropic: {anth_s}\")\n",
        "        # Log initial and final states if available in eval_data for review\n",
        "        if \"initial_datastore_state_provided_to_eval\" in eval_data:\n",
        "            print(f\"    Initial DS Orders: {len(eval_data['initial_datastore_state_provided_to_eval'].get('orders', {}))}, Products Inv P3: {eval_data['initial_datastore_state_provided_to_eval'].get('products', {}).get('P3',{}).get('inventory_count', 'N/A')}\")\n",
        "        if \"final_datastore_state_provided_to_eval\" in eval_data:\n",
        "            print(f\"    Final DS Orders: {len(eval_data['final_datastore_state_provided_to_eval'].get('orders', {}))}, Products Inv P3: {eval_data['final_datastore_state_provided_to_eval'].get('products', {}).get('P3',{}).get('inventory_count', 'N/A')}\")\n",
        "\n",
        "        clarif_details = eval_data.get('clarification_details',{})\n",
        "        if clarif_details.get('used'):\n",
        "            print(f\"    Evaluator Clarification: Needed='{clarif_details.get('needed', 'N/A')}', Provided='{clarif_details.get('provided_input', 'N/A')}'\")\n",
        "            if clarif_details.get('action_summary'): print(f\"    Action from Evaluator Clarification: {clarif_details['action_summary']}\")\n",
        "    print(f\"\\\\n----- Overall Performance -----\")\n",
        "    if num_q > 0: print(f\"Avg Anthropic Score: {total_anthropic_score/num_q:.2f}\")\n",
        "    else: print(\"No queries processed.\")\n",
        "    print(f\"Total Anthropic Score: {total_anthropic_score}\")\n",
        "    print(f\"\\\\nLearnings are stored in: {LEARNINGS_DRIVE_BASE_PATH}\")\n",
        "    latest_learnings_file = agent._get_latest_learnings_filepath_from_drive()\n",
        "    if latest_learnings_file: print(f\"Most recent learnings file: {os.path.basename(latest_learnings_file)}\")\n",
        "    else: print(\"No learnings files found.\")\n",
        "    print(\"\\\\nExecution Finished.\")\n",
        "\n",
        "# To run in a new cell:\n",
        "# main()"
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "id": "O2-ztJ2BO7gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Sample queries:\n",
        "* Show me all the products available\n",
        "* I'd like to order 25 Perplexinators, please\n",
        "* Show me the status of my order\n",
        "* (If the order is not in Shipped state, then) Please ship my order now\n",
        "* How many Perplexinators are now left in stock?\n",
        "* Add a new customer: Bill Leece, bill.leece@mail.com, +1.222.333.4444\n",
        "* Add new new product: Gizmo X, description: A fancy gizmo, price: 29.99, inventory: 50\n",
        "* Update Gizzmo's price to 99.99 #Note the misspelling of 'Gizmo'\n",
        "* Who won the 2020 US presidential election?\n",
        "* I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount.\n",
        "* Summarize your learnings from our recent interactions.\n",
        "\"\"\"\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dg85ek6bSvW5",
        "outputId": "63ac04e8-dc2c-4617-eb60-ef24fa1f699d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nStarting Main Execution (Single Agent - Anthropic) with MODIFIED Evaluator...\\n\n",
            "AgentEvaluator initialized with new Storage for Anthropic agent.\n",
            "[RAG Cache] Initializing: Loading latest learnings from Drive...\n",
            "[RAG Cache] Loading initial learnings from: /content/drive/My Drive/AI/Knowledgebases/learnings_20250519_141006_754753.json\n",
            "AgentEvaluator initialized. Learnings path: /content/drive/My Drive/AI/Knowledgebases. Loaded 2 initial learnings.\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): I'd like to order 25 Perplexinators, please\n",
            "\\n\\n============================================================\\nUser Message: I'd like to order 25 Perplexinators, please\\n============================================================\n",
            "Current Context Summary for Agent:\\nNo specific context items set yet.\\n------------------------------------------------------------\n",
            "No specific relevant learnings found for this turn.\n",
            "--- Captured Initial Datastore State for Evaluation (Products count: 3) ---\n",
            "\\n--- Getting Anthropic's Response ---\n",
            "Anthropic Tool Call: get_product_info, Input: {'product_id_or_name': 'Perplexinator'}, ID: toolu_01NYsHuAuUBATWBPjTQccucC\n",
            "--- [Tool Dispatcher] Attempting tool: get_product_info with input: {\"product_id_or_name\": \"Perplexinator\"} for storage: AnthropicStorage ---\n",
            "[Tool Helper] find_product_by_name: Matched 'Perplexinator' to 'Perplexinator' (ID: P3) with score 100 (in Storage)\n",
            "[Tool Executed] get_product_info: Found by name (fuzzy) 'Perplexinator' as ID 'P3' (in Storage).\n",
            "--- [Tool Dispatcher] Result for get_product_info on AnthropicStorage: {\n",
            "  \"status\": \"success\",\n",
            "  \"message\": \"Found product matching 'Perplexinator'\",\n",
            "  \"product_id\": \"P3\",\n",
            "  \"product\": {\n",
            "    \"name\": \"Perplexinator\",\n",
            "    \"description\": \"A perplexing perfunctator\",\n",
            "    \"price\": 79.99,\n",
            "    \"inventory_count\": 1483\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: products, ID: P3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_get_product_info_Anthropic, Details: {\"input\": {\"product_id_or_name\": \"Perplexinator\"}, \"result\": {\"status\": \"success\", \"message\": \"Found product matching 'Perplexinator'\", \"product_id\": \"P3\", \"product\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1483}}}\n",
            "Anthropic Tool Call: create_order, Input: {'product_id_or_name': 'Perplexinator', 'quantity': 25, 'status': 'Processing'}, ID: toolu_01HA3VDo99eWJcCJCncdA5Po\n",
            "--- [Tool Dispatcher] Attempting tool: create_order with input: {\"product_id_or_name\": \"Perplexinator\", \"quantity\": 25, \"status\": \"Processing\"} for storage: AnthropicStorage ---\n",
            "[Tool Helper] find_product_by_name: Matched 'Perplexinator' to 'Perplexinator' (ID: P3) with score 100 (in Storage)\n",
            "[Tool Executed] create_order: Order O3 created for 25 of Perplexinator (ID: P3). Status: Processing. Remaining inv: 1483 (in Storage)\n",
            "--- [Tool Dispatcher] Result for create_order on AnthropicStorage: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O3\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O3\",\n",
            "    \"product_id\": \"P3\",\n",
            "    \"product_name\": \"Perplexinator\",\n",
            "    \"quantity\": 25,\n",
            "    \"price\": 79.99,\n",
            "    \"status\": \"Processing\"\n",
            "  },\n",
            "  \"remaining_inventory\": 1483\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_create_order_Anthropic, Details: {\"input\": {\"product_id_or_name\": \"Perplexinator\", \"quantity\": 25, \"status\": \"Processing\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O3\", \"order_details\": {\"id\": \"O3\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 25, \"price\": 79.99, \"status\": \"Processing\"}, \"remaining_inventory\": 1483}}\n",
            "\\n--- Anthropic Final Response Text (Post-Tool/Clarification) ---\\nI've successfully placed your order! Here are the details:\n",
            "- Order ID: O3\n",
            "- Product: Perplexinator\n",
            "- Quantity: 25\n",
            "- Price per unit: $79.99\n",
            "- Total price: $1,999.75\n",
            "- Status: Processing\n",
            "\n",
            "Your order is now being processed. Is there anything else you'd like to know about your order?\n",
            "--- Captured Final Datastore State for Evaluation (Products count: 3) ---\n",
            "\\n--- Starting Evaluation by Gemini (with Before/After States) ---\n",
            "Gemini Raw Evaluation (using Before/After states):\\n## Evaluation of AI Assistant Response\n",
            "\n",
            "**1. Accuracy:**\n",
            "    *   **Textual Response Accuracy**: The AI's textual response is highly accurate regarding the details of the order it claims to have placed.\n",
            "        *   Order ID: \"O3\" - This matches the new order created in the 'Data Store State *After* AI Action'.\n",
            "        *   Product: \"Perplexinator\" - This matches product P3 and the `product_name` in order O3.\n",
            "        *   Quantity: 25 - This matches the `quantity` in order O3.\n",
            "        *   Price per unit: \"$79.99\" - This matches the `price` for product P3 in the 'Data Store State *Before* AI Action' and in order O3.\n",
            "        *   Total price: \"$1,999.75\" - This calculation (25 * $79.99) is correct.\n",
            "        *   Status: \"Processing\" - This matches the `status` in order O3.\n",
            "    *   **Accuracy of AI's Actions (Tool Calls)**:\n",
            "        *   An order (O3) was correctly created in the `orders` table. The 'Data Store State *After* AI Action' shows: `O3: { \"id\": \"O3\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 25, \"price\": 79.99, \"status\": \"Processing\" }`. This aligns with the user's request and the AI's response.\n",
            "        *   However, there's a significant issue with inventory update. The 'Data Store State *Before* AI Action' shows product P3 (\"Perplexinator\") had an `inventory_count` of 1483. After an order for 25 units, the `inventory_count` for P3 in the 'Data Store State *After* AI Action' *remains* 1483. For the datastore to be correctly modified as intended by an \"order placement\" in an inventory-managed system, the inventory should have been decremented to 1483 - 25 = 1458. This did not happen.\n",
            "        *   While the AI's textual response doesn't explicitly claim inventory was updated, the action of \"successfully placing an order\" implies that all necessary systemic changes, including inventory allocation, have occurred. The failure to update inventory means the AI's action did not fully and correctly modify the datastore as intended for a complete order fulfillment process.\n",
            "\n",
            "    *Score: 6/10* (Points deducted significantly because the action of placing an order was incomplete due to the lack of inventory update, which is a critical aspect of order processing.)\n",
            "\n",
            "**2. Efficiency:**\n",
            "    *   The AI did not ask any clarification questions.\n",
            "    *   This was appropriate as the user's query \"order 25 Perplexinators\" was clear. The AI correctly identified the product (\"Perplexinator\" corresponding to P3) and the quantity from the 'Data Store State *Before* AI Action' and the query.\n",
            "    *   The AI proceeded directly to creating the order.\n",
            "    *   Tool calls were used to create the order.\n",
            "\n",
            "    *Score: 10/10*\n",
            "\n",
            "**3. Context Awareness:**\n",
            "    *   There was no prior conversation context or RAG learnings provided.\n",
            "    *   The AI correctly interpreted the user's intent to place a new order based solely on the current query.\n",
            "\n",
            "    *Score: 10/10*\n",
            "\n",
            "**4. Helpfulness:**\n",
            "    *   The AI addressed the user's explicit request to order a product by creating an order record.\n",
            "    *   The response was clear, providing all relevant details of the created order record (ID, product, quantity, price, total price, status).\n",
            "    *   The offer \"Is there anything else you'd like to know about your order?\" is a good practice for helpfulness.\n",
            "    *   However, the helpfulness is somewhat undermined by the fact that the inventory was not updated. While the user has an order record, the lack of inventory adjustment could lead to future problems (e.g., overselling if this isn't rectified). For the immediate interaction of \"placing an order\" (i.e., creating the order entry), it was helpful, but not entirely complete from a business process standpoint.\n",
            "\n",
            "    *Score: 8/10* (Helpful in creating the order record and providing information, but the underlying process flaw regarding inventory reduces overall helpfulness in a broader sense.)\n",
            "\n",
            "**Overall Score: 8.5/10** ((6+10+10+8)/4, rounded to nearest 0.5 or decided holistically. While efficiency and context were perfect, the accuracy flaw is significant but the user did get an order number and confirmation. The helpfulness is good on the surface.)\n",
            "\n",
            "**Reasoning for Overall Score:**\n",
            "The AI was very efficient and understood the request perfectly without any context. The textual response confirming the order was clear and contained all the necessary details derived from the created order record. However, the major drawback was the failure of its action (or the underlying tool) to update the product inventory in the datastore. This is a critical failure in correctly reflecting the outcome of an order. While the order *record* O3 was created accurately as per the AI's claims, the overall action of \"placing an order\" was incomplete. The scores reflect a strong performance in communication and efficiency, but a notable lapse in the completeness and correctness of the datastore modification.\n",
            "Extracted score 8 for 'Anthropic' (or generic) using pattern: Overall Score[:\\s]*(\\d+)(?:/10)?\n",
            "Do you want to add any general learnings from this turn? (Type your learning or 'skip'): If there is sufficient inventory available, the order should be set to \"Shipped\" and the inventory count should be updated.\n",
            "\\n--- Processing New Candidate Learning from Human Feedback: \\\"If there is sufficient inventory available, the order should be set to \"Shipped\" and the inventory count should be updated.\\\" ---\n",
            "\\n[RAG Cache] Evaluator response on learning processing:\\n1.  **Analyze New Human Feedback.**\n",
            "    The New Human Feedback is: \"If there is sufficient inventory available, the order should be set to \"Shipped\" and the inventory count should be updated.\" This feedback specifies two actions to be taken when an order is made and inventory is sufficient: set the order status to \"Shipped\" and update the inventory count.\n",
            "\n",
            "2.  **Compare with Existing ACTIVE Learnings.**\n",
            "    *   **Existing Learning 1 (ID: d90939a9):** \"If a user inquiry about order status (e.g., 'Show me the status of my order') directly follows their statement of intent to place an order (e.g., 'I'd like to order 25 Perplexinators, please'), the AI should assume 'my order' refers to this newly initiated or currently discussed order.\"\n",
            "        *   This learning deals with pronoun resolution in conversation and is not directly related to order processing logic. There is no conflict or redundancy with the new feedback.\n",
            "\n",
            "    *   **Existing Learning 2 (ID: c4e242ea):** \"` When a customer makes an order, if there is sufficient inventory in stock, set the order status to \"Shipped\". If there is not sufficient inventory, keep the order status as \"Processing\", notify the user of the insufficient inventory, and inform them that the order will be shipped as soon as sufficient inventory is available.\"\n",
            "        *   This learning outlines the procedure for order status based on inventory.\n",
            "        *   For the \"sufficient inventory\" case, it states: \"if there is sufficient inventory in stock, set the order status to \"Shipped\".\"\n",
            "        *   The new feedback also states: \"the order should be set to \"Shipped\"\". This part overlaps.\n",
            "        *   However, the new feedback adds a crucial second action: \"and the inventory count should be updated.\" Existing Learning 2 does *not* explicitly mention updating the inventory count when an order is shipped due to sufficient inventory.\n",
            "\n",
            "3.  **Conflict/Redundancy Assessment:**\n",
            "    *   **Conflict:** There is no conflict. The new feedback does not contradict Existing Learning 2. Instead, it adds a necessary detail (inventory update) to the procedure for handling orders with sufficient inventory.\n",
            "    *   **Redundancy:** The new feedback is not entirely redundant. While the instruction to set the order status to \"Shipped\" is present in Existing Learning 2, the instruction to update the inventory count is new information. The new feedback refines and expands upon the existing procedure.\n",
            "\n",
            "4.  **Synthesize Finalized Learning Statement.**\n",
            "    Since the new feedback refines an existing process by adding a critical step and does not conflict with or become fully redundant by existing learnings, a new finalized learning statement should be created. This statement should incorporate both actions mentioned in the new feedback.\n",
            "\n",
            "`FINALIZED_LEARNING: When an order is placed and sufficient inventory is available for the items ordered, the order status should be set to 'Shipped', and the corresponding product inventory counts must be updated to reflect the fulfilled items.`\n",
            "\\n✅ Finalized Learning by Evaluator: \\\"When an order is placed and sufficient inventory is available for the items ordered, the order status should be set to 'Shipped', and the corresponding product inventory counts must be updated to reflect the fulfilled items.`\\\"\n",
            "[RAG Cache] Learning processed. Cache now has 3 entries.\n",
            "[RAG Cache] Successfully persisted 3 active learnings to: /content/drive/My Drive/AI/Knowledgebases/learnings_20250519_165126_973580.json\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): Please ship my most recent order.\n",
            "\\n\\n============================================================\\nUser Message: Please ship my most recent order.\\n============================================================\n",
            "Current Context Summary for Agent:\\nRecent products: ID: P3 (Name: Perplexinator)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Processing)\n",
            "Last action: tool_create_order_Anthropic at 2025-05-19T16:47:34.400769 (Input: {'product_id_or_name': 'Perplexinator', 'quantity': 25, 'status': 'Processing'}, Result Status: success, OrderID: O3)\\n------------------------------------------------------------\n",
            "Relevant Learnings for this turn:\\n\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 9e733076, Time: 2025-05-19T16:51:26.972235): When an order is placed and sufficient inventory is available for the items ordered, the order status should be set to 'Shipped', and the corresponding product inventory counts must be updated to reflect the fulfilled items.`\n",
            "--- Captured Initial Datastore State for Evaluation (Products count: 3) ---\n",
            "\\n--- Getting Anthropic's Response ---\n",
            "Anthropic Tool Call: update_order_status, Input: {'order_id': 'O3', 'new_status': 'Shipped'}, ID: toolu_018x3T3jH6CQmDMWkoFfKU2a\n",
            "--- [Tool Dispatcher] Attempting tool: update_order_status with input: {\"order_id\": \"O3\", \"new_status\": \"Shipped\"} for storage: AnthropicStorage ---\n",
            "[Tool Executed] update_order_status: Order O3 Shipped. Inv for P3 reduced by 25 to 1458 (in Storage).\n",
            "[Tool Executed] update_order_status: Order O3 status updated from Processing to Shipped (in Storage).\n",
            "--- [Tool Dispatcher] Result for update_order_status on AnthropicStorage: {\n",
            "  \"status\": \"success\",\n",
            "  \"message\": \"Order O3 status updated from Processing to Shipped.\",\n",
            "  \"order_id\": \"O3\",\n",
            "  \"product_id\": \"P3\",\n",
            "  \"old_status\": \"Processing\",\n",
            "  \"new_status\": \"Shipped\",\n",
            "  \"inventory_adjusted\": true,\n",
            "  \"current_inventory\": 1458,\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O3\",\n",
            "    \"product_id\": \"P3\",\n",
            "    \"product_name\": \"Perplexinator\",\n",
            "    \"quantity\": 25,\n",
            "    \"price\": 79.99,\n",
            "    \"status\": \"Shipped\"\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_update_order_status_Anthropic, Details: {\"input\": {\"order_id\": \"O3\", \"new_status\": \"Shipped\"}, \"result\": {\"status\": \"success\", \"message\": \"Order O3 status updated from Processing to Shipped.\", \"order_id\": \"O3\", \"product_id\": \"P3\", \"old_status\": \"Processing\", \"new_status\": \"Shipped\", \"inventory_adjusted\": true, \"current_inventory\": 1458, \"order_details\": {\"id\": \"O3\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 25, \"price\": 79.99, \"status\": \"Shipped\"}}}\n",
            "\\n--- Anthropic Final Response Text (Post-Tool/Clarification) ---\\nYour order of 25 Perplexinators has been marked as shipped! The inventory has been automatically adjusted to reflect this change. Is there anything else you need assistance with?\n",
            "--- Captured Final Datastore State for Evaluation (Products count: 3) ---\n",
            "\\n--- Starting Evaluation by Gemini (with Before/After States) ---\n",
            "Gemini Raw Evaluation (using Before/After states):\\nEVALUATION:\n",
            "\n",
            "1.  **Accuracy**:\n",
            "    *   **Textual Response**: The AI's response, \"Your order of 25 Perplexinators has been marked as shipped! The inventory has been automatically adjusted to reflect this change,\" is entirely accurate.\n",
            "        *   The 'Data Store State *Before* AI Action' shows order O3 for \"Perplexinator\" with a quantity of 25 and status \"Processing\".\n",
            "        *   The 'Data Store State *After* AI Action' confirms order O3 status is now \"Shipped\".\n",
            "        *   The 'Data Store State *Before* AI Action' shows product P3 (\"Perplexinator\") had an inventory_count of 1483.\n",
            "        *   The 'Data Store State *After* AI Action' shows product P3 inventory_count is 1458. The difference (1483 - 1458 = 25) correctly reflects the quantity shipped from order O3.\n",
            "    *   **AI's Actions**: The AI's actions correctly modified the datastore as intended and claimed.\n",
            "        *   Order O3 status was updated from \"Processing\" to \"Shipped\".\n",
            "        *   Product P3 (\"Perplexinator\") inventory was updated from 1483 to 1458.\n",
            "    *   **Factual Claims**: All factual claims in the response (product name, quantity, new status, inventory adjustment) are verified by comparing the 'Before' and 'After' data store states.\n",
            "\n",
            "2.  **Efficiency**:\n",
            "    *   The assistant correctly processed the request without asking any clarifying questions.\n",
            "    *   No questions were necessary. The user's query (\"Please ship my most recent order\") combined with the provided context (\"Recent orders: ID: O3 (Product: Perplexinator, Status: Processing)\") and the RAG learning (\"When an order is placed and sufficient inventory is available...the order status should be set to 'Shipped', and the...product inventory counts must be updated\") provided all necessary information. The AI correctly identified order O3, checked inventory for P3 (1483 > 25), and proceeded with the shipping process.\n",
            "    *   The implicit tool calls (to update order status and product inventory) were appropriate and necessary to fulfill the request.\n",
            "\n",
            "3.  **Context Awareness**:\n",
            "    *   The assistant correctly used the conversation context. It identified \"my most recent order\" as O3 from the \"Recent orders\" information.\n",
            "    *   It correctly applied the RAG learning by checking inventory (P3 inventory 1483 was sufficient for 25 units), changing the order status to \"Shipped,\" and updating the product inventory.\n",
            "    *   The assistant correctly understood the user's intent to have order O3 shipped.\n",
            "\n",
            "4.  **Helpfulness**:\n",
            "    *   The assistant fully addressed the user's needs. The order was successfully marked as shipped, and the inventory was correctly updated.\n",
            "    *   The response was clear, concise, and provided all relevant information about the outcome of the request (confirmation of shipping and inventory adjustment).\n",
            "    *   The offer of further assistance (\"Is there anything else you need assistance with?\") is a good customer service practice.\n",
            "\n",
            "**Scores**:\n",
            "*   **Accuracy**: 10/10\n",
            "*   **Efficiency**: 10/10\n",
            "*   **Context Awareness**: 10/10\n",
            "*   **Helpfulness**: 10/10\n",
            "\n",
            "**Overall Score**: 10/10\n",
            "\n",
            "**Reasoning for Overall Score**:\n",
            "The AI assistant performed impeccably. It accurately interpreted the user's request, leveraged the provided context and RAG learnings effectively, and executed the necessary actions correctly in the datastore. The textual response was accurate, clear, and confirmed the actions taken. No unnecessary clarifications were asked, leading to an efficient interaction. The changes between the 'Data Store State *Before* AI Action' and 'Data Store State *After* AI Action' perfectly align with the AI's response and the user's request.\n",
            "Could not extract score for 'Anthropic' from eval text. Review eval output. Defaulting to 0.\n",
            "Do you want to add any general learnings from this turn? (Type your learning or 'skip'): skip\n",
            "[INFO] Skipping the addition of general learnings for this turn.\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): How many Perplexinators are now left in stock?\n",
            "\\n\\n============================================================\\nUser Message: How many Perplexinators are now left in stock?\\n============================================================\n",
            "Current Context Summary for Agent:\\nRecent products: ID: P3 (Name: Perplexinator)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Shipped)\n",
            "Last action: tool_update_order_status_Anthropic at 2025-05-19T16:52:27.839471 (Input: {'order_id': 'O3', 'new_status': 'Shipped'}, Result Status: success, OrderID: O3)\\n------------------------------------------------------------\n",
            "Relevant Learnings for this turn:\\n\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 9e733076, Time: 2025-05-19T16:51:26.972235): When an order is placed and sufficient inventory is available for the items ordered, the order status should be set to 'Shipped', and the corresponding product inventory counts must be updated to reflect the fulfilled items.`\n",
            "--- Captured Initial Datastore State for Evaluation (Products count: 3) ---\n",
            "\\n--- Getting Anthropic's Response ---\n",
            "Anthropic Tool Call: get_product_info, Input: {'product_id_or_name': 'Perplexinator'}, ID: toolu_01FHo9L5W3WDuT93NrvUUu3d\n",
            "--- [Tool Dispatcher] Attempting tool: get_product_info with input: {\"product_id_or_name\": \"Perplexinator\"} for storage: AnthropicStorage ---\n",
            "[Tool Helper] find_product_by_name: Matched 'Perplexinator' to 'Perplexinator' (ID: P3) with score 100 (in Storage)\n",
            "[Tool Executed] get_product_info: Found by name (fuzzy) 'Perplexinator' as ID 'P3' (in Storage).\n",
            "--- [Tool Dispatcher] Result for get_product_info on AnthropicStorage: {\n",
            "  \"status\": \"success\",\n",
            "  \"message\": \"Found product matching 'Perplexinator'\",\n",
            "  \"product_id\": \"P3\",\n",
            "  \"product\": {\n",
            "    \"name\": \"Perplexinator\",\n",
            "    \"description\": \"A perplexing perfunctator\",\n",
            "    \"price\": 79.99,\n",
            "    \"inventory_count\": 1458\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: products, ID: P3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_get_product_info_Anthropic, Details: {\"input\": {\"product_id_or_name\": \"Perplexinator\"}, \"result\": {\"status\": \"success\", \"message\": \"Found product matching 'Perplexinator'\", \"product_id\": \"P3\", \"product\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1458}}}\n",
            "\\n--- Anthropic Final Response Text (Post-Tool/Clarification) ---\\nThere are currently 1,458 Perplexinators in stock. Is there anything else you'd like to know?\n",
            "--- Captured Final Datastore State for Evaluation (Products count: 3) ---\n",
            "\\n--- Starting Evaluation by Gemini (with Before/After States) ---\n",
            "Gemini Raw Evaluation (using Before/After states):\\n## Evaluation of AI Assistant Response\n",
            "\n",
            "**1. Accuracy:**\n",
            "    *   **Textual Response Accuracy**: Score: 10/10\n",
            "        *   The AI assistant responded, \"There are currently 1,458 Perplexinators in stock.\"\n",
            "        *   Referring to the 'Data Store State *Before* AI Action', the product P3 (\"Perplexinator\") has an `inventory_count` of 1458.\n",
            "        *   The AI's statement is factually correct based on the provided data.\n",
            "    *   **Actions Accuracy**: Score: 10/10\n",
            "        *   The AI assistant did not perform any tool calls. This is appropriate as the user's query was a request for information already available in the data store.\n",
            "        *   The 'Data Store State *After* AI Action' shows no changes compared to the 'Data Store State *Before* AI Action', which is correct as no data modification actions were taken or required.\n",
            "        *   The RAG learning states: \"When an order is placed and sufficient inventory is available for the items ordered, the order status should be set to 'Shipped', and the corresponding product inventory counts must be updated to reflect the fulfilled items.\" The \"Last action\" was setting order O3 (25 units of Perplexinator) to 'Shipped'. The 'Data Store State *Before* AI Action' (which is the ground truth for the AI's current turn) reflects an inventory of 1458 for Perplexinators *after* this shipment. Assuming the system correctly applied the RAG learning during that \"Last action\", the 1458 figure is the already updated inventory. The AI correctly reported this figure.\n",
            "\n",
            "**2. Efficiency:**\n",
            "    *   Score: 10/10\n",
            "    *   The AI assistant did not ask any clarifying questions. None were necessary as the query was specific (\"Perplexinators\") and the information was directly available in the 'Data Store State *Before* AI Action'.\n",
            "    *   The AI directly answered the query without unnecessary steps or tool calls.\n",
            "\n",
            "**3. Context Awareness:**\n",
            "    *   Score: 10/10\n",
            "    *   The AI correctly identified \"Perplexinators\" from the user's query and linked it to product P3.\n",
            "    *   It correctly used the `inventory_count` from the 'Data Store State *Before* AI Action' to answer the question.\n",
            "    *   The AI implicitly understood that the \"Last action\" (shipping O3) and the RAG learning about inventory updates meant the current inventory count in the data store should be the value to report.\n",
            "\n",
            "**4. Helpfulness:**\n",
            "    *   Score: 10/10\n",
            "    *   The AI's response directly and accurately answered the user's query.\n",
            "    *   The response was clear and concise. It also offered further assistance (\"Is there anything else you'd like to know?\"), which is a good customer service practice.\n",
            "\n",
            "**Overall Score:** 10/10\n",
            "\n",
            "**Reasoning for Overall Score:**\n",
            "The AI assistant performed excellently.\n",
            "*   **Accuracy**: It provided a factually correct inventory count based on the 'Data Store State *Before* AI Action'. No actions were taken, which was appropriate, and thus the 'Data Store State *After* AI Action' correctly reflected no changes. The response is consistent with the assumption that the prior \"Shipped\" action for order O3 had already resulted in the inventory being updated to 1458, as per the RAG learning.\n",
            "*   **Efficiency**: It answered directly without any unnecessary questions or tool calls.\n",
            "*   **Context Awareness**: It correctly understood the query and used the provided data store information effectively.\n",
            "*   **Helpfulness**: It provided a clear, direct, and helpful answer to the user's question.\n",
            "\n",
            "The AI correctly reported the current stock level as presented in the \"Initial Ground Truth\". It did not need to perform calculations or modifications, as the query was purely informational.\n",
            "Could not extract score for 'Anthropic' from eval text. Review eval output. Defaulting to 0.\n",
            "Do you want to add any general learnings from this turn? (Type your learning or 'skip'): skip\n",
            "[INFO] Skipping the addition of general learnings for this turn.\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): Add a new customer: Bill Leece, bill.leece@mail.com, +1.222.333.4444\n",
            "\\n\\n============================================================\\nUser Message: Add a new customer: Bill Leece, bill.leece@mail.com, +1.222.333.4444\\n============================================================\n",
            "Current Context Summary for Agent:\\nRecent products: ID: P3 (Name: Perplexinator)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Shipped)\n",
            "Last action: tool_get_product_info_Anthropic at 2025-05-19T16:54:27.377662 (Input: {'product_id_or_name': 'Perplexinator'}, Result Status: success, ProductID: P3)\\n------------------------------------------------------------\n",
            "Relevant Learnings for this turn:\\n\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 9e733076, Time: 2025-05-19T16:51:26.972235): When an order is placed and sufficient inventory is available for the items ordered, the order status should be set to 'Shipped', and the corresponding product inventory counts must be updated to reflect the fulfilled items.`\n",
            "--- Captured Initial Datastore State for Evaluation (Products count: 3) ---\n",
            "\\n--- Getting Anthropic's Response ---\n",
            "Anthropic Tool Call: create_customer, Input: {'name': 'Bill Leece', 'email': 'bill.leece@mail.com', 'phone': '+1.222.333.4444'}, ID: toolu_01RBRWXqt2M7NicCHb7hUAzx\n",
            "--- [Tool Dispatcher] Attempting tool: create_customer with input: {\"name\": \"Bill Leece\", \"email\": \"bill.leece@mail.com\", \"phone\": \"+1.222.333.4444\"} for storage: AnthropicStorage ---\n",
            "[Tool Executed] create_customer: ID C3, Name: Bill Leece (in Storage)\n",
            "--- [Tool Dispatcher] Result for create_customer on AnthropicStorage: {\n",
            "  \"status\": \"success\",\n",
            "  \"customer_id\": \"C3\",\n",
            "  \"customer\": {\n",
            "    \"name\": \"Bill Leece\",\n",
            "    \"email\": \"bill.leece@mail.com\",\n",
            "    \"phone\": \"+1.222.333.4444\"\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: customers, ID: C3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_create_customer_Anthropic, Details: {\"input\": {\"name\": \"Bill Leece\", \"email\": \"bill.leece@mail.com\", \"phone\": \"+1.222.333.4444\"}, \"result\": {\"status\": \"success\", \"customer_id\": \"C3\", \"customer\": {\"name\": \"Bill Leece\", \"email\": \"bill.leece@mail.com\", \"phone\": \"+1.222.333.4444\"}}}\n",
            "\\n--- Anthropic Final Response Text (Post-Tool/Clarification) ---\\nI've successfully created a customer account for Bill Leece. Here are the details:\n",
            "- Customer ID: C3\n",
            "- Name: Bill Leece\n",
            "- Email: bill.leece@mail.com\n",
            "- Phone: +1.222.333.4444\n",
            "\n",
            "Is there anything else you'd like me to help you with?\n",
            "--- Captured Final Datastore State for Evaluation (Products count: 3) ---\n",
            "\\n--- Starting Evaluation by Gemini (with Before/After States) ---\n",
            "Gemini Raw Evaluation (using Before/After states):\\n## Evaluation of AI Assistant Response\n",
            "\n",
            "**1. Accuracy:**\n",
            "    *   **Textual Response:** The AI's textual response is highly accurate. It correctly states that a customer account for \"Bill Leece\" was created and provides the correct details: Customer ID \"C3\", Name \"Bill Leece\", Email \"bill.leece@mail.com\", and Phone \"+1.222.333.4444\".\n",
            "    *   **Actions (Tool Calls):** The AI's action (implicitly, an `add_customer` tool call) correctly modified the datastore.\n",
            "        *   **'Data Store State *Before* AI Action'**: The `customers` table contained C1 (John Doe) and C2 (Jane Smith).\n",
            "        *   **'Data Store State *After* AI Action'**: The `customers` table now includes C3 with the details: `{\"name\": \"Bill Leece\", \"email\": \"bill.leece@mail.com\", \"phone\": \"+1.222.333.4444\"}`.\n",
            "        *   The new customer ID \"C3\" is consistent with the next available ID.\n",
            "    *   All factual claims in the AI's response are verified by the 'Data Store State *After* AI Action'.\n",
            "\n",
            "    **Score: 10/10**\n",
            "\n",
            "**2. Efficiency:**\n",
            "    *   The assistant processed the request and performed the correct action without asking any clarifying questions.\n",
            "    *   No clarification questions were necessary as the user's query provided all the required information (name, email, phone number) to create a new customer.\n",
            "    *   The AI used its tools appropriately and directly.\n",
            "\n",
            "    **Score: 10/10**\n",
            "\n",
            "**3. Context Awareness:**\n",
            "    *   The AI correctly understood the user's intent to \"Add a new customer\" and extracted all necessary information from the query.\n",
            "    *   The provided conversation context (recent products, orders, last action) was not directly relevant to this specific request, and the AI appropriately focused on the current task without being sidetracked.\n",
            "\n",
            "    **Score: 10/10**\n",
            "\n",
            "**4. Helpfulness:**\n",
            "    *   The assistant fully addressed the user's request by successfully adding the new customer to the system.\n",
            "    *   The response was clear, provided all relevant information (confirmation, new customer ID, and details), and proactively asked if further assistance was needed. This is very helpful for the user.\n",
            "\n",
            "    **Score: 10/10**\n",
            "\n",
            "**Overall Score:**\n",
            "    **Score: 10/10**\n",
            "\n",
            "**Reasoning for Overall Score:**\n",
            "The AI assistant performed excellently.\n",
            "*   **Accuracy:** It accurately processed the user's request, correctly updated the data store by adding the new customer with the specified details (as confirmed by comparing the 'Before' and 'After' states), and provided a factually correct confirmation, including the new customer ID (C3).\n",
            "*   **Efficiency:** It achieved this without any unnecessary interactions or clarifying questions, as all required information was present in the initial query.\n",
            "*   **Context Awareness:** It correctly interpreted the user's intent from the current query.\n",
            "*   **Helpfulness:** The response was clear, confirmed the action, provided all necessary details (including the new customer ID), and offered further help.\n",
            "\n",
            "The 'Data Store State *After* AI Action' perfectly reflects the successful execution of the user's request and matches the AI's textual response.\n",
            "Could not extract score for 'Anthropic' from eval text. Review eval output. Defaulting to 0.\n",
            "Do you want to add any general learnings from this turn? (Type your learning or 'skip'): skip\n",
            "[INFO] Skipping the addition of general learnings for this turn.\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): Add new new product: Gizmo X, description: A fancy gizmo, price: 29.99, inventory: 50\n",
            "\\n\\n============================================================\\nUser Message: Add new new product: Gizmo X, description: A fancy gizmo, price: 29.99, inventory: 50\\n============================================================\n",
            "Current Context Summary for Agent:\\nRecent customers: ID: C3 (Name: Bill Leece)\n",
            "Recent products: ID: P3 (Name: Perplexinator)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Shipped)\n",
            "Last action: tool_create_customer_Anthropic at 2025-05-19T16:58:19.126945 (Input: {'name': 'Bill Leece', 'email': 'bill.leece@mail.com', 'phone': '+1.222.333.4444'}, Result Status: success)\\n------------------------------------------------------------\n",
            "Relevant Learnings for this turn:\\n\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 9e733076, Time: 2025-05-19T16:51:26.972235): When an order is placed and sufficient inventory is available for the items ordered, the order status should be set to 'Shipped', and the corresponding product inventory counts must be updated to reflect the fulfilled items.`\n",
            "--- Captured Initial Datastore State for Evaluation (Products count: 3) ---\n",
            "\\n--- Getting Anthropic's Response ---\n",
            "Anthropic Tool Call: create_product, Input: {'name': 'Gizmo X', 'description': 'A fancy gizmo', 'price': 29.99, 'inventory_count': 50}, ID: toolu_01XgE7jC1NNMjcDPnhdP14qX\n",
            "--- [Tool Dispatcher] Attempting tool: create_product with input: {\"name\": \"Gizmo X\", \"description\": \"A fancy gizmo\", \"price\": 29.99, \"inventory_count\": 50} for storage: AnthropicStorage ---\n",
            "[Tool Executed] create_product: ID P4, Name: Gizmo X (in Storage)\n",
            "--- [Tool Dispatcher] Result for create_product on AnthropicStorage: {\n",
            "  \"status\": \"success\",\n",
            "  \"product_id\": \"P4\",\n",
            "  \"product\": {\n",
            "    \"name\": \"Gizmo X\",\n",
            "    \"description\": \"A fancy gizmo\",\n",
            "    \"price\": 29.99,\n",
            "    \"inventory_count\": 50\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: products, ID: P4, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_create_product_Anthropic, Details: {\"input\": {\"name\": \"Gizmo X\", \"description\": \"A fancy gizmo\", \"price\": 29.99, \"inventory_count\": 50}, \"result\": {\"status\": \"success\", \"product_id\": \"P4\", \"product\": {\"name\": \"Gizmo X\", \"description\": \"A fancy gizmo\", \"price\": 29.99, \"inventory_count\": 50}}}\n",
            "\\n--- Anthropic Final Response Text (Post-Tool/Clarification) ---\\nThe product has been successfully added to the system! Here are the details:\n",
            "- Product ID: P4\n",
            "- Name: Gizmo X\n",
            "- Description: A fancy gizmo\n",
            "- Price: $29.99\n",
            "- Initial inventory: 50 units\n",
            "\n",
            "Is there anything else you'd like me to help you with?\n",
            "--- Captured Final Datastore State for Evaluation (Products count: 4) ---\n",
            "\\n--- Starting Evaluation by Gemini (with Before/After States) ---\n",
            "Gemini Raw Evaluation (using Before/After states):\\n## Evaluation of AI Assistant Response\n",
            "\n",
            "**1. Accuracy:**\n",
            "*   **Textual Response:** The AI's textual response is entirely accurate. It correctly states the product ID as P4, name as \"Gizmo X\", description as \"A fancy gizmo\", price as $29.99, and initial inventory as 50 units.\n",
            "*   **Actions (Tool Calls):** The AI's actions correctly modified the datastore.\n",
            "    *   The 'Data Store State *Before* AI Action' shows existing products P1, P2, and P3.\n",
            "    *   The 'Data Store State *After* AI Action' shows a new product, P4, has been added to the `products` table:\n",
            "        ```json\n",
            "        \"P4\": {\n",
            "          \"name\": \"Gizmo X\",\n",
            "          \"description\": \"A fancy gizmo\",\n",
            "          \"price\": 29.99,\n",
            "          \"inventory_count\": 50\n",
            "        }\n",
            "        ```\n",
            "    *   This matches exactly what the user requested and what the AI claimed in its response. The new entity P4 was created with the correct ID and values.\n",
            "\n",
            "**Score: 10/10**\n",
            "\n",
            "**2. Efficiency:**\n",
            "*   The assistant did not ask any clarifying questions.\n",
            "*   All necessary information (product name, description, price, inventory) was provided in the user's initial query.\n",
            "*   The AI directly proceeded to create the product, which was the most efficient path.\n",
            "\n",
            "**Score: 10/10**\n",
            "\n",
            "**3. Context Awareness:**\n",
            "*   The AI correctly understood the user's intent to \"Add new new product\" despite the slight repetition of \"new\".\n",
            "*   It successfully parsed all the provided parameters for the new product from the single user query.\n",
            "*   The RAG learnings and recent context were not directly relevant to this specific task of adding a product, and the AI appropriately did not attempt to use them.\n",
            "\n",
            "**Score: 10/10**\n",
            "\n",
            "**4. Helpfulness:**\n",
            "*   The assistant fully addressed the user's need by successfully adding the new product.\n",
            "*   The response was clear, concise, and provided all relevant information about the newly created product, including its system-assigned ID (P4).\n",
            "*   The offer for further assistance (\"Is there anything else you'd like me to help you with?\") is a good practice.\n",
            "\n",
            "**Score: 10/10**\n",
            "\n",
            "**Overall Score:** **10/10**\n",
            "\n",
            "**Reasoning for Overall Score:**\n",
            "The AI assistant performed flawlessly. It accurately understood the user's request, extracted all necessary information, and correctly executed the action of adding a new product. The 'Data Store State *After* AI Action' confirms the successful and accurate creation of product P4 with all the specified details. The textual response was clear, accurate, and helpful, confirming the action and providing the new product's ID. No unnecessary questions were asked, leading to an efficient interaction.\n",
            "Could not extract score for 'Anthropic' from eval text. Review eval output. Defaulting to 0.\n",
            "Do you want to add any general learnings from this turn? (Type your learning or 'skip'): skip\n",
            "[INFO] Skipping the addition of general learnings for this turn.\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): Update Gizzmo's price to 99.99\n",
            "\\n\\n============================================================\\nUser Message: Update Gizzmo's price to 99.99\\n============================================================\n",
            "Current Context Summary for Agent:\\nRecent customers: ID: C3 (Name: Bill Leece)\n",
            "Recent products: ID: P3 (Name: Perplexinator), ID: P4 (Name: Gizmo X)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Shipped)\n",
            "Last action: tool_create_product_Anthropic at 2025-05-19T17:01:11.288186 (Input: {'name': 'Gizmo X', 'description': 'A fancy gizmo', 'price': 29.99, 'inventory_count': 50}, Result Status: success, ProductID: P4)\\n------------------------------------------------------------\n",
            "Relevant Learnings for this turn:\\n\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 9e733076, Time: 2025-05-19T16:51:26.972235): When an order is placed and sufficient inventory is available for the items ordered, the order status should be set to 'Shipped', and the corresponding product inventory counts must be updated to reflect the fulfilled items.`\n",
            "--- Captured Initial Datastore State for Evaluation (Products count: 4) ---\n",
            "\\n--- Getting Anthropic's Response ---\n",
            "Anthropic Tool Call: update_product, Input: {'product_id': 'P4', 'price': 99.99}, ID: toolu_012VWPwWrEovnqwUUBE6vq2L\n",
            "--- [Tool Dispatcher] Attempting tool: update_product with input: {\"product_id\": \"P4\", \"price\": 99.99} for storage: AnthropicStorage ---\n",
            "[Tool Executed] update_product: ID P4, Updated fields: price (in Storage)\n",
            "--- [Tool Dispatcher] Result for update_product on AnthropicStorage: {\n",
            "  \"status\": \"success\",\n",
            "  \"message\": \"Product P4 updated. Fields: price\",\n",
            "  \"product_id\": \"P4\",\n",
            "  \"updated_fields\": [\n",
            "    \"price\"\n",
            "  ],\n",
            "  \"product\": {\n",
            "    \"name\": \"Gizmo X\",\n",
            "    \"description\": \"A fancy gizmo\",\n",
            "    \"price\": 99.99,\n",
            "    \"inventory_count\": 50\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: products, ID: P4, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_update_product_Anthropic, Details: {\"input\": {\"product_id\": \"P4\", \"price\": 99.99}, \"result\": {\"status\": \"success\", \"message\": \"Product P4 updated. Fields: price\", \"product_id\": \"P4\", \"updated_fields\": [\"price\"], \"product\": {\"name\": \"Gizmo X\", \"description\": \"A fancy gizmo\", \"price\": 99.99, \"inventory_count\": 50}}}\n",
            "\\n--- Anthropic Final Response Text (Post-Tool/Clarification) ---\\nI've updated the price for Gizmo X from $29.99 to $99.99. All other product details remain unchanged. Is there anything else you'd like me to help you with?\n",
            "--- Captured Final Datastore State for Evaluation (Products count: 4) ---\n",
            "\\n--- Starting Evaluation by Gemini (with Before/After States) ---\n",
            "Gemini Raw Evaluation (using Before/After states):\\n## Evaluation of AI Assistant's Response\n",
            "\n",
            "**Overall Score:** 10/10\n",
            "\n",
            "**1. Accuracy:**\n",
            "*   **Score:** 10/10\n",
            "*   **Reasoning:** The AI's textual response is entirely accurate.\n",
            "    *   It correctly identified the product \"Gizmo X\" (P4) despite the user's slight misspelling \"Gizzmo\".\n",
            "    *   It accurately stated the original price was $29.99, which is confirmed by the 'Data Store State *Before* AI Action' for product P4 (`\"price\": 29.99`).\n",
            "    *   It accurately stated the new price is $99.99.\n",
            "    *   The AI's action to update the price was correctly performed. The 'Data Store State *After* AI Action' shows product P4 (\"Gizmo X\") with `\"price\": 99.99`.\n",
            "    *   The claim \"All other product details remain unchanged\" is also correct. Comparing P4 in the 'Before' and 'After' states, the `description` (\"A fancy gizmo\") and `inventory_count` (50) remained the same.\n",
            "\n",
            "**2. Efficiency:**\n",
            "*   **Score:** 10/10\n",
            "*   **Reasoning:** The assistant was highly efficient.\n",
            "    *   It did not ask any clarifying questions. A question about \"Gizzmo\" vs. \"Gizmo X\" was not strictly necessary because \"Gizmo X\" was in the \"Recent products\" context, making it a very strong candidate, and the AI confirmed the full name in its response.\n",
            "    *   It directly proceeded to the correct action (updating the product price).\n",
            "    *   The tool call `tool_update_product` (inferred, as the price was changed) was appropriate and necessary.\n",
            "\n",
            "**3. Context Awareness:**\n",
            "*   **Score:** 10/10\n",
            "*   **Reasoning:** The AI demonstrated excellent context awareness.\n",
            "    *   It correctly used the \"Recent products\" context, which listed \"ID: P4 (Name: Gizmo X)\", to infer that the user's \"Gizzmo\" referred to \"Gizmo X\".\n",
            "    *   It implicitly used the 'Data Store State *Before* AI Action' to fetch the original price of \"Gizmo X\" ($29.99) to include in its confirmation message.\n",
            "\n",
            "**4. Helpfulness:**\n",
            "*   **Score:** 10/10\n",
            "*   **Reasoning:** The assistant was very helpful.\n",
            "    *   It successfully fulfilled the user's request to update the product price.\n",
            "    *   The response was clear, concise, and provided all relevant information: confirmation of the product updated (\"Gizmo X\"), the old price, and the new price. This proactive confirmation is excellent.\n",
            "    *   It also politely offered further assistance (\"Is there anything else you'd like me to help you with?\").\n",
            "\n",
            "This was an exemplary interaction, correctly interpreting a slightly ambiguous product name using context and accurately performing the requested update and confirming it clearly.\n",
            "Could not extract score for 'Anthropic' from eval text. Review eval output. Defaulting to 0.\n",
            "Do you want to add any general learnings from this turn? (Type your learning or 'skip'): skip\n",
            "[INFO] Skipping the addition of general learnings for this turn.\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): Who won the 2020 US presidential election?\n",
            "\\n\\n============================================================\\nUser Message: Who won the 2020 US presidential election?\\n============================================================\n",
            "Current Context Summary for Agent:\\nRecent customers: ID: C3 (Name: Bill Leece)\n",
            "Recent products: ID: P3 (Name: Perplexinator), ID: P4 (Name: Gizmo X)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Shipped)\n",
            "Last action: tool_update_product_Anthropic at 2025-05-19T17:04:32.879977 (Input: {'product_id': 'P4', 'price': 99.99}, Result Status: success, ProductID: P4)\\n------------------------------------------------------------\n",
            "Relevant Learnings for this turn:\\n\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 9e733076, Time: 2025-05-19T16:51:26.972235): When an order is placed and sufficient inventory is available for the items ordered, the order status should be set to 'Shipped', and the corresponding product inventory counts must be updated to reflect the fulfilled items.`\n",
            "--- Captured Initial Datastore State for Evaluation (Products count: 4) ---\n",
            "\\n--- Getting Anthropic's Response ---\n",
            "\\n--- Anthropic Final Response Text (Post-Tool/Clarification) ---\\nI apologize, but I am designed to help with e-commerce related tasks such as managing orders, products, and customers. I cannot provide information about political elections or other topics outside of this e-commerce system. \n",
            "\n",
            "I can help you with:\n",
            "- Creating and managing orders\n",
            "- Looking up product information\n",
            "- Adding or updating products\n",
            "- Managing customer information\n",
            "- Checking inventory levels\n",
            "- Updating order statuses\n",
            "\n",
            "Is there something related to these e-commerce functions that I can help you with?\n",
            "--- Captured Final Datastore State for Evaluation (Products count: 4) ---\n",
            "\\n--- Starting Evaluation by Gemini (with Before/After States) ---\n",
            "Gemini Raw Evaluation (using Before/After states):\\nEVALUATION:\n",
            "\n",
            "1.  **Accuracy**:\n",
            "    *   **Textual response**: The AI's textual response is accurate. It correctly states that it is designed for e-commerce tasks and cannot provide information about political elections. It accurately lists the types of e-commerce functions it can perform.\n",
            "    *   **AI's actions**: The AI made no tool calls, which is the correct action for an out-of-scope query. The 'Data Store State *Before* AI Action' and 'Data Store State *After* AI Action' are identical, reflecting that no changes were made to the data store, which is appropriate.\n",
            "\n",
            "2.  **Efficiency**:\n",
            "    *   The assistant correctly identified the query as out-of-scope without asking any clarifying questions. This is efficient.\n",
            "    *   No tool calls were made, which is appropriate and efficient.\n",
            "\n",
            "3.  **Context Awareness**:\n",
            "    *   The assistant correctly understood that the user's query was unrelated to the provided e-commerce context (recent customers, products, orders, RAG learnings). It appropriately recognized its limitations based on its designated role.\n",
            "\n",
            "4.  **Helpfulness**:\n",
            "    *   The assistant was helpful by clearly explaining its limitations and then offering to help with tasks within its scope. This manages user expectations and provides a clear path forward for relevant requests. The list of its capabilities is a helpful guide for the user.\n",
            "\n",
            "**Scores**:\n",
            "*   Accuracy: 10/10\n",
            "*   Efficiency: 10/10\n",
            "*   Context Awareness: 10/10\n",
            "*   Helpfulness: 10/10\n",
            "\n",
            "**Overall Score**: 10/10\n",
            "\n",
            "**Reasoning**:\n",
            "The AI correctly identified that the user's query was outside its designed capabilities. It politely declined to answer the out-of-scope question, explained its purpose, and offered to assist with relevant e-commerce tasks. No actions were taken on the data store, which is correct as confirmed by the identical 'Before' and 'After' states. The response was efficient, contextually aware, and helpful in guiding the user.\n",
            "Could not extract score for 'Anthropic' from eval text. Review eval output. Defaulting to 0.\n",
            "Do you want to add any general learnings from this turn? (Type your learning or 'skip'): This is a good answer. We should only answer relevant questions while politely refusing to answer out of scope questions. Well done! \n",
            "\\n--- Processing New Candidate Learning from Human Feedback: \\\"This is a good answer. We should only answer relevant questions while politely refusing to answer out of scope questions. Well done!\\\" ---\n",
            "\\n[RAG Cache] Evaluator response on learning processing:\\n`FINALIZED_LEARNING:` When faced with questions that fall outside its designated customer service scope (e.g., general knowledge, political topics like \"Who won the 2020 US presidential election?\"), the AI should politely state its inability to answer such queries and offer to assist with relevant customer service issues.\n",
            "\\n✅ Finalized Learning by Evaluator: \\\"` When faced with questions that fall outside its designated customer service scope (e.g., general knowledge, political topics like \"Who won the 2020 US presidential election?\"), the AI should politely state its inability to answer such queries and offer to assist with relevant customer service issues.\\\"\n",
            "[RAG Cache] Learning processed. Cache now has 4 entries.\n",
            "[RAG Cache] Successfully persisted 4 active learnings to: /content/drive/My Drive/AI/Knowledgebases/learnings_20250519_170646_768942.json\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount.\n",
            "\\n\\n============================================================\\nUser Message: I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount.\\n============================================================\n",
            "Current Context Summary for Agent:\\nRecent customers: ID: C3 (Name: Bill Leece)\n",
            "Recent products: ID: P3 (Name: Perplexinator), ID: P4 (Name: Gizmo X)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Shipped)\n",
            "Last action: tool_update_product_Anthropic at 2025-05-19T17:04:32.879977 (Input: {'product_id': 'P4', 'price': 99.99}, Result Status: success, ProductID: P4)\\n------------------------------------------------------------\n",
            "Relevant Learnings for this turn:\\n\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: d903a9cd, Time: 2025-05-19T17:06:46.767503): ` When faced with questions that fall outside its designated customer service scope (e.g., general knowledge, political topics like \"Who won the 2020 US presidential election?\"), the AI should politely state its inability to answer such queries and offer to assist with relevant customer service issues.\\n- Learning (ID: 9e733076, Time: 2025-05-19T16:51:26.972235): When an order is placed and sufficient inventory is available for the items ordered, the order status should be set to 'Shipped', and the corresponding product inventory counts must be updated to reflect the fulfilled items.`\n",
            "--- Captured Initial Datastore State for Evaluation (Products count: 4) ---\n",
            "\\n--- Getting Anthropic's Response ---\n",
            "Anthropic Tool Call: list_all_products, Input: {}, ID: toolu_011BLFYkD1ntTDtPNPLHUNM3\n",
            "--- [Tool Dispatcher] Attempting tool: list_all_products with input: {} for storage: AnthropicStorage ---\n",
            "[Tool Executed] list_all_products: Found 4 products (in Storage).\n",
            "--- [Tool Dispatcher] Result for list_all_products on AnthropicStorage: {\n",
            "  \"status\": \"success\",\n",
            "  \"count\": 4,\n",
            "  \"products\": {\n",
            "    \"P1\": {\n",
            "      \"name\": \"Widget A\",\n",
            "      \"description\": \"A simple widget. Very compact.\",\n",
            "      \"price\": 19.99,\n",
            "      \"inventory_count\": 999\n",
            "    },\n",
            "    \"P2\": {\n",
            "      \"name\": \"Gadget B\",\n",
            "      \"description\": \"A powerful gadget. It spins.\",\n",
            "      \"price\": 49.99,\n",
            "      \"inventory_count\": 200\n",
            "    },\n",
            "    \"P3\": {\n",
            "      \"name\": \"Perplexinator\",\n",
            "      \"description\": \"A perplexing perfunctator\",\n",
            "      \"price\": 79.99,\n",
            "      \"inventory_count\": 1458\n",
            "    },\n",
            "    \"P4\": {\n",
            "      \"name\": \"Gizmo X\",\n",
            "      \"description\": \"A fancy gizmo\",\n",
            "      \"price\": 99.99,\n",
            "      \"inventory_count\": 50\n",
            "    }\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: products, ID: P1, Data (type): <class 'dict'>\n",
            "[Context Updated] Entity: products, ID: P2, Data (type): <class 'dict'>\n",
            "[Context Updated] Entity: products, ID: P3, Data (type): <class 'dict'>\n",
            "[Context Updated] Entity: products, ID: P4, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_list_all_products_Anthropic, Details: {\"input\": {}, \"result\": {\"status\": \"success\", \"count\": 4, \"products\": {\"P1\": {\"name\": \"Widget A\", \"description\": \"A simple widget. Very compact.\", \"price\": 19.99, \"inventory_count\": 999}, \"P2\": {\"name\": \"Gadget B\", \"description\": \"A powerful gadget. It spins.\", \"price\": 49.99, \"inventory_count\": 200}, \"P3\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1458}, \"P4\": {\"name\": \"Gizmo X\", \"description\": \"A fancy gizmo\", \"price\": 99.99, \"inventory_count\": 50}}}}\n",
            "\\n--- Anthropic Final Response Text (Post-Tool/Clarification) ---\\nI'll calculate the total value of all inventory:\n",
            "- Widget A: 999 units × $19.99 = $19,970.01\n",
            "- Gadget B: 200 units × $49.99 = $9,998.00\n",
            "- Perplexinator: 1,458 units × $79.99 = $116,625.42\n",
            "- Gizmo X: 50 units × $99.99 = $4,999.50\n",
            "\n",
            "The total value of all products currently in inventory is $151,592.93.\n",
            "\n",
            "Is there anything else you need to know about our inventory?\n",
            "--- Captured Final Datastore State for Evaluation (Products count: 4) ---\n",
            "\\n--- Starting Evaluation by Gemini (with Before/After States) ---\n",
            "Gemini Raw Evaluation (using Before/After states):\\n## Evaluation of AI Assistant Response\n",
            "\n",
            "**1. Accuracy:**\n",
            "*   **Textual Response:** The AI's textual response is entirely accurate. It correctly identifies all products in the inventory, their respective prices and inventory counts, and calculates the value of each product accurately. The final total inventory value is also calculated correctly.\n",
            "    *   Widget A: 999 units × $19.99 = $19,970.01 (Correct based on 'Before' state)\n",
            "    *   Gadget B: 200 units × $49.99 = $9,998.00 (Correct based on 'Before' state)\n",
            "    *   Perplexinator: 1,458 units × $79.99 = $116,625.42 (Correct based on 'Before' state)\n",
            "    *   Gizmo X: 50 units × $99.99 = $4,999.50 (Correct based on 'Before' state)\n",
            "    *   Total: $19,970.01 + $9,998.00 + $116,625.42 + $4,999.50 = $151,592.93 (Correct)\n",
            "*   **AI Actions & Data Store:** The AI correctly understood that this was an informational query and did not attempt any tool calls or modifications to the datastore. The 'Data Store State *Before* AI Action' and 'Data Store State *After* AI Action' are identical, which is the correct outcome for this user request.\n",
            "\n",
            "**Score: 10/10**\n",
            "\n",
            "**2. Efficiency:**\n",
            "*   The assistant answered the query directly and correctly without asking any clarification questions.\n",
            "*   No clarification questions were necessary, as all required information (product names, prices, inventory counts) was available in the 'Data Store State *Before* AI Action'.\n",
            "*   No tool calls were made, which is appropriate as the AI could derive the answer from the provided data state.\n",
            "\n",
            "**Score: 10/10**\n",
            "\n",
            "**3. Context Awareness:**\n",
            "*   The AI correctly understood the user's intent to get the total value of *all* products in inventory.\n",
            "*   It utilized the information from the 'products' section of the 'Data Store State *Before* AI Action' appropriately.\n",
            "*   The recent context and RAG learnings were not directly applicable to this specific calculation task, and the AI correctly did not try to force their use.\n",
            "\n",
            "**Score: 10/10**\n",
            "\n",
            "**4. Helpfulness:**\n",
            "*   The assistant fully addressed the user's need by providing the total inventory value.\n",
            "*   The response was clear, well-structured, and provided a breakdown of the calculation for each product, which enhances transparency and allows the user to verify the amounts.\n",
            "*   The concluding question, \"Is there anything else you need to know about our inventory?\", is a good way to offer further assistance.\n",
            "\n",
            "**Score: 10/10**\n",
            "\n",
            "**Overall Score: 10/10**\n",
            "\n",
            "**Reasoning for Overall Score:**\n",
            "The AI assistant performed excellently on all criteria. It accurately calculated and presented the requested information, did so efficiently without unnecessary interactions, correctly used the available data, and provided a helpful, clear response. The data store state remained unchanged, which is correct for this informational query.\n",
            "Extracted score 10 for 'Anthropic' (or generic) using pattern: Overall Score[:\\s]*(\\d+)(?:/10)?\n",
            "Do you want to add any general learnings from this turn? (Type your learning or 'skip'): skip\n",
            "[INFO] Skipping the addition of general learnings for this turn.\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): Summarize your learnings from our recent interactions.\n",
            "\\n\\n============================================================\\nUser Message: Summarize your learnings from our recent interactions.\\n============================================================\n",
            "Current Context Summary for Agent:\\nRecent customers: ID: C3 (Name: Bill Leece)\n",
            "Recent products: ID: P3 (Name: Perplexinator), ID: P4 (Name: Gizmo X), ID: P1 (Name: Widget A), ID: P2 (Name: Gadget B)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Shipped)\n",
            "Last action: tool_list_all_products_Anthropic at 2025-05-19T17:07:03.836800 (Input: {}, Result Status: success)\\n------------------------------------------------------------\n",
            "Relevant Learnings for this turn:\\n\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: d903a9cd, Time: 2025-05-19T17:06:46.767503): ` When faced with questions that fall outside its designated customer service scope (e.g., general knowledge, political topics like \"Who won the 2020 US presidential election?\"), the AI should politely state its inability to answer such queries and offer to assist with relevant customer service issues.\\n- Learning (ID: 9e733076, Time: 2025-05-19T16:51:26.972235): When an order is placed and sufficient inventory is available for the items ordered, the order status should be set to 'Shipped', and the corresponding product inventory counts must be updated to reflect the fulfilled items.`\n",
            "--- Captured Initial Datastore State for Evaluation (Products count: 4) ---\n",
            "\\n--- Getting Anthropic's Response ---\n",
            "\\n--- Anthropic Final Response Text (Post-Tool/Clarification) ---\\nBased on our recent interactions, I've learned:\n",
            "\n",
            "1. Order and Inventory Management:\n",
            "- Successfully processed and shipped an order for 25 Perplexinators\n",
            "- The Perplexinator inventory was automatically adjusted after shipping\n",
            "- Current inventory stands at 1,458 units\n",
            "\n",
            "2. Customer Management:\n",
            "- Added a new customer (Bill Leece) with complete contact details:\n",
            "  * Email: bill.leece@mail.com\n",
            "  * Phone: +1.222.333.4444\n",
            "\n",
            "3. Product Management:\n",
            "- Added a new product (Gizmo X):\n",
            "  * Initial price: $29.99\n",
            "  * Later updated price to $99.99\n",
            "  * Initial inventory: 50 units\n",
            "  * Description: A fancy gizmo\n",
            "\n",
            "4. Inventory Value:\n",
            "- Calculated total inventory value across all products: $151,592.93\n",
            "- Breakdown includes all four products (Widget A, Gadget B, Perplexinator, Gizmo X)\n",
            "\n",
            "5. System Boundaries:\n",
            "- Demonstrated clear understanding of scope limitations by declining to answer questions about political elections\n",
            "- Maintained focus on e-commerce related tasks and functions\n",
            "\n",
            "Would you like me to elaborate on any of these points?\n",
            "--- Captured Final Datastore State for Evaluation (Products count: 4) ---\n",
            "\\n--- Starting Evaluation by Gemini (with Before/After States) ---\n",
            "Gemini Raw Evaluation (using Before/After states):\\n## Evaluation of AI Assistant Response\n",
            "\n",
            "**1. Accuracy:**\n",
            "    *   **Textual Response Accuracy**:\n",
            "        *   **Order/Inventory (Perplexinator)**:\n",
            "            *   \"Successfully processed and shipped an order for 25 Perplexinators\": The 'Data Store State *Before* AI Action' shows order O3 (Perplexinator, 25 units) was *already* 'Shipped'. While this might have been a \"recent interaction\" topic, the AI phrasing implies it performed this action, which is not substantiated for the current scope of \"learnings.\"\n",
            "            *   \"The Perplexinator inventory was automatically adjusted after shipping\": Related to the above, the inventory for P3 (Perplexinator) is 1458 in both 'Before' and 'After' states. This statement describes a general process (from RAG learning 9e733076) rather than a specific recent adjustment made by the AI that it \"learned\" from.\n",
            "            *   \"Current inventory stands at 1,458 units\": This is factually correct as per the 'Before' state.\n",
            "        *   **Customer Management (Bill Leece)**:\n",
            "            *   \"Added a new customer (Bill Leece)\": Customer C3 (Bill Leece) already exists in the 'Before' state. The AI did not \"add\" this customer in a way that would be a \"learning\" from a recent action; it's recalling existing data.\n",
            "            *   Contact details are correct as per the 'Before' state.\n",
            "        *   **Product Management (Gizmo X)**:\n",
            "            *   \"Added a new product (Gizmo X)\": Product P4 (Gizmo X) already exists in the 'Before' state. Similar to the customer, the AI is presenting existing data as a recent addition it performed.\n",
            "            *   \"Initial price: $29.99\": This is incorrect. The 'Before' state for P4 shows the price as $99.99. There is no information in the provided context or data store to support an initial price of $29.99.\n",
            "            *   \"Later updated price to $99.99\": This claim is based on the incorrect initial price. The price was already $99.99 in the 'Before' state.\n",
            "            *   \"Initial inventory: 50 units\" and \"Description: A fancy gizmo\": These are factually correct as per the 'Before' state, though \"initial\" is misleading when claiming to have \"added\" the product.\n",
            "        *   **Inventory Value**:\n",
            "            *   \"Calculated total inventory value across all products: $151,592.93\": This calculation is correct based on the product prices and inventory counts in the 'Before' state (P1: 19.99\\*999=19970.01; P2: 49.99\\*200=9998.00; P3: 79.99\\*1458=116625.42; P4: 99.99\\*50=4999.50. Total = 151592.93). This could be a valid \"learning\" if the AI performed this calculation in a recent interaction.\n",
            "        *   **System Boundaries**:\n",
            "            *   \"Demonstrated clear understanding of scope limitations...\": This accurately reflects RAG learning d903a9cd. This is a valid \"learning.\"\n",
            "    *   **Actions (Tool Calls) Accuracy**: No tool calls were made in this turn. The 'Data Store State *Before* AI Action' and 'Data Store State *After* AI Action' are identical, which is appropriate for a summarization request.\n",
            "\n",
            "    *Score: 3/10* (Significant factual inaccuracies regarding Gizmo X price, and misrepresentation of existing data as recent actions/learnings. Some parts are correct, like the RAG summary and inventory value.)\n",
            "\n",
            "**2. Efficiency:**\n",
            "    *   The AI did not ask any clarification questions, proceeding directly to the summary.\n",
            "    *   However, the summary provided is not an efficient or accurate representation of \"learnings from recent interactions\" as it largely recounts pre-existing states as if they were recent discoveries or actions by the AI, and includes factual errors.\n",
            "    *Score: 6/10* (No unnecessary questions, but the answer itself is flawed in addressing the specific nuance of \"learnings from interactions\".)\n",
            "\n",
            "**3. Context Awareness:**\n",
            "    *   The AI correctly identified and summarized the RAG learnings provided (d903a9cd and implicitly 9e733076, though the application of the latter to O3 was misleading).\n",
            "    *   It used the \"Recent customers,\" \"Recent products,\" and \"Recent orders\" from the context. However, it misinterpreted their presence as evidence that the AI *itself* recently created or modified them, rather than them being topics of recent discussion or focus. For example, it states it \"Added\" Bill Leece and Gizmo X, when they were already in the 'Before' data store.\n",
            "    *Score: 5/10* (Good use of RAG, but misinterpretation of the significance of entities listed in \"recent\" context.)\n",
            "\n",
            "**4. Helpfulness:**\n",
            "    *   The response is only partially helpful. While it provides some correct factual data (e.g., Perplexinator inventory, Bill Leece's contact info, total inventory value, RAG learning summary), it misleads the user by:\n",
            "        *   Framing pre-existing data as recent actions or learnings by the AI (e.g., \"added\" customer/product, \"processed and shipped\" an already shipped order).\n",
            "        *   Providing incorrect information (the Gizmo X price history).\n",
            "    *   The user asked to \"Summarize your learnings from our recent interactions.\" A more accurate response would differentiate between information recalled, actions performed, and new procedural knowledge acquired.\n",
            "    *Score: 4/10* (The inaccuracies and misrepresentations significantly detract from the helpfulness of the summary.)\n",
            "\n",
            "**Overall Score:** 4.5/10\n",
            "*(Accuracy: 3 + Efficiency: 6 + Context Awareness: 5 + Helpfulness: 4) / 4 = 4.5*\n",
            "\n",
            "**Reasoning for Overall Score:**\n",
            "The AI's response suffers from significant accuracy issues, primarily by misrepresenting information from the 'Data Store State *Before* AI Action' as things it \"learned\" through recent actions (e.g., \"added\" an existing customer, \"processed\" an already shipped order). Furthermore, it hallucinated an incorrect price history for \"Gizmo X.\" While it correctly summarized actual RAG learnings and performed a correct calculation for inventory value, these correct elements are overshadowed by the misleading claims. The AI did not make any changes to the datastore, which is appropriate. It didn't ask unnecessary questions, but its interpretation of \"learnings\" and \"recent\" was flawed, leading to an unhelpful and inaccurate summary.\n",
            "Could not extract score for 'Anthropic' from eval text. Review eval output. Defaulting to 0.\n",
            "Do you want to add any general learnings from this turn? (Type your learning or 'skip'): skip\n",
            "[INFO] Skipping the addition of general learnings for this turn.\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): quit\n",
            "Exiting the system. Goodbye!\n",
            "\\n\\n===== EVALUATION SUMMARY =====\n",
            "\\nQuery 1: I'd like to order 25 Perplexinators, please\n",
            "  Anthropic Resp: I've successfully placed your order! Here are the details:\n",
            "- Order ID: O3\n",
            "- Product: Perplexinator\n",
            "- Quantity: 25\n",
            "- Price per unit: $79.99\n",
            "- Total price: $1,999.75\n",
            "- Status: Processing\n",
            "\n",
            "Your order is now being processed. Is there anything else you'd ...\n",
            "  Score - Anthropic: 8\n",
            "    Initial DS Orders: 2, Products Inv P3: 1483\n",
            "    Final DS Orders: 3, Products Inv P3: 1483\n",
            "\\nQuery 2: Please ship my most recent order.\n",
            "  Anthropic Resp: Your order of 25 Perplexinators has been marked as shipped! The inventory has been automatically adjusted to reflect this change. Is there anything else you need assistance with?...\n",
            "  Score - Anthropic: 0\n",
            "    Initial DS Orders: 3, Products Inv P3: 1483\n",
            "    Final DS Orders: 3, Products Inv P3: 1458\n",
            "\\nQuery 3: How many Perplexinators are now left in stock?\n",
            "  Anthropic Resp: There are currently 1,458 Perplexinators in stock. Is there anything else you'd like to know?...\n",
            "  Score - Anthropic: 0\n",
            "    Initial DS Orders: 3, Products Inv P3: 1458\n",
            "    Final DS Orders: 3, Products Inv P3: 1458\n",
            "\\nQuery 4: Add a new customer: Bill Leece, bill.leece@mail.com, +1.222.333.4444\n",
            "  Anthropic Resp: I've successfully created a customer account for Bill Leece. Here are the details:\n",
            "- Customer ID: C3\n",
            "- Name: Bill Leece\n",
            "- Email: bill.leece@mail.com\n",
            "- Phone: +1.222.333.4444\n",
            "\n",
            "Is there anything else you'd like me to help you with?...\n",
            "  Score - Anthropic: 0\n",
            "    Initial DS Orders: 3, Products Inv P3: 1458\n",
            "    Final DS Orders: 3, Products Inv P3: 1458\n",
            "\\nQuery 5: Add new new product: Gizmo X, description: A fancy gizmo, price: 29.99, inventory: 50\n",
            "  Anthropic Resp: The product has been successfully added to the system! Here are the details:\n",
            "- Product ID: P4\n",
            "- Name: Gizmo X\n",
            "- Description: A fancy gizmo\n",
            "- Price: $29.99\n",
            "- Initial inventory: 50 units\n",
            "\n",
            "Is there anything else you'd like me to help you with?...\n",
            "  Score - Anthropic: 0\n",
            "    Initial DS Orders: 3, Products Inv P3: 1458\n",
            "    Final DS Orders: 3, Products Inv P3: 1458\n",
            "\\nQuery 6: Update Gizzmo's price to 99.99\n",
            "  Anthropic Resp: I've updated the price for Gizmo X from $29.99 to $99.99. All other product details remain unchanged. Is there anything else you'd like me to help you with?...\n",
            "  Score - Anthropic: 0\n",
            "    Initial DS Orders: 3, Products Inv P3: 1458\n",
            "    Final DS Orders: 3, Products Inv P3: 1458\n",
            "\\nQuery 7: Who won the 2020 US presidential election?\n",
            "  Anthropic Resp: I apologize, but I am designed to help with e-commerce related tasks such as managing orders, products, and customers. I cannot provide information about political elections or other topics outside of this e-commerce system. \n",
            "\n",
            "I can help you with:\n",
            "- ...\n",
            "  Score - Anthropic: 0\n",
            "    Initial DS Orders: 3, Products Inv P3: 1458\n",
            "    Final DS Orders: 3, Products Inv P3: 1458\n",
            "\\nQuery 8: I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount.\n",
            "  Anthropic Resp: I'll calculate the total value of all inventory:\n",
            "- Widget A: 999 units × $19.99 = $19,970.01\n",
            "- Gadget B: 200 units × $49.99 = $9,998.00\n",
            "- Perplexinator: 1,458 units × $79.99 = $116,625.42\n",
            "- Gizmo X: 50 units × $99.99 = $4,999.50\n",
            "\n",
            "The total value of a...\n",
            "  Score - Anthropic: 10\n",
            "    Initial DS Orders: 3, Products Inv P3: 1458\n",
            "    Final DS Orders: 3, Products Inv P3: 1458\n",
            "\\nQuery 9: Summarize your learnings from our recent interactions.\n",
            "  Anthropic Resp: Based on our recent interactions, I've learned:\n",
            "\n",
            "1. Order and Inventory Management:\n",
            "- Successfully processed and shipped an order for 25 Perplexinators\n",
            "- The Perplexinator inventory was automatically adjusted after shipping\n",
            "- Current inventory stands...\n",
            "  Score - Anthropic: 0\n",
            "    Initial DS Orders: 3, Products Inv P3: 1458\n",
            "    Final DS Orders: 3, Products Inv P3: 1458\n",
            "\\n----- Overall Performance -----\n",
            "Avg Anthropic Score: 2.00\n",
            "Total Anthropic Score: 18\n",
            "\\nLearnings are stored in: /content/drive/My Drive/AI/Knowledgebases\n",
            "Most recent learnings file: learnings_20250519_170646_768942.json\n",
            "\\nExecution Finished.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}