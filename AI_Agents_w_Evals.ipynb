{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjleece/AI-Agents/blob/main/AI_Agents_w_Evals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install anthropic\n",
        "#%pip install openai\n",
        "%pip install -q -U google-generativeai\n",
        "%pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDKcVFI7PAJ5",
        "outputId": "53159dd2-8288-4bee-f984-c6f641349290"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.51.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.0)\n",
            "Downloading anthropic-0.51.0-py3-none-any.whl (263 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/264.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m215.0/264.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.51.0\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup and Imports\n",
        "import anthropic\n",
        "import google.generativeai as gemini\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import glob # For finding files matching a pattern\n",
        "import uuid # For generating unique learning IDs in RAG\n",
        "from google.colab import userdata\n",
        "#from openai import OpenAI\n",
        "from google.colab import drive # For Google Drive mounting\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional, Union, Tuple\n",
        "from fuzzywuzzy import process, fuzz\n",
        "\n",
        "# LLM API Keys\n",
        "ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "#OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "#openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "gemini.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "ANTHROPIC_MODEL_NAME = \"claude-3-5-sonnet-latest\"\n",
        "#OPENAI_MODEL_NAME = \"gpt-4.1\" # Or your preferred GPT-4 class model\n",
        "EVAL_MODEL_NAME = \"gemini-2.5-pro-preview-05-06\" # Or your preferred Gemini model\n",
        "\n",
        "\n",
        "DRIVE_MOUNT_PATH = '/content/drive'\n",
        "\n",
        "try:\n",
        "    drive.mount(DRIVE_MOUNT_PATH)\n",
        "    print(f\"Google Drive mounted successfully at {DRIVE_MOUNT_PATH}.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}. RAG features will not work.\")\n",
        "\n",
        "# Set up the default learnings path\n",
        "DEFAULT_LEARNINGS_DRIVE_SUBPATH = \"My Drive/AI/Knowledgebases\"  # Your default path\n",
        "LEARNINGS_DRIVE_BASE_PATH = os.path.join(DRIVE_MOUNT_PATH, DEFAULT_LEARNINGS_DRIVE_SUBPATH)\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(LEARNINGS_DRIVE_BASE_PATH):\n",
        "    try:\n",
        "        os.makedirs(LEARNINGS_DRIVE_BASE_PATH)\n",
        "        print(f\"Created learnings directory: {LEARNINGS_DRIVE_BASE_PATH}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating learnings directory {LEARNINGS_DRIVE_BASE_PATH}: {e}\")\n",
        "else:\n",
        "    print(f\"Using existing learnings directory: {LEARNINGS_DRIVE_BASE_PATH}\")\n",
        "\n",
        "print(\"Imports and LLM clients initialized. Drive RAG configuration variables set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoQ4L2N6o339",
        "outputId": "cf1171b9-2e3b-4515-8fd2-b729ed5b3aae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully at /content/drive.\n",
            "Using existing learnings directory: /content/drive/My Drive/AI/Knowledgebases\n",
            "Imports and LLM clients initialized. Drive RAG configuration variables set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Specialized System Prompts ---\n",
        "\n",
        "# --- Worker AI Prompts ---\n",
        "worker_base_instructions = \"\"\"\n",
        "You are a helpful customer service assistant for an e-commerce system.\n",
        "Your overriding goal is to be helpful by answering questions and performing actions as requested by a human user.\n",
        "When responding to the user, use the conversation context to maintain continuity.\n",
        "- If a user refers to \"my order\" or similar, use the context to determine which order they're talking about.\n",
        "- If they mention \"that product\" or use other references, check the context to determine what they're referring to.\n",
        "- Always prioritize recent context over older context when resolving references.\n",
        "\n",
        "The conversation context will be provided to you with each message. This includes:\n",
        "- Previous questions and answers\n",
        "- Recently viewed customers, products, and orders\n",
        "- Recent actions taken (like creating orders, updating products, etc.)\n",
        "- Relevant Learnings from a knowledge base (if applicable to the current query type).\n",
        "\n",
        "REQUESTING CLARIFICATION FROM THE USER:\n",
        "If you determine that you absolutely need more information from the user to accurately and efficiently fulfill their request or use a tool correctly, you MUST:\n",
        "1. Formulate a clear, concise question for the user.\n",
        "2. Prefix your entire response with the exact tag: `CLARIFICATION_REQUESTED:`\n",
        "   Example: `CLARIFICATION_REQUESTED: To update the order, could you please provide the Order ID?`\n",
        "3. Do NOT use any tools in the same turn you are requesting clarification. Wait for the user's response.\n",
        "\n",
        "Keep all other responses friendly, concise, and helpful.\n",
        "\"\"\"\n",
        "\n",
        "worker_operational_system_prompt = f\"\"\"\n",
        "{worker_base_instructions}\n",
        "\n",
        "Your current task is OPERATIONAL. Focus on understanding user requests related to e-commerce functions (managing orders, products, customers), using the provided tools accurately, and interacting with the data store.\n",
        "The \"Relevant Learnings from Knowledge Base\" provided in your context may contain operational guidelines.\n",
        "\"\"\"\n",
        "\n",
        "worker_metacognitive_learnings_system_prompt = f\"\"\"\n",
        "{worker_base_instructions}\n",
        "\n",
        "Your current task is METACOGNITIVE: SUMMARIZING LEARNINGS.\n",
        "If the user asks you to \"summarize your learnings,\" \"what have you learned,\" \"why did you\", \"is there a better way to\" or similar phrases, your response should be based PRIMARILY on the content provided to you under the heading \"Relevant Learnings from Knowledge Base (In-Session Cache)\" in your current context.\n",
        "- List the key principles or pieces of information from these provided learnings.\n",
        "- Do not confuse these explicit learnings with a general summary of your recent actions or the current state of the data store, unless a learning specifically refers to such an action or state.\n",
        "- If no specific learnings are provided in your context for this type of query, you can state that no specific new learnings have been highlighted for this interaction.\n",
        "- Avoid using tools for this type of summarization unless a tool is specifically designed to retrieve or process learnings.\n",
        "\"\"\"\n",
        "\n",
        "# --- Evaluator AI Prompt (unified but guided by query type information) ---\n",
        "# This prompt is largely the same as the one from worker_prompt_update_learning_summary,\n",
        "# but we will emphasize the query_type in the main prompt to the evaluator.\n",
        "\n",
        "evaluator_system_prompt = \"\"\"\n",
        "You are Google Gemini, an impartial evaluator assessing the quality of responses from an AI assistant to customer service queries.\n",
        "\n",
        "You will be provided with:\n",
        "- The user's query and the TYPE of query it was classified as (e.g., OPERATIONAL, METACOGNITIVE_LEARNINGS_SUMMARY).\n",
        "- The conversation context (including RAG learnings) that was available to the AI assistant.\n",
        "- The AI assistant's final response.\n",
        "- A snapshot of the 'Data Store State *Before* AI Action'.\n",
        "- A snapshot of the 'Data Store State *After* AI Action'.\n",
        "- Details of any clarification questions the AI assistant asked.\n",
        "\n",
        "Your primary goal is to assess the AI assistant based on the SPECIFIC TASK it was attempting, as indicated by the query type.\n",
        "\n",
        "For each interaction, evaluate the assistant's response based on:\n",
        "1.  **Accuracy**:\n",
        "    * If OPERATIONAL: How correct and factual is the AI's textual response? Did its actions (tool calls) correctly modify the datastore as intended and claimed? Verify against 'Before' and 'After' states.\n",
        "    * If METACOGNITIVE_LEARNINGS_SUMMARY: Did the AI accurately summarize the \"Relevant Learnings from Knowledge Base\" provided in its context? Was the summary faithful to these learnings? Avoid confusing this with operational history.\n",
        "    * Check for new entity IDs and correct updates if applicable to the query type.\n",
        "\n",
        "2.  **Efficiency**:\n",
        "    * Did the assistant achieve its goal with minimal clarifying questions?\n",
        "    * If OPERATIONAL: Were tool calls used appropriately?\n",
        "    * If METACOGNITIVE_LEARNINGS_SUMMARY: Was the summary direct and to the point based on provided learnings?\n",
        "\n",
        "3.  **Context Awareness**:\n",
        "    * Did the assistant correctly use the conversation history and entities?\n",
        "    * Crucially, did the assistant adhere to the task defined by the query type? (e.g., if asked to summarize learnings, did it do that, or did it perform an operational summary by mistake?).\n",
        "    * Did it correctly use any \"Relevant Learnings from Knowledge Base\" that were pertinent to the query type?\n",
        "\n",
        "4.  **Helpfulness**:\n",
        "    * How well did the assistant address the user's needs *for the identified query type*?\n",
        "    * Was the response clear and did it provide relevant information?\n",
        "\n",
        "Score the response on a scale of 1-10 for each criterion, and provide an overall score. Provide detailed reasoning, EXPLICITLY MENTIONING THE QUERY TYPE you are evaluating against.\n",
        "- For OPERATIONAL queries, heavily reference the 'Before' and 'After' data store states.\n",
        "- For METACOGNITIVE_LEARNINGS_SUMMARY, heavily reference the \"Relevant Learnings from Knowledge Base\" that were provided to the worker.\n",
        "\n",
        "EVALUATING CLARIFICATION QUESTIONS: (Same as before)\n",
        "If the worker AI asked for clarification:\n",
        "- Assess necessity using 'Data Store State *Before* AI Action' and context.\n",
        "- If necessary and well-phrased, it should NOT negatively impact Efficiency.\n",
        "- If unnecessary, it SHOULD negatively impact Efficiency.\n",
        "\n",
        "If you, the evaluator, still have questions, use \"CLARIFICATION NEEDED_EVALUATOR:\".\n",
        "\n",
        "DATA STORE CONSISTENCY (Primarily for OPERATIONAL tasks):\n",
        "When assessing Accuracy for OPERATIONAL tasks, explicitly compare the AI's actions with changes between 'Before' and 'After' states.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zMWjRsv3QNc1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize stuff to prevent possible caching issues\n",
        "\n",
        "human_feedback_learnings = {}\n",
        "tools_schemas_list = []"
      ],
      "metadata": {
        "id": "YgO9bnabVWZC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gemini models have different structure than Anthropic and need to be called this way before use to enable generate_content(prompt),\n",
        "#whereas Anthropic allows model definition + system instructions within messages.create(prompt)\n",
        "\n",
        "eval_model_instance = gemini.GenerativeModel(\n",
        "    model_name=EVAL_MODEL_NAME,\n",
        "    system_instruction=evaluator_system_prompt\n",
        ")\n",
        "print(\"Gemini Evaluator model instance initialized.\")\n",
        "\n",
        "#this instance of Gemini is to get \"ground truth\" answers by running queries in parallel with Anthropic. The evaluator instance then evaluates the \"ground truth\" against Anthropic's response.\n",
        "gemini_actor_model_instance = gemini.GenerativeModel(\n",
        "    model_name=EVAL_MODEL_NAME, # Using the same underlying model\n",
        "    system_instruction=worker_base_instructions # But with the worker's system prompt\n",
        ")\n",
        "print(\"Gemini Actor model instance initialized.\")"
      ],
      "metadata": {
        "id": "lHWwoW0JQRS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f791f903-69c7-4734-d123-7368d861c273"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Evaluator model instance initialized.\n",
            "Gemini Actor model instance initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Data Stores (Initial data - will be managed by the Storage class instance)\n",
        "# These are initial values. The Storage class will manage them.\n",
        "initial_customers = {\n",
        "    \"C1\": {\"name\": \"John Doe\", \"email\": \"john@example.com\", \"phone\": \"123-456-7890\"},\n",
        "    \"C2\": {\"name\": \"Jane Smith\", \"email\": \"jane@example.com\", \"phone\": \"987-654-3210\"}\n",
        "}\n",
        "\n",
        "initial_products = {\n",
        "    \"P1\": {\"name\": \"Widget A\", \"description\": \"A simple widget. Very compact.\", \"price\": 19.99, \"inventory_count\": 999},\n",
        "    \"P2\": {\"name\": \"Gadget B\", \"description\": \"A powerful gadget. It spins.\", \"price\": 49.99, \"inventory_count\": 200},\n",
        "    \"P3\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1483}\n",
        "}\n",
        "\n",
        "initial_orders = {\n",
        "    \"O1\": {\"id\": \"O1\", \"product_id\": \"P1\", \"product_name\": \"Widget A\", \"quantity\": 2, \"price\": 19.99, \"status\": \"Shipped\"},\n",
        "    \"O2\": {\"id\": \"O2\", \"product_id\": \"P2\", \"product_name\": \"Gadget B\", \"quantity\": 1, \"price\": 49.99, \"status\": \"Processing\"}\n",
        "}\n"
      ],
      "metadata": {
        "id": "5G9rP40vQXdU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standalone Anthropic Completion Function (for basic tests)\n",
        "def get_completion_anthropic_standalone(prompt: str):\n",
        "    message = anthropic_client.messages.create(\n",
        "        model=ANTHROPIC_MODEL_NAME,\n",
        "        max_tokens=2000,\n",
        "        temperature=0.0,\n",
        "        system=worker_base_instructions,\n",
        "        tools=tools_schemas_list,\n",
        "        messages=[\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return message.content[0].text"
      ],
      "metadata": {
        "id": "_ADM0bBpQlVK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_test_anthropic = \"Hey there, which AI model do you use for answering questions?\"\n",
        "print(f\"Anthropic Standalone Test: {get_completion_anthropic_standalone(prompt_test_anthropic)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPOq1s0SQqk_",
        "outputId": "10772a98-3f18-4a53-ed6d-dc83ddf0a69a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anthropic Standalone Test: I am a customer service assistant designed to help with e-commerce related questions and tasks. I aim to be helpful by answering questions and performing actions related to orders, products, customers, and other e-commerce functions. I don't actually discuss my underlying AI model or technical details - instead, I'd be happy to help you with any questions about orders, products, or other e-commerce related matters. What can I assist you with today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def get_completion_openai_standalone(prompt: str):\n",
        "#    response = openai_client.chat.completions.create(\n",
        "#        model=OPENAI_MODEL_NAME,\n",
        "#        max_tokens=2000,\n",
        "#        temperature=0.0,\n",
        "#        tools=tools_schemas_list,\n",
        "#        messages=[\n",
        "#            {\"role\": \"system\", \"content\": worker_system_prompt},\n",
        "#            {\"role\": \"user\", \"content\": prompt}\n",
        "#        ]\n",
        "#    )\n",
        "#    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Y5c_bv3qQwWV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt_test_openai = \"Hey there, which AI model do you use for answering questions?\"\n",
        "#print(f\"OpenAI Standalone Test: {get_completion_openai_standalone(prompt_test_openai)}\")"
      ],
      "metadata": {
        "id": "b_LaDQ74Q1Lp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_eval_standalone(prompt: str):\n",
        "    # Uses the eval_model_instance which has the system prompt\n",
        "        response = eval_model_instance.generate_content(prompt)\n",
        "        return response.text"
      ],
      "metadata": {
        "id": "XjcV5GcaQ6aT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_test_eval = \"Hey there, can you tell me which AI you are and what your key tasks are?\"\n",
        "print(f\"Gemini Eval Standalone Test:\\n{get_completion_eval_standalone(prompt_test_eval)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "Cu8doX53RE0Z",
        "outputId": "a1854659-c98d-4ab6-9df9-5ae66991286a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Eval Standalone Test:\n",
            "## Evaluation of AI Assistant Response\n",
            "\n",
            "**1. Accuracy:**\n",
            "   - **Score:** 10/10\n",
            "   - **Reasoning:** The AI accurately identifies itself as \"a large language model, trained by Google.\" It also correctly describes its key tasks as understanding and responding to a wide range of questions and requests, assisting with information, completing tasks based on instructions, and engaging in conversation. This is a truthful representation of its capabilities in this context.\n",
            "\n",
            "**2. Efficiency:**\n",
            "   - **Score:** 10/10\n",
            "   - **Reasoning:** The AI answered the user's query directly and concisely without asking any clarifying questions. The response was immediate and to the point.\n",
            "\n",
            "**3. Context Awareness:**\n",
            "   - **Score:** 10/10\n",
            "   - **Reasoning:** The query type is METACOGNITIVE_ABOUT_ASSISTANT. The AI correctly understood that the user was asking about its own identity and functions. It did not attempt to perform an operational task or summarize learnings, which would have been inappropriate for this query type. No specific \"Relevant Learnings from Knowledge Base\" were provided or needed for this type of query, and the AI correctly did not refer to any.\n",
            "\n",
            "**4. Helpfulness:**\n",
            "   - **Score:** 10/10\n",
            "   - **Reasoning:** The response directly and clearly answers the user's two-part question: \"which AI you are\" and \"what your key tasks are.\" The information provided is relevant and satisfies the user's inquiry for this METACOGNITIVE_ABOUT_ASSISTANT query.\n",
            "\n",
            "**Overall Score:** 10/10\n",
            "\n",
            "**Reasoning for Overall Score:**\n",
            "The AI performed exceptionally well on this METACOGNITIVE_ABOUT_ASSISTANT query. It accurately described itself and its functions, did so efficiently without unnecessary dialogue, understood the context of the question perfectly, and provided a helpful and complete answer. There were no data store modifications or specific learnings to consider for this query type, and the AI handled it appropriately by providing a general, truthful statement about its nature and purpose.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storage Class\n",
        "class Storage:\n",
        "    def __init__(self):\n",
        "        self.customers = copy.deepcopy(initial_customers)\n",
        "        self.products = copy.deepcopy(initial_products)\n",
        "        self.orders = copy.deepcopy(initial_orders)\n",
        "        self.human_feedback_learnings = human_feedback_learnings\n",
        "\n",
        "    def get_full_datastore_copy(self) -> Dict[str, Any]:\n",
        "        \"\"\"Returns a deep copy of the current datastore.\"\"\"\n",
        "        return {\n",
        "            \"customers\": copy.deepcopy(self.customers),\n",
        "            \"products\": copy.deepcopy(self.products),\n",
        "            \"orders\": copy.deepcopy(self.orders)\n",
        "        }\n",
        "\n",
        "print(\"Storage class defined with deepcopy for initial data and get_full_datastore_copy method.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpVJLbF6ROgf",
        "outputId": "155b889c-8467-480d-99ce-69fee17b7819"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Storage class defined with deepcopy for initial data and get_full_datastore_copy method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definitive list of tool schemas.\n",
        "tools_schemas_list = [\n",
        "    {\n",
        "        \"name\": \"create_customer\",\n",
        "        \"description\": \"Adds a new customer to the database. Includes customer name, email, and (optional) phone number.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The name of the customer.\"},\n",
        "                \"email\": {\"type\": \"string\", \"description\": \"The email address of the customer.\"},\n",
        "                \"phone\": {\"type\": \"string\", \"description\": \"The phone number of the customer (optional).\"}\n",
        "            },\n",
        "            \"required\": [\"name\", \"email\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_customer_info\",\n",
        "        \"description\": \"Retrieves customer information based on their customer ID. Returns the customer's name, email, and (optional) phone number.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"customer_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the customer.\"}\n",
        "            },\n",
        "            \"required\": [\"customer_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"create_product\",\n",
        "        \"description\": \"Adds a new product to the product database. Includes name, description, price, and initial inventory count.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The name of the product.\"},\n",
        "                \"description\": {\"type\": \"string\", \"description\": \"A description of the product.\"},\n",
        "                \"price\": {\"type\": \"number\", \"description\": \"The price of the product.\"},\n",
        "                \"inventory_count\": {\"type\": \"integer\", \"description\": \"The amount of the product that is currently in inventory.\"}\n",
        "            },\n",
        "            \"required\": [\"name\", \"description\", \"price\", \"inventory_count\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"update_product\",\n",
        "        \"description\": \"Updates an existing product with new information. Only fields that are provided will be updated; other fields remain unchanged.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the product to update.\"},\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The new name for the product (optional).\"},\n",
        "                \"description\": {\"type\": \"string\", \"description\": \"The new description for the product (optional).\"},\n",
        "                \"price\": {\"type\": \"number\", \"description\": \"The new price for the product (optional).\"},\n",
        "                \"inventory_count\": {\"type\": \"integer\", \"description\": \"The new inventory count for the product (optional).\"}\n",
        "            },\n",
        "            \"required\": [\"product_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_product_info\",\n",
        "        \"description\": \"Retrieves product information based on product ID or product name (with fuzzy matching for misspellings). Returns product details including name, description, price, and inventory count.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id_or_name\": {\"type\": \"string\", \"description\": \"The product ID or name (can be approximate).\"}\n",
        "            },\n",
        "            \"required\": [\"product_id_or_name\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"list_all_products\",\n",
        "        \"description\": \"Lists all available products in the inventory.\",\n",
        "        \"input_schema\": { \"type\": \"object\", \"properties\": {}, \"required\": [] }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"create_order\",\n",
        "        \"description\": \"Creates an order using the product's current price. If requested quantity exceeds available inventory, no order is created and available quantity is returned. Orders can only be created for products that are in stock. Supports specifying products by either ID or name with fuzzy matching for misspellings.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id_or_name\": {\"type\": \"string\", \"description\": \"The ID or name of the product to order (supports fuzzy matching).\"},\n",
        "                \"quantity\": {\"type\": \"integer\", \"description\": \"The quantity of the product in the order.\"},\n",
        "                \"status\": {\"type\": \"string\", \"description\": \"The initial status of the order (e.g., 'Processing', 'Shipped').\"}\n",
        "            },\n",
        "            \"required\": [\"product_id_or_name\", \"quantity\", \"status\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_order_details\",\n",
        "        \"description\": \"Retrieves the details of a specific order based on the order ID. Returns the order ID, product name, quantity, price, and order status.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the order.\"}\n",
        "            },\n",
        "            \"required\": [\"order_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"update_order_status\",\n",
        "        \"description\": \"Updates the status of an order and adjusts inventory accordingly. Changing to \\\"Shipped\\\" decreases inventory. Changing to \\\"Returned\\\" or \\\"Canceled\\\" from \\\"Shipped\\\" increases inventory. Status can be \\\"Processing\\\", \\\"Shipped\\\", \\\"Delivered\\\", \\\"Returned\\\", or \\\"Canceled\\\".\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the order.\"},\n",
        "                \"new_status\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The new status to set for the order.\",\n",
        "                    \"enum\": [\"Processing\", \"Shipped\", \"Delivered\", \"Returned\", \"Canceled\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"order_id\", \"new_status\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "print(f\"Defined {len(tools_schemas_list)} tool schemas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgk-hLUBRTCY",
        "outputId": "e8b9f39b-fb6d-4952-d54f-5b0fc38bab4e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined 9 tool schemas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool Function Definitions\n",
        "# These tool functions now accept a 'current_storage' argument to operate on a specific Storage instance.\n",
        "\n",
        "# Customer functions\n",
        "def create_customer(current_storage: Storage, name: str, email: str, phone: Optional[str] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Creates a new customer and adds them to the customer database.\"\"\"\n",
        "    new_id = f\"C{len(current_storage.customers) + 1}\"\n",
        "    current_storage.customers[new_id] = {\"name\": name, \"email\": email, \"phone\": phone}\n",
        "    print(f\"[Tool Executed] create_customer: ID {new_id}, Name: {name} (in {type(current_storage).__name__})\")\n",
        "    return {\"status\": \"success\", \"customer_id\": new_id, \"customer\": current_storage.customers[new_id]}\n",
        "\n",
        "def get_customer_info(current_storage: Storage, customer_id: str) -> Dict[str, Any]:\n",
        "    \"\"\"Retrieves information about a customer based on their ID.\"\"\"\n",
        "    customer = current_storage.customers.get(customer_id)\n",
        "    if customer:\n",
        "        print(f\"[Tool Executed] get_customer_info: ID {customer_id} found (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"success\", \"customer_id\": customer_id, \"customer\": customer}\n",
        "    print(f\"[Tool Executed] get_customer_info: ID {customer_id} not found (in {type(current_storage).__name__}).\")\n",
        "    return {\"status\": \"error\", \"message\": \"Customer not found\"}\n",
        "\n",
        "# Product functions\n",
        "def create_product(current_storage: Storage, name: str, description: str, price: float, inventory_count: int) -> Dict[str, Any]:\n",
        "    \"\"\"Creates a new product and adds it to the product database.\"\"\"\n",
        "    new_id = f\"P{len(current_storage.products) + 1}\"\n",
        "    current_storage.products[new_id] = {\n",
        "        \"name\": name,\n",
        "        \"description\": description,\n",
        "        \"price\": float(price),\n",
        "        \"inventory_count\": int(inventory_count)\n",
        "    }\n",
        "    print(f\"[Tool Executed] create_product: ID {new_id}, Name: {name} (in {type(current_storage).__name__})\")\n",
        "    return {\"status\": \"success\", \"product_id\": new_id, \"product\": current_storage.products[new_id]}\n",
        "\n",
        "def update_product(current_storage: Storage, product_id: str, name: Optional[str] = None, description: Optional[str] = None,\n",
        "                   price: Optional[float] = None, inventory_count: Optional[int] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Updates a product with the provided parameters.\"\"\"\n",
        "    if product_id not in current_storage.products:\n",
        "        print(f\"[Tool Executed] update_product: ID {product_id} not found (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"error\", \"message\": f\"Product {product_id} not found\"}\n",
        "\n",
        "    product = current_storage.products[product_id]\n",
        "    updated_fields = []\n",
        "\n",
        "    if name is not None:\n",
        "        product[\"name\"] = name\n",
        "        updated_fields.append(\"name\")\n",
        "    if description is not None:\n",
        "        product[\"description\"] = description\n",
        "        updated_fields.append(\"description\")\n",
        "    if price is not None:\n",
        "        product[\"price\"] = float(price)\n",
        "        updated_fields.append(\"price\")\n",
        "    if inventory_count is not None:\n",
        "        product[\"inventory_count\"] = int(inventory_count)\n",
        "        updated_fields.append(\"inventory_count\")\n",
        "\n",
        "    if not updated_fields:\n",
        "        print(f\"[Tool Executed] update_product: ID {product_id}, no fields updated (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"warning\", \"message\": \"No fields were updated.\", \"product\": product}\n",
        "\n",
        "    print(f\"[Tool Executed] update_product: ID {product_id}, Updated fields: {', '.join(updated_fields)} (in {type(current_storage).__name__})\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"message\": f\"Product {product_id} updated. Fields: {', '.join(updated_fields)}\",\n",
        "        \"product_id\": product_id,\n",
        "        \"updated_fields\": updated_fields,\n",
        "        \"product\": product\n",
        "    }\n",
        "\n",
        "def find_product_by_name(current_storage: Storage, product_name: str, min_similarity: int = 70) -> Tuple[Optional[str], Optional[Dict[str, Any]]]:\n",
        "    \"\"\"Find a product by name using fuzzy string matching.\"\"\"\n",
        "    if not product_name: return None, None\n",
        "\n",
        "    name_id_list = [(p_data[\"name\"], p_id) for p_id, p_data in current_storage.products.items()]\n",
        "    if not name_id_list: return None, None\n",
        "\n",
        "    best_match_name_score = process.extractOne(\n",
        "        product_name,\n",
        "        [item[0] for item in name_id_list],\n",
        "        scorer=fuzz.token_sort_ratio\n",
        "    )\n",
        "\n",
        "    if best_match_name_score and best_match_name_score[1] >= min_similarity:\n",
        "        matched_name = best_match_name_score[0]\n",
        "        for name, pid_val in name_id_list:\n",
        "            if name == matched_name:\n",
        "                print(f\"[Tool Helper] find_product_by_name: Matched '{product_name}' to '{matched_name}' (ID: {pid_val}) with score {best_match_name_score[1]} (in {type(current_storage).__name__})\")\n",
        "                return pid_val, current_storage.products[pid_val]\n",
        "\n",
        "    print(f\"[Tool Helper] find_product_by_name: No good match for '{product_name}' (min_similarity: {min_similarity}, Best match: {best_match_name_score}) (in {type(current_storage).__name__})\")\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def get_product_id(current_storage: Storage, product_identifier: str) -> Optional[str]:\n",
        "    \"\"\"Get product ID either directly or by fuzzy matching the name.\"\"\"\n",
        "    if product_identifier in current_storage.products:\n",
        "        return product_identifier\n",
        "    product_id, _ = find_product_by_name(current_storage, product_identifier)\n",
        "    return product_id\n",
        "\n",
        "def get_product_info(current_storage: Storage, product_id_or_name: str) -> Dict[str, Any]:\n",
        "    \"\"\"Get information about a product by its ID or name.\"\"\"\n",
        "    if product_id_or_name in current_storage.products:\n",
        "        product = current_storage.products[product_id_or_name]\n",
        "        print(f\"[Tool Executed] get_product_info: Found by ID '{product_id_or_name}' (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"success\", \"product_id\": product_id_or_name, \"product\": product}\n",
        "\n",
        "    # Use the modified find_product_by_name that takes current_storage\n",
        "    product_id_found, product_data = find_product_by_name(current_storage, product_id_or_name)\n",
        "    if product_id_found and product_data:\n",
        "        print(f\"[Tool Executed] get_product_info: Found by name (fuzzy) '{product_id_or_name}' as ID '{product_id_found}' (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"success\", \"message\": f\"Found product matching '{product_id_or_name}'\", \"product_id\": product_id_found, \"product\": product_data}\n",
        "\n",
        "    print(f\"[Tool Executed] get_product_info: No product found for '{product_id_or_name}' (in {type(current_storage).__name__}).\")\n",
        "    return {\"status\": \"error\", \"message\": f\"No product found matching '{product_id_or_name}'\"}\n",
        "\n",
        "\n",
        "def list_all_products(current_storage: Storage) -> Dict[str, Any]:\n",
        "    \"\"\"List all available products in the inventory.\"\"\"\n",
        "    print(f\"[Tool Executed] list_all_products: Found {len(current_storage.products)} products (in {type(current_storage).__name__}).\")\n",
        "    return {\"status\": \"success\", \"count\": len(current_storage.products), \"products\": dict(current_storage.products)}\n",
        "\n",
        "# Order functions\n",
        "def create_order(current_storage: Storage, product_id_or_name: str, quantity: int, status: str) -> Dict[str, Any]:\n",
        "    \"\"\"Creates an order using the product's stored price.\"\"\"\n",
        "    actual_product_id = get_product_id(current_storage, product_id_or_name) # Pass current_storage\n",
        "\n",
        "    if not actual_product_id:\n",
        "        print(f\"[Tool Executed] create_order: Product '{product_id_or_name}' not found (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"error\", \"message\": f\"Product '{product_id_or_name}' not found.\"}\n",
        "\n",
        "    product = current_storage.products[actual_product_id]\n",
        "    price = product[\"price\"]\n",
        "\n",
        "    if product[\"inventory_count\"] == 0:\n",
        "        print(f\"[Tool Executed] create_order: Product ID {actual_product_id} is out of stock (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"error\", \"message\": f\"{product['name']} is out of stock.\"}\n",
        "    if quantity <= 0:\n",
        "        print(f\"[Tool Executed] create_order: Quantity must be positive. Requested: {quantity} (in {type(current_storage).__name__})\")\n",
        "        return {\"status\": \"error\", \"message\": \"Quantity must be a positive number.\"}\n",
        "    if quantity > product[\"inventory_count\"]:\n",
        "        print(f\"[Tool Executed] create_order: Insufficient inventory for {product['name']} (ID: {actual_product_id}). Available: {product['inventory_count']}, Requested: {quantity} (in {type(current_storage).__name__})\")\n",
        "        return {\n",
        "            \"status\": \"partial_availability\",\n",
        "            \"message\": f\"Insufficient inventory. Only {product['inventory_count']} units of {product['name']} are available.\",\n",
        "            \"available_quantity\": product[\"inventory_count\"],\n",
        "            \"requested_quantity\": quantity,\n",
        "            \"product_name\": product['name']\n",
        "        }\n",
        "\n",
        "    if status == \"Shipped\":\n",
        "        product[\"inventory_count\"] -= quantity\n",
        "        print(f\"[Tool Executed] create_order: Inventory for {product['name']} (ID: {actual_product_id}) reduced by {quantity} due to 'Shipped' status on creation (in {type(current_storage).__name__}).\")\n",
        "\n",
        "    new_id = f\"O{len(current_storage.orders) + 1}\"\n",
        "    current_storage.orders[new_id] = {\n",
        "        \"id\": new_id,\n",
        "        \"product_id\": actual_product_id,\n",
        "        \"product_name\": product[\"name\"],\n",
        "        \"quantity\": quantity,\n",
        "        \"price\": price,\n",
        "        \"status\": status\n",
        "    }\n",
        "    print(f\"[Tool Executed] create_order: Order {new_id} created for {quantity} of {product['name']} (ID: {actual_product_id}). Status: {status}. Remaining inv: {product['inventory_count']} (in {type(current_storage).__name__})\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"order_id\": new_id,\n",
        "        \"order_details\": current_storage.orders[new_id],\n",
        "        \"remaining_inventory\": product[\"inventory_count\"]\n",
        "    }\n",
        "\n",
        "def get_order_details(current_storage: Storage, order_id: str) -> Dict[str, Any]:\n",
        "    \"\"\"Get details of a specific order.\"\"\"\n",
        "    order = current_storage.orders.get(order_id)\n",
        "    if order:\n",
        "        print(f\"[Tool Executed] get_order_details: Order {order_id} found (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"success\", \"order_id\": order_id, \"order_details\": dict(order)}\n",
        "    print(f\"[Tool Executed] get_order_details: Order {order_id} not found (in {type(current_storage).__name__}).\")\n",
        "    return {\"status\": \"error\", \"message\": \"Order not found\"}\n",
        "\n",
        "def update_order_status(current_storage: Storage, order_id: str, new_status: str) -> Dict[str, Any]:\n",
        "    \"\"\"Updates the status of an order and adjusts inventory accordingly.\"\"\"\n",
        "    if order_id not in current_storage.orders:\n",
        "        print(f\"[Tool Executed] update_order_status: Order {order_id} not found (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"error\", \"message\": \"Order not found\"}\n",
        "\n",
        "    order = current_storage.orders[order_id]\n",
        "    old_status = order[\"status\"]\n",
        "    product_id = order[\"product_id\"]\n",
        "    quantity = order[\"quantity\"]\n",
        "\n",
        "    if old_status == new_status:\n",
        "        print(f\"[Tool Executed] update_order_status: Order {order_id} status unchanged ({old_status}) (in {type(current_storage).__name__}).\")\n",
        "        return {\"status\": \"unchanged\", \"message\": f\"Order {order_id} status is already {old_status}\", \"order_details\": dict(order)}\n",
        "\n",
        "    inventory_adjusted = False\n",
        "    current_inventory_val = \"unknown\" # Default if product not found (should not happen if order is valid)\n",
        "\n",
        "    if product_id in current_storage.products:\n",
        "        product = current_storage.products[product_id]\n",
        "        current_inventory_val = product[\"inventory_count\"]\n",
        "\n",
        "        if new_status == \"Shipped\" and old_status not in [\"Shipped\", \"Delivered\"]:\n",
        "            if current_inventory_val < quantity:\n",
        "                print(f\"[Tool Executed] update_order_status: Insufficient inventory to ship order {order_id}. Have {current_inventory_val}, need {quantity} (in {type(current_storage).__name__}).\")\n",
        "                return {\"status\": \"error\", \"message\": f\"Insufficient inventory to ship. Available: {current_inventory_val}, Required: {quantity}\"}\n",
        "            product[\"inventory_count\"] -= quantity\n",
        "            inventory_adjusted = True\n",
        "            current_inventory_val = product[\"inventory_count\"]\n",
        "            print(f\"[Tool Executed] update_order_status: Order {order_id} Shipped. Inv for {product_id} reduced by {quantity} to {current_inventory_val} (in {type(current_storage).__name__}).\")\n",
        "        elif new_status in [\"Returned\", \"Canceled\"] and old_status in [\"Shipped\", \"Delivered\"]:\n",
        "            product[\"inventory_count\"] += quantity\n",
        "            inventory_adjusted = True\n",
        "            current_inventory_val = product[\"inventory_count\"]\n",
        "            print(f\"[Tool Executed] update_order_status: Order {order_id} {new_status}. Inv for {product_id} increased by {quantity} to {current_inventory_val} (in {type(current_storage).__name__}).\")\n",
        "    else:\n",
        "        print(f\"[Tool Executed] update_order_status: Product {product_id} for order {order_id} not found for inventory adjustment (in {type(current_storage).__name__}).\")\n",
        "\n",
        "    order[\"status\"] = new_status\n",
        "    print(f\"[Tool Executed] update_order_status: Order {order_id} status updated from {old_status} to {new_status} (in {type(current_storage).__name__}).\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"message\": f\"Order {order_id} status updated from {old_status} to {new_status}.\",\n",
        "        \"order_id\": order_id,\n",
        "        \"product_id\": product_id,\n",
        "        \"old_status\": old_status,\n",
        "        \"new_status\": new_status,\n",
        "        \"inventory_adjusted\": inventory_adjusted,\n",
        "        \"current_inventory\": current_inventory_val,\n",
        "        \"order_details\": dict(order)\n",
        "    }\n",
        "\n",
        "print(\"Tool functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RZI6SGzRf6j",
        "outputId": "d91b912c-b15f-48e4-9c3c-6956b9ab374c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationContext:\n",
        "    def __init__(self):\n",
        "        self.messages: List[Dict[str, Any]] = []\n",
        "        self.context_data: Dict[str, Any] = {\n",
        "            \"customers\": {}, \"products\": {}, \"orders\": {}, \"last_action\": None\n",
        "        }\n",
        "        self.session_start_time = datetime.now()\n",
        "\n",
        "    def add_user_message(self, message: str) -> None:\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    def add_assistant_message(self, message_content: Union[str, List[Dict[str, Any]]]) -> None:\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": message_content})\n",
        "\n",
        "    def update_entity_in_context(self, entity_type: str, entity_id: str, data: Any) -> None:\n",
        "        if entity_type in self.context_data:\n",
        "            self.context_data[entity_type][entity_id] = data # Store the actual data\n",
        "            print(f\"[Context Updated] Entity: {entity_type}, ID: {entity_id}, Data (type): {type(data)}\")\n",
        "\n",
        "    def set_last_action(self, action_type: str, action_details: Any) -> None:\n",
        "        self.context_data[\"last_action\"] = {\n",
        "            \"type\": action_type,\n",
        "            \"details\": action_details,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "        print(f\"[Context Updated] Last Action: {action_type}, Details: {json.dumps(action_details, default=str)}\")\n",
        "\n",
        "\n",
        "    def get_full_conversation_for_api(self) -> List[Dict[str, Any]]:\n",
        "        return self.messages.copy()\n",
        "\n",
        "    def get_context_summary(self) -> str:\n",
        "        summary_parts = []\n",
        "        if self.context_data[\"customers\"]:\n",
        "            customers_str = \", \".join([f\"ID: {cid} (Name: {c.get('name', 'N/A') if isinstance(c, dict) else 'N/A'})\" for cid, c in self.context_data[\"customers\"].items()])\n",
        "            summary_parts.append(f\"Recent customers: {customers_str}\")\n",
        "        if self.context_data[\"products\"]:\n",
        "            products_str = \", \".join([f\"ID: {pid} (Name: {p.get('name', 'N/A') if isinstance(p, dict) else 'N/A'})\" for pid, p in self.context_data[\"products\"].items()])\n",
        "            summary_parts.append(f\"Recent products: {products_str}\")\n",
        "        if self.context_data[\"orders\"]:\n",
        "            orders_str = \", \".join([f\"ID: {oid} (Product: {o.get('product_name', 'N/A') if isinstance(o, dict) else 'N/A'}, Status: {o.get('status', 'N/A') if isinstance(o, dict) else 'N/A'})\" for oid, o in self.context_data[\"orders\"].items()])\n",
        "            summary_parts.append(f\"Recent orders: {orders_str}\")\n",
        "\n",
        "        last_action = self.context_data[\"last_action\"]\n",
        "        if last_action:\n",
        "            action_type = last_action['type']\n",
        "            action_details_summary = \"...\" # Default summary\n",
        "            if isinstance(last_action.get('details'), dict):\n",
        "                action_input = last_action['details'].get('input', {})\n",
        "                action_result_status = last_action['details'].get('result', {}).get('status')\n",
        "                action_details_summary = f\"Input: {action_input}, Result Status: {action_result_status}\"\n",
        "                if action_result_status == \"success\":\n",
        "                    if \"order_id\" in last_action['details'].get('result', {}):\n",
        "                         action_details_summary += f\", OrderID: {last_action['details']['result']['order_id']}\"\n",
        "                    elif \"product_id\" in last_action['details'].get('result', {}):\n",
        "                         action_details_summary += f\", ProductID: {last_action['details']['result']['product_id']}\"\n",
        "\n",
        "\n",
        "            summary_parts.append(f\"Last action: {action_type} at {last_action['timestamp']} ({action_details_summary})\")\n",
        "\n",
        "        if not summary_parts: return \"No specific context items set yet.\"\n",
        "        return \"\\n\".join(summary_parts)\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        self.messages = []\n",
        "        self.context_data = {\"customers\": {}, \"products\": {}, \"orders\": {}, \"last_action\": None}\n",
        "        self.session_start_time = datetime.now()\n",
        "        print(\"[Context Cleared]\")\n",
        "\n",
        "print(\"ConversationContext class defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFpBL_-HSGPY",
        "outputId": "c5e81b88-46c9-4fbc-92ea-78a5b68c75cd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConversationContext class defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MODIFIED AgentEvaluator Class ---\n",
        "class AgentEvaluator:\n",
        "    def __init__(self):\n",
        "        if 'tools_schemas_list' not in globals() or not tools_schemas_list:\n",
        "            raise NameError(\"ERROR: Global 'tools_schemas_list' not found or empty.\")\n",
        "        self.conversation_context = ConversationContext()\n",
        "        self.evaluation_results = []\n",
        "        self.anthropic_storage = Storage()\n",
        "        self.anthropic_tools_schemas = tools_schemas_list\n",
        "        self.available_tool_functions = {\n",
        "            \"create_customer\": create_customer, \"get_customer_info\": get_customer_info,\n",
        "            \"create_product\": create_product, \"update_product\": update_product,\n",
        "            \"get_product_info\": get_product_info, \"list_all_products\": list_all_products,\n",
        "            \"create_order\": create_order, \"get_order_details\": get_order_details,\n",
        "            \"update_order_status\": update_order_status,\n",
        "        }\n",
        "        self.active_learnings_cache: List[Dict] = self._load_initial_learnings_from_drive()\n",
        "        self.learnings_updated_this_session_flag: bool = False\n",
        "        print(f\"AgentEvaluator initialized. Loaded {len(self.active_learnings_cache)} initial learnings.\")\n",
        "\n",
        "    def _classify_query_type(self, user_message: str) -> str:\n",
        "        \"\"\"\n",
        "        Classifies the user query into predefined types.\n",
        "        Simple keyword-based classification for now.\n",
        "        \"\"\"\n",
        "        msg_lower = user_message.lower()\n",
        "        if \"learnings\" in msg_lower or \"what have you learned\" in msg_lower or \"summarize your learning\" in msg_lower:\n",
        "            return \"METACOGNITIVE_LEARNINGS_SUMMARY\"\n",
        "        # Add more classifications here if needed, e.g., for explaining reasoning\n",
        "        # elif \"why did you\" in msg_lower:\n",
        "        #     return \"METACOGNITIVE_EXPLAIN_REASONING\"\n",
        "        return \"OPERATIONAL\" # Default\n",
        "\n",
        "    # RAG and Learning Persistence methods (_mount_drive_if_needed, _initialize_learnings_path, etc.)\n",
        "    # ... (Copied from previous version, assumed correct and complete) ...\n",
        "    def _mount_drive_if_needed(self):\n",
        "        if not os.path.exists(DRIVE_MOUNT_PATH) or not os.listdir(DRIVE_MOUNT_PATH):\n",
        "            try: drive.mount(DRIVE_MOUNT_PATH, force_remount=True); print(f\"Drive mounted.\")\n",
        "            except Exception as e: print(f\"Error mounting Drive: {e}.\")\n",
        "    def _initialize_learnings_path(self):\n",
        "        global LEARNINGS_DRIVE_BASE_PATH\n",
        "        if not LEARNINGS_DRIVE_BASE_PATH: LEARNINGS_DRIVE_BASE_PATH = os.path.join(DRIVE_MOUNT_PATH, DEFAULT_LEARNINGS_DRIVE_SUBPATH)\n",
        "        if not os.path.exists(LEARNINGS_DRIVE_BASE_PATH):\n",
        "            try: os.makedirs(LEARNINGS_DRIVE_BASE_PATH); print(f\"Created: {LEARNINGS_DRIVE_BASE_PATH}\")\n",
        "            except Exception as e: print(f\"Error creating learnings dir: {e}\")\n",
        "    def _get_latest_learnings_filepath_from_drive(self) -> Optional[str]:\n",
        "        self._mount_drive_if_needed(); self._initialize_learnings_path()\n",
        "        if not os.path.isdir(LEARNINGS_DRIVE_BASE_PATH): return None\n",
        "        list_of_files = glob.glob(os.path.join(LEARNINGS_DRIVE_BASE_PATH, 'learnings_*.json'))\n",
        "        return max(list_of_files, key=os.path.getctime) if list_of_files else None\n",
        "    def _read_learnings_from_drive_file(self, filepath: str) -> List[Dict]:\n",
        "        if not filepath or not os.path.exists(filepath): return []\n",
        "        try:\n",
        "            with open(filepath, 'r') as f: learnings_list = json.load(f)\n",
        "            return learnings_list if isinstance(learnings_list, list) else []\n",
        "        except Exception as e: print(f\"Error reading learnings {filepath}: {e}\"); return []\n",
        "    def _load_initial_learnings_from_drive(self) -> List[Dict]:\n",
        "        latest_filepath = self._get_latest_learnings_filepath_from_drive()\n",
        "        if latest_filepath: return self._read_learnings_from_drive_file(latest_filepath)\n",
        "        return []\n",
        "    def _persist_active_learnings_to_drive(self):\n",
        "        self._mount_drive_if_needed(); self._initialize_learnings_path()\n",
        "        if not os.path.isdir(LEARNINGS_DRIVE_BASE_PATH) or not self.active_learnings_cache: return\n",
        "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
        "        new_filepath = os.path.join(LEARNINGS_DRIVE_BASE_PATH, f'learnings_{ts}.json')\n",
        "        try:\n",
        "            with open(new_filepath, 'w') as f: json.dump(self.active_learnings_cache, f, indent=4)\n",
        "            print(f\"Persisted {len(self.active_learnings_cache)} learnings to {new_filepath}\")\n",
        "            self.learnings_updated_this_session_flag = False\n",
        "        except Exception as e: print(f\"Error persisting learnings: {e}\")\n",
        "    def check_relevant_learnings(self, query: str, query_type: str, count: int = 5) -> Optional[str]:\n",
        "        if not self.active_learnings_cache: return None\n",
        "        # For learning summaries, we might want to show all or more learnings.\n",
        "        if query_type == \"METACOGNITIVE_LEARNINGS_SUMMARY\":\n",
        "            count = len(self.active_learnings_cache) # Show all for summary\n",
        "\n",
        "        # Basic keyword matching for operational, more direct presentation for summary\n",
        "        relevant_learning_objects = []\n",
        "        if query_type == \"OPERATIONAL\":\n",
        "            keywords_from_query = self.extract_keywords(query)\n",
        "            for entry in self.active_learnings_cache:\n",
        "                text_to_search = entry.get(\"final_learning_statement\", \"\") + \" \" + \" \".join(entry.get(\"keywords\", []))\n",
        "                if any(kw.lower() in text_to_search.lower() for kw in keywords_from_query):\n",
        "                    relevant_learning_objects.append(entry)\n",
        "        elif query_type == \"METACOGNITIVE_LEARNINGS_SUMMARY\":\n",
        "            relevant_learning_objects = self.active_learnings_cache # All of them\n",
        "\n",
        "        relevant_learning_objects.sort(key=lambda x: x.get('timestamp_created', ''), reverse=True)\n",
        "\n",
        "        # Only include up to 'count' learnings, especially if not summarizing all.\n",
        "        learnings_to_format = relevant_learning_objects[:count] if query_type != \"METACOGNITIVE_LEARNINGS_SUMMARY\" else relevant_learning_objects\n",
        "\n",
        "        formatted_learnings = [\n",
        "            f\"- Learning (ID: {entry.get('learning_id', 'N/A')[:8]}): {entry.get('final_learning_statement', str(entry))}\"\n",
        "            for entry in learnings_to_format\n",
        "        ]\n",
        "        return \"\\\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\\\n\" + \"\\\\n\".join(formatted_learnings) if formatted_learnings else None\n",
        "\n",
        "    def _update_context_from_tool_results(self, tool_name: str, tool_input: Dict, tool_result: Dict): # Same as before\n",
        "        if not isinstance(tool_result, dict): return\n",
        "        if tool_result.get(\"status\") == \"success\":\n",
        "            if \"customer_id\" in tool_result and \"customer\" in tool_result: self.conversation_context.update_entity_in_context(\"customers\", tool_result[\"customer_id\"], tool_result[\"customer\"])\n",
        "            elif \"product_id\" in tool_result and \"product\" in tool_result: self.conversation_context.update_entity_in_context(\"products\", tool_result[\"product_id\"], tool_result[\"product\"])\n",
        "            elif \"order_id\" in tool_result and \"order_details\" in tool_result: self.conversation_context.update_entity_in_context(\"orders\", tool_result[\"order_id\"], tool_result[\"order_details\"])\n",
        "        self.conversation_context.set_last_action(f\"tool_{tool_name}_Anthropic\", {\"input\": tool_input, \"result\": tool_result})\n",
        "\n",
        "    def process_tool_call(self, tool_name: str, tool_input: Dict[str, Any]) -> Dict[str, Any]: # Same as before\n",
        "        if tool_name in self.available_tool_functions:\n",
        "            try:\n",
        "                result = self.available_tool_functions[tool_name](self.anthropic_storage, **tool_input)\n",
        "                return result\n",
        "            except Exception as e: return {\"status\": \"error\", \"message\": str(e)}\n",
        "        return {\"status\": \"error\", \"message\": f\"Tool {tool_name} not found.\"}\n",
        "\n",
        "    def get_anthropic_response(self, current_worker_system_prompt: str, conversation_history: List[Dict[str, Any]], query_type: str) -> str:\n",
        "        messages_for_api = list(conversation_history)\n",
        "        # For metacognitive tasks like summarizing learnings, we typically don't want tool use.\n",
        "        # The prompt already guides this, but we can also pass an empty tool list for such tasks.\n",
        "        tools_for_this_call = self.anthropic_tools_schemas if query_type == \"OPERATIONAL\" else []\n",
        "\n",
        "        try:\n",
        "            for i in range(5 if query_type == \"OPERATIONAL\" else 1): # Allow tool iterations only for operational\n",
        "                response = anthropic_client.messages.create(\n",
        "                    model=ANTHROPIC_MODEL_NAME, max_tokens=4000, temperature=0.0,\n",
        "                    system=current_worker_system_prompt,\n",
        "                    tools=tools_for_this_call, # Use conditional tools\n",
        "                    messages=messages_for_api\n",
        "                )\n",
        "                assistant_response_blocks = response.content\n",
        "                messages_for_api.append({\"role\": \"assistant\", \"content\": assistant_response_blocks})\n",
        "                text_blocks = [block.text for block in assistant_response_blocks if block.type == \"text\"]\n",
        "                final_text_response = \" \".join(text_blocks).strip()\n",
        "\n",
        "                if final_text_response.startswith(\"CLARIFICATION_REQUESTED:\"): return final_text_response\n",
        "\n",
        "                tool_calls_to_process = [block for block in assistant_response_blocks if block.type == \"tool_use\"]\n",
        "                if not tool_calls_to_process or query_type != \"OPERATIONAL\": # No tools or not an operational task\n",
        "                    return final_text_response if final_text_response else \"No text content.\"\n",
        "\n",
        "                tool_results_content = []\n",
        "                for tool_use_block in tool_calls_to_process:\n",
        "                    tool_name, tool_input, tool_use_id = tool_use_block.name, tool_use_block.input, tool_use_block.id\n",
        "                    tool_result_data = self.process_tool_call(tool_name, tool_input)\n",
        "                    self._update_context_from_tool_results(tool_name, tool_input, tool_result_data)\n",
        "                    tool_results_content.append({\"type\": \"tool_result\", \"tool_use_id\": tool_use_id, \"content\": json.dumps(tool_result_data)})\n",
        "                messages_for_api.append({\"role\": \"user\", \"content\": tool_results_content})\n",
        "            return \"Max tool iterations reached.\"\n",
        "        except Exception as e: return f\"Error in get_anthropic_response: {str(e)}\"\n",
        "\n",
        "    def _handle_worker_clarification(self, agent_question: str, current_prompt: str,\n",
        "                                     agent_specific_history: List[Dict], query_type: str, max_attempts: int = 2) -> Tuple[str, List[Dict]]:\n",
        "        clarification_turn_details = []\n",
        "        current_history = list(agent_specific_history)\n",
        "        for attempt in range(max_attempts):\n",
        "            print(f\"--- Anthropic requests clarification: {agent_question} ---\")\n",
        "            user_clarification = input(f\"Your response to Anthropic: \").strip() or \"(User provided no input)\"\n",
        "            clarification_turn_details.append({\"agent_question\": agent_question, \"user_answer\": user_clarification})\n",
        "            current_history.append({\"role\": \"user\", \"content\": user_clarification})\n",
        "            agent_response_text = self.get_anthropic_response(current_prompt, current_history, query_type) # Pass query_type\n",
        "            if agent_response_text.startswith(\"CLARIFICATION_REQUESTED:\"):\n",
        "                agent_question = agent_response_text.split(\"CLARIFICATION_REQUESTED:\", 1)[-1].strip()\n",
        "            else: return agent_response_text, clarification_turn_details\n",
        "        return agent_response_text, clarification_turn_details # Max attempts reached\n",
        "\n",
        "    def _get_llm_response_with_clarification_loop(self, system_prompt: str, base_history: List[Dict], query_type: str) -> Tuple[str, List[Dict]]:\n",
        "        current_history = list(base_history)\n",
        "        final_agent_response = self.get_anthropic_response(system_prompt, current_history, query_type) # Pass query_type\n",
        "        clarifications = []\n",
        "        if final_agent_response.startswith(\"CLARIFICATION_REQUESTED:\"):\n",
        "            question = final_agent_response.split(\"CLARIFICATION_REQUESTED:\", 1)[-1].strip()\n",
        "            final_agent_response, clarifications = self._handle_worker_clarification(question, system_prompt, current_history, query_type) # Pass query_type\n",
        "        return final_agent_response, clarifications\n",
        "\n",
        "    def process_user_request(self, user_message: str) -> Dict[str, Any]:\n",
        "        print(f\"\\\\n{'='*60}\\\\nUser Message: {user_message}\\\\n{'='*60}\")\n",
        "        self.conversation_context.add_user_message(user_message)\n",
        "\n",
        "        query_type = self._classify_query_type(user_message)\n",
        "        print(f\"--- Classified Query Type: {query_type} ---\")\n",
        "\n",
        "        # Select worker prompt based on query type\n",
        "        if query_type == \"METACOGNITIVE_LEARNINGS_SUMMARY\":\n",
        "            current_worker_base_prompt = worker_metacognitive_learnings_system_prompt\n",
        "        else: # Default to OPERATIONAL\n",
        "            current_worker_base_prompt = worker_operational_system_prompt\n",
        "\n",
        "        context_summary = self.conversation_context.get_context_summary()\n",
        "        learnings_for_prompt = self.check_relevant_learnings(user_message, query_type) # Pass query_type\n",
        "\n",
        "        # Construct the full prompt for the worker\n",
        "        # Note: The RAG learnings might be more or less relevant depending on the query type.\n",
        "        # The worker prompts themselves guide how to use these.\n",
        "        prompt_for_worker_with_context = (\n",
        "            f\"{current_worker_base_prompt}\\\\n\\\\n\"\n",
        "            f\"Conversation Context Summary:\\\\n{context_summary}\\\\n\\\\n\"\n",
        "            f\"{learnings_for_prompt if learnings_for_prompt else 'No specific learnings from knowledge base provided for this query.'}\"\n",
        "        )\n",
        "\n",
        "        initial_datastore_state_for_eval = self.anthropic_storage.get_full_datastore_copy()\n",
        "\n",
        "        anthropic_base_history = self.conversation_context.get_full_conversation_for_api()\n",
        "        anthropic_final_response, anthropic_clarifications = self._get_llm_response_with_clarification_loop(\n",
        "            prompt_for_worker_with_context, anthropic_base_history, query_type # Pass query_type\n",
        "        )\n",
        "        self.conversation_context.add_assistant_message(f\"[Anthropic Final Text ({query_type})]: {anthropic_final_response}\")\n",
        "\n",
        "        if anthropic_clarifications: # Process learnings from clarifications\n",
        "            for inter in anthropic_clarifications: self.process_and_store_new_learning(f\"User clarification: '{inter['user_answer']}' (re: '{inter['agent_question']}')\", user_message, context_summary)\n",
        "\n",
        "        final_datastore_state_for_eval = self.anthropic_storage.get_full_datastore_copy()\n",
        "\n",
        "        evaluation = self.evaluate_responses(\n",
        "            user_message, query_type, anthropic_final_response,\n",
        "            context_summary, learnings_for_prompt or \"\",\n",
        "            anthropic_clarifications,\n",
        "            initial_datastore_state_for_eval,\n",
        "            final_datastore_state_for_eval\n",
        "        )\n",
        "        self.evaluation_results.append(evaluation)\n",
        "\n",
        "        # Human feedback for general learning\n",
        "        try:\n",
        "            human_general_learning = input(\"General learning from this turn? (or 'skip'): \").strip()\n",
        "            if human_general_learning.lower() not in ['skip', '']:\n",
        "                self.process_and_store_new_learning(human_general_learning, user_message, context_summary)\n",
        "        except EOFError: pass # Non-interactive skip\n",
        "\n",
        "        if self.learnings_updated_this_session_flag: self._persist_active_learnings_to_drive()\n",
        "\n",
        "        return {\"user_message\": user_message, \"query_type\": query_type, \"anthropic_response\": anthropic_final_response, \"evaluation\": evaluation}\n",
        "\n",
        "    def evaluate_responses(self, user_message: str, query_type: str, anthropic_response: str,\n",
        "                       context_summary_for_eval: str, learnings_for_eval: str,\n",
        "                       anthropic_clarifications: Optional[List[Dict]],\n",
        "                       initial_datastore_state: Dict[str, Any],\n",
        "                       final_datastore_state: Dict[str, Any]\n",
        "                       ) -> Dict[str, Any]:\n",
        "        print(f\"\\\\n--- Starting Evaluation by Gemini (Query Type: {query_type}) ---\")\n",
        "\n",
        "        initial_ds_prompt = f\"Data Store State *Before* AI Action:\\\\n{json.dumps(initial_datastore_state, indent=2, default=str)}\"\n",
        "        final_ds_prompt = f\"Data Store State *After* AI Action:\\\\n{json.dumps(final_datastore_state, indent=2, default=str)}\"\n",
        "\n",
        "        clarification_info_prompt = \"No worker AI clarifications.\"\n",
        "        if anthropic_clarifications:\n",
        "            clar_summary = [f\"  Q: '{c['agent_question']}' -> User A: '{c['user_answer']}'\" for c in anthropic_clarifications]\n",
        "            clarification_info_prompt = f\"Worker AI Clarification Interactions:\\\\n\" + \"\\\\n\".join(clar_summary)\n",
        "\n",
        "        # The evaluator_system_prompt is already set on eval_model_instance.\n",
        "        # We construct the main content prompt for the evaluator.\n",
        "        eval_content_prompt = f\"\"\"\n",
        "        User query: {user_message}\n",
        "        Classified Query Type: {query_type}\n",
        "\n",
        "        Context provided to assistant:\n",
        "        {context_summary_for_eval}\n",
        "\n",
        "        Relevant RAG Learnings provided to assistant:\n",
        "        {learnings_for_eval if learnings_for_eval else 'None'}\n",
        "\n",
        "        {initial_ds_prompt}\n",
        "        {final_ds_prompt}\n",
        "\n",
        "        {clarification_info_prompt}\n",
        "\n",
        "        Anthropic Claude final textual response:\n",
        "        {anthropic_response}\n",
        "\n",
        "        ---\n",
        "        INSTRUCTIONS FOR EVALUATOR (You are Gemini):\n",
        "        Based on your system prompt and the classified query type ({query_type}), please evaluate the AI assistant's response.\n",
        "        - If OPERATIONAL, focus on tool use accuracy and data store changes (Before vs. After).\n",
        "        - If METACOGNITIVE_LEARNINGS_SUMMARY, focus on whether the AI accurately summarized the 'Relevant RAG Learnings' it was provided, not its operational history.\n",
        "        Provide detailed reasoning for scores (Accuracy, Efficiency, Context Awareness, Helpfulness) and an overall score (1-10).\n",
        "        \"\"\"\n",
        "        try:\n",
        "            gemini_response_obj = eval_model_instance.generate_content(eval_content_prompt)\n",
        "            evaluation_text = gemini_response_obj.text\n",
        "            print(f\"Gemini Raw Evaluation:\\\\n{evaluation_text}\")\n",
        "\n",
        "            # Handle evaluator clarification (simplified, assumes it doesn't change query_type focus)\n",
        "            clarif_details = {\"used\": False, \"needed\": \"\", \"provided_input\": \"\", \"action_summary\": \"\"}\n",
        "            # ... (evaluator clarification logic can be added here if needed) ...\n",
        "\n",
        "            final_evaluation_text = evaluation_text\n",
        "            anthropic_score = self.extract_score(final_evaluation_text)\n",
        "            return {\"anthropic_score\": anthropic_score, \"full_evaluation\": final_evaluation_text,\n",
        "                    \"clarification_details\": clarif_details, \"query_type_evaluated\": query_type}\n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e), \"anthropic_score\": 0, \"full_evaluation\": f\"Eval failed: {e}\",\n",
        "                    \"clarification_details\": {}, \"query_type_evaluated\": query_type}\n",
        "\n",
        "    def process_and_store_new_learning(self, human_feedback_text: str, user_query_context: str, turn_context_summary: str): # Mostly same\n",
        "        print(f\"--- Processing New Learning: \\\"{human_feedback_text}\\\" ---\")\n",
        "        # ... (rest of the learning synthesis logic using eval_model_instance)\n",
        "        # For brevity, assuming the existing logic for synthesis is okay.\n",
        "        # Key is that it uses `eval_model_instance` which has the general evaluator prompt.\n",
        "        # This part might also benefit from a specialized prompt if it's too complex.\n",
        "        evaluator_task_prompt_parts = [\n",
        "            \"You are an AI assistant helping to maintain a knowledge base of 'learnings'.\",\n",
        "            f\"New Human Feedback: \\\"{human_feedback_text}\\\"\",\n",
        "            f\"Context of User Query: \\\"{user_query_context}\\\"\",\n",
        "            \"Existing ACTIVE learnings (sample):\" + \\\n",
        "            \"\".join([f\"  - {entry.get('final_learning_statement', '')[:100]}...\" for entry in self.active_learnings_cache[-3:]]) ,\n",
        "            \"Tasks: Analyze feedback. Check for CONFLICT/REDUNDANCY. If new/refining, output `FINALIZED_LEARNING: [statement]`. Else, `CONFLICT_DETECTED:` or `REDUNDANT_LEARNING:` or `NOT_ACTIONABLE:`.\"\n",
        "        ]\n",
        "        synthesis_response_obj = eval_model_instance.generate_content(\"\\\\n\".join(evaluator_task_prompt_parts))\n",
        "        evaluator_synthesis_text = synthesis_response_obj.text\n",
        "        # ... (parse synthesis_text and update active_learnings_cache)\n",
        "        if \"FINALIZED_LEARNING:\" in evaluator_synthesis_text:\n",
        "            final_statement = evaluator_synthesis_text.split(\"FINALIZED_LEARNING:\", 1)[-1].strip()\n",
        "            if final_statement:\n",
        "                 self.active_learnings_cache.append({\n",
        "                     \"learning_id\": str(uuid.uuid4()), \"timestamp_created\": datetime.now().isoformat(),\n",
        "                     \"original_human_input\": human_feedback_text, \"final_learning_statement\": final_statement,\n",
        "                     \"keywords\": self.extract_keywords(final_statement + \" \" + human_feedback_text), \"status\": \"active\"\n",
        "                 })\n",
        "                 self.learnings_updated_this_session_flag = True\n",
        "                 print(f\"Stored new learning. Cache size: {len(self.active_learnings_cache)}\")\n",
        "\n",
        "\n",
        "    def extract_keywords(self, text: str) -> List[str]: # Same as before\n",
        "        if not text: return [\"general\"]\n",
        "        words = re.findall(r'\\\\b\\\\w{4,}\\\\b', text.lower())\n",
        "        stop_words = {\"the\", \"and\", \"is\", \"in\", \"to\", \"a\", \"of\", \"for\", \"with\", \"on\", \"at\", \"what\", \"how\", \"show\", \"tell\", \"please\", \"user\", \"query\", \"this\", \"that\", \"context\", \"claude\", \"anthropic\", \"before\", \"after\", \"state\", \"action\", \"truth\", \"ground\", \"learnings\"}\n",
        "        extracted = list(set(word for word in words if word not in stop_words and not word.isdigit()))\n",
        "        return extracted if extracted else [\"generic\"]\n",
        "\n",
        "    def extract_score(self, evaluation_text: str) -> int: # Same as before\n",
        "        patterns = [rf\"Overall Score.*?[:\\\\s]*(\\\\d+)/10\", rf\"Overall Score.*?[:\\\\s]*(\\\\d+)\"]\n",
        "        for p_str in patterns:\n",
        "            match = re.search(p_str, evaluation_text, re.IGNORECASE | re.DOTALL)\n",
        "            if match and match.group(1):\n",
        "                try: return int(match.group(1))\n",
        "                except ValueError: continue\n",
        "        return 0 # Default if not found\n",
        "\n",
        "    def process_human_feedback_actions(self, feedback: str, target_storage: Optional[Storage]): # Same as before\n",
        "        # ... (implementation)\n",
        "        return \"No specific data action taken from evaluator feedback.\"\n",
        "\n",
        "print(\"AgentEvaluator class MODIFIED with query classification and gated prompt logic.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzLHm8MmSOMC",
        "outputId": "4f518060-0584-441f-8d62-d79352be7b96"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AgentEvaluator class MODIFIED with query classification and gated prompt logic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"\\\\nStarting Main Execution (Single Agent - Anthropic) with MODIFIED Evaluator...\\\\n\")\n",
        "    try:\n",
        "        agent = AgentEvaluator()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to initialize AgentEvaluator: {e}\")\n",
        "        import traceback; traceback.print_exc()\n",
        "        return\n",
        "\n",
        "    results_log = []\n",
        "    while True:\n",
        "        try:\n",
        "            user_query = input(\"\\\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): \")\n",
        "            if user_query.lower() in ['quit', 'exit', 'stop', 'q']:\n",
        "                print(\"Exiting the system. Goodbye!\")\n",
        "                if agent.learnings_updated_this_session_flag:\n",
        "                    print(\"Persisting final session learnings to Drive...\")\n",
        "                    agent._persist_active_learnings_to_drive()\n",
        "                break\n",
        "            if not user_query.strip(): print(\"Empty query, please enter something.\"); continue\n",
        "\n",
        "            result = agent.process_user_request(user_query)\n",
        "            results_log.append(result)\n",
        "        except SystemExit as se:\n",
        "            print(f\"System exit requested: {se}\")\n",
        "            if agent.learnings_updated_this_session_flag:\n",
        "                print(\"Persisting session learnings to Drive before exiting...\")\n",
        "                agent._persist_active_learnings_to_drive()\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"CRITICAL ERROR processing query '{user_query}': {e}\")\n",
        "            import traceback; traceback.print_exc()\n",
        "            results_log.append({\"user_message\": user_query, \"anthropic_response\": \"ERROR\",\n",
        "                                \"evaluation\": {\"anthropic_score\": 0, \"full_evaluation\": f\"Critical error: {e}\",\n",
        "                                               \"clarification_details\": {\"used\": False, \"action_summary\": \"\"}}})\n",
        "    print(\"\\\\n\\\\n===== EVALUATION SUMMARY =====\")\n",
        "    total_anthropic_score, num_q = 0, 0\n",
        "    for i, res in enumerate(results_log):\n",
        "        if not res: print(f\"\\\\nQuery {i+1}: Skipped (empty result).\"); continue\n",
        "        num_q +=1\n",
        "        print(f\"\\\\nQuery {i+1}: {res.get('user_message', 'N/A')}\")\n",
        "        print(f\"  Anthropic Resp: {str(res.get('anthropic_response', 'N/A'))[:250]}...\")\n",
        "        eval_data = res.get('evaluation', {})\n",
        "        anth_s = eval_data.get('anthropic_score', 0)\n",
        "        total_anthropic_score += anth_s\n",
        "        print(f\"  Score - Anthropic: {anth_s}\")\n",
        "        # Log initial and final states if available in eval_data for review\n",
        "        if \"initial_datastore_state_provided_to_eval\" in eval_data:\n",
        "            print(f\"    Initial DS Orders: {len(eval_data['initial_datastore_state_provided_to_eval'].get('orders', {}))}, Products Inv P3: {eval_data['initial_datastore_state_provided_to_eval'].get('products', {}).get('P3',{}).get('inventory_count', 'N/A')}\")\n",
        "        if \"final_datastore_state_provided_to_eval\" in eval_data:\n",
        "            print(f\"    Final DS Orders: {len(eval_data['final_datastore_state_provided_to_eval'].get('orders', {}))}, Products Inv P3: {eval_data['final_datastore_state_provided_to_eval'].get('products', {}).get('P3',{}).get('inventory_count', 'N/A')}\")\n",
        "\n",
        "        clarif_details = eval_data.get('clarification_details',{})\n",
        "        if clarif_details.get('used'):\n",
        "            print(f\"    Evaluator Clarification: Needed='{clarif_details.get('needed', 'N/A')}', Provided='{clarif_details.get('provided_input', 'N/A')}'\")\n",
        "            if clarif_details.get('action_summary'): print(f\"    Action from Evaluator Clarification: {clarif_details['action_summary']}\")\n",
        "    print(f\"\\\\n----- Overall Performance -----\")\n",
        "    if num_q > 0: print(f\"Avg Anthropic Score: {total_anthropic_score/num_q:.2f}\")\n",
        "    else: print(\"No queries processed.\")\n",
        "    print(f\"Total Anthropic Score: {total_anthropic_score}\")\n",
        "    print(f\"\\\\nLearnings are stored in: {LEARNINGS_DRIVE_BASE_PATH}\")\n",
        "    latest_learnings_file = agent._get_latest_learnings_filepath_from_drive()\n",
        "    if latest_learnings_file: print(f\"Most recent learnings file: {os.path.basename(latest_learnings_file)}\")\n",
        "    else: print(\"No learnings files found.\")\n",
        "    print(\"\\\\nExecution Finished.\")\n",
        "\n",
        "# To run in a new cell:\n",
        "# main()"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "id": "O2-ztJ2BO7gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Sample queries:\n",
        "* Show me all the products available\n",
        "* I'd like to order 25 Perplexinators, please\n",
        "* Show me the status of my order\n",
        "* (If the order is not in Shipped state, then) Please ship my order now\n",
        "* How many Perplexinators are now left in stock?\n",
        "* Add a new customer: Bill Leece, bill.leece@mail.com, +1.222.333.4444\n",
        "* Add new new product: Gizmo X, description: A fancy gizmo, price: 29.99, inventory: 50\n",
        "* Update Gizzmo's price to 99.99 #Note the misspelling of 'Gizmo'\n",
        "* Who won the 2020 US presidential election?\n",
        "* I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount.\n",
        "* Summarize your learnings from our recent interactions.\n",
        "\"\"\"\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dg85ek6bSvW5",
        "outputId": "45cefb6a-1d00-4375-b49d-0a5f8872cdcd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nStarting Main Execution (Single Agent - Anthropic) with MODIFIED Evaluator...\\n\n",
            "AgentEvaluator initialized. Loaded 0 initial learnings.\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): Show me all the products available\n",
            "\\n============================================================\\nUser Message: Show me all the products available\\n============================================================\n",
            "--- Classified Query Type: OPERATIONAL ---\n",
            "[Tool Executed] list_all_products: Found 3 products (in Storage).\n",
            "[Context Updated] Last Action: tool_list_all_products_Anthropic, Details: {\"input\": {}, \"result\": {\"status\": \"success\", \"count\": 3, \"products\": {\"P1\": {\"name\": \"Widget A\", \"description\": \"A simple widget. Very compact.\", \"price\": 19.99, \"inventory_count\": 999}, \"P2\": {\"name\": \"Gadget B\", \"description\": \"A powerful gadget. It spins.\", \"price\": 49.99, \"inventory_count\": 200}, \"P3\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1483}}}}\n",
            "\\n--- Starting Evaluation by Gemini (Query Type: OPERATIONAL) ---\n",
            "Gemini Raw Evaluation:\\nEVALUATION:\n",
            "\n",
            "1.  **Accuracy**:\n",
            "    *   **Score**: 10/10\n",
            "    *   **Reasoning**: The AI's textual response is entirely correct and factual. It accurately lists all three products (\"Widget A\", \"Gadget B\", \"Perplexinator\") along with their descriptions, prices, and inventory counts as present in the 'Data Store State *Before* AI Action'. The 'Data Store State *After* AI Action' shows no changes, which is correct for an OPERATIONAL query that only involves reading data (showing products). No data modification was intended or claimed, and none occurred.\n",
            "\n",
            "2.  **Efficiency**:\n",
            "    *   **Score**: 10/10\n",
            "    *   **Reasoning**: The assistant achieved its goal without any clarifying questions, which were not needed for this straightforward query. The response was direct and provided all the requested information. Since this is a read operation, the implicit tool call (data retrieval) was used appropriately.\n",
            "\n",
            "3.  **Context Awareness**:\n",
            "    *   **Score**: 10/10\n",
            "    *   **Reasoning**: There was no prior conversation history or specific entities to leverage beyond the current query. The AI correctly understood the OPERATIONAL nature of the query (\"Show me all the products available\") and performed the task of retrieving and displaying product information from the data store. No RAG learnings were provided.\n",
            "\n",
            "4.  **Helpfulness**:\n",
            "    *   **Score**: 10/10\n",
            "    *   **Reasoning**: The assistant's response fully addressed the user's need as defined by the OPERATIONAL query type. The list of products is clear, well-formatted, and provides all relevant details (description, price, stock). The concluding question, \"Is there anything specific you'd like to know about any of these products?\" is a good way to prompt further interaction and offer additional assistance.\n",
            "\n",
            "**Overall Score**: 10/10\n",
            "**Reasoning**: The AI perfectly handled this OPERATIONAL query. It accurately retrieved and presented all available products from the data store without any errors or unnecessary steps. The response was efficient, contextually appropriate, and very helpful to the user.\n",
            "General learning from this turn? (or 'skip'): skip\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): I'd like to order 25 Perplexinators, please\n",
            "\\n============================================================\\nUser Message: I'd like to order 25 Perplexinators, please\\n============================================================\n",
            "--- Classified Query Type: OPERATIONAL ---\n",
            "[Tool Helper] find_product_by_name: Matched 'Perplexinator' to 'Perplexinator' (ID: P3) with score 100 (in Storage)\n",
            "[Tool Executed] create_order: Order O3 created for 25 of Perplexinator (ID: P3). Status: Processing. Remaining inv: 1483 (in Storage)\n",
            "[Context Updated] Entity: orders, ID: O3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_create_order_Anthropic, Details: {\"input\": {\"product_id_or_name\": \"Perplexinator\", \"quantity\": 25, \"status\": \"Processing\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O3\", \"order_details\": {\"id\": \"O3\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 25, \"price\": 79.99, \"status\": \"Processing\"}, \"remaining_inventory\": 1483}}\n",
            "\\n--- Starting Evaluation by Gemini (Query Type: OPERATIONAL) ---\n",
            "Gemini Raw Evaluation:\\n**1. Accuracy**\n",
            "    - Score: 5/10\n",
            "    - Reasoning: The AI's textual response accurately summarized the details of the order (Order ID: O3, Quantity: 25, Price per unit: $79.99, Total price: $1,999.75, Status: Processing). The `Data Store State *After* AI Action` confirms that a new order O3 was created with these correct details: `{\"id\": \"O3\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 25, \"price\": 79.99, \"status\": \"Processing\"}`.\n",
            "    However, the AI claimed the order was \"successfully placed\". A critical aspect of successfully placing an order involving physical stock is updating the inventory. The `products.P3.inventory_count` was 1483 *Before* and remained 1483 *After* the action. It should have been updated to 1483 - 25 = 1458. This failure to modify the inventory means the datastore was not correctly and completely modified as intended by an \"order\" operation.\n",
            "\n",
            "**2. Efficiency**\n",
            "    - Score: 9/10\n",
            "    - Reasoning: The assistant directly understood the user's request and proceeded to create the order record without asking any clarification questions. It achieved the *creation of the order record* efficiently. The missing inventory update is an accuracy/completeness issue rather than an efficiency one in terms of conversational turns.\n",
            "\n",
            "**3. Context Awareness**\n",
            "    - Score: 10/10\n",
            "    - Reasoning: The assistant correctly identified \"Perplexinators\" from the user's query and presumably mapped it to product P3 using information available from previous turns (e.g., `tool_list_all_products_Anthropic`). It used the correct price for P3 ($79.99) and quantity (25) to create the order. The assistant adhered to the OPERATIONAL task type by performing a datastore modification.\n",
            "\n",
            "**4. Helpfulness**\n",
            "    - Score: 7/10\n",
            "    - Reasoning: The assistant was helpful in that it acknowledged the user's request and provided a clear confirmation and summary of the order it created. The offer for further assistance (\"Would you like me to track the status of your order or is there anything else you need help with?\") is also good. However, the underlying failure to update inventory, while not visible to the user from the AI's response, means the order wasn't truly \"successfully placed\" in a complete sense, which slightly reduces overall helpfulness from a system perspective.\n",
            "\n",
            "**Overall Score:** 7/10\n",
            "    - Reasoning: The AI successfully created an order record with accurate details as per the user's request and communicated this clearly. It was efficient and context-aware. However, the significant failure to update the product inventory in the datastore is a major flaw in an OPERATIONAL task of this nature, impacting the accuracy of the overall operation. While the user receives a confirmation, the backend state is inconsistent.\n",
            "General learning from this turn? (or 'skip'): When there is sufficient inventory for an order, the order should immediately ship. This means that the order should also automatically be set to \"Shipped\" state. If there is not sufficient inventory to complete the order, the Agent should notify the user and the order will remain in \"Processing\" state until there is sufficient inventory to complete the order.\n",
            "--- Processing New Learning: \"When there is sufficient inventory for an order, the order should immediately ship. This means that the order should also automatically be set to \"Shipped\" state. If there is not sufficient inventory to complete the order, the Agent should notify the user and the order will remain in \"Processing\" state until there is sufficient inventory to complete the order.\" ---\n",
            "Stored new learning. Cache size: 1\n",
            "Persisted 1 learnings to /content/drive/My Drive/AI/Knowledgebases/learnings_20250519_174939_598070.json\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): Show me the status of my order\n",
            "\\n============================================================\\nUser Message: Show me the status of my order\\n============================================================\n",
            "--- Classified Query Type: OPERATIONAL ---\n",
            "[Tool Executed] get_order_details: Order O3 found (in Storage).\n",
            "[Context Updated] Entity: orders, ID: O3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_get_order_details_Anthropic, Details: {\"input\": {\"order_id\": \"O3\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O3\", \"order_details\": {\"id\": \"O3\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 25, \"price\": 79.99, \"status\": \"Processing\"}}}\n",
            "\\n--- Starting Evaluation by Gemini (Query Type: OPERATIONAL) ---\n",
            "Gemini Raw Evaluation:\\nEVALUATION:\n",
            "\n",
            "1.  **Accuracy**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The AI's textual response accurately reflects the state of order O3 as per the 'Data Store State *Before* AI Action' and the provided context (\"Recent orders: ID: O3 (Product: Perplexinator, Status: Processing)\").\n",
            "        *   Order ID: O3 (Correct)\n",
            "        *   Product: Perplexinator (Correct, matches P3 in datastore and O3)\n",
            "        *   Quantity: 25 units (Correct for O3)\n",
            "        *   Price per unit: $79.99 (Correct for O3, derived from product P3 price)\n",
            "        *   Status: Processing (Correct for O3)\n",
            "    *   The statement \"Based on our inventory levels, we should be able to ship this order soon\" is accurate. Product P3 (Perplexinator) has an inventory count of 1483, and order O3 is for 25 units, so inventory is sufficient.\n",
            "    *   No tool calls were made by the AI in this step, which is appropriate for a query asking to \"show\" status. The AI offers a subsequent action (\"Would you like me to update the status to 'Shipped' now?\"), but does not perform it.\n",
            "    *   The 'Data Store State *After* AI Action' is identical to the 'Before' state, which is correct as no update operation was performed or should have been performed without explicit confirmation for the proposed action.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "2.  **Efficiency**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The assistant achieved its primary goal of showing the order status directly and without any clarifying questions.\n",
            "    *   The proactive offer to update the status to \"Shipped\" is a logical next step and can be seen as efficient in anticipating user needs, rather than waiting for a separate follow-up query.\n",
            "    *   No unnecessary tool calls were made.\n",
            "    *   **Score**: 9/10 (Highly efficient; the proactive offer is generally good, a slight improvement in phrasing of the offer might be possible but doesn't significantly detract from efficiency).\n",
            "\n",
            "3.  **Context Awareness**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The assistant correctly used the conversation history (\"Recent orders: ID: O3...\") to identify the relevant order the user was asking about.\n",
            "    *   It adhered to the OPERATIONAL task by focusing on retrieving and presenting order-specific information.\n",
            "    *   The \"Relevant RAG Learnings from Knowledge Base\" provided (`- Learning (ID: 3f8e4e06): [statement]`...\": This describes a *process* for the AI to follow when handling new feedback...`) was meta-instructional and not directly relevant to the user's query about order status. The AI correctly did not attempt to summarize or use this learning in its response to the user.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "4.  **Helpfulness**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The assistant was very helpful. It clearly and accurately provided all the key details of the order status.\n",
            "    *   The additional context (\"Based on our inventory levels, we should be able to ship this order soon.\") adds valuable information.\n",
            "    *   The proactive question \"Would you like me to update the status to 'Shipped' now?\" addresses a likely next step for the user, given the sufficient inventory, making the interaction more helpful.\n",
            "    *   **Score**: 9/10 (Very helpful in providing the requested information and anticipating the next logical step for the user).\n",
            "\n",
            "**Overall Score**: 9.5/10 (Calculated as (10+9+10+9)/4)\n",
            "\n",
            "**Reasoning for Overall Score**:\n",
            "The AI performed very well on this OPERATIONAL query. It accurately retrieved and presented the order status, using the available context correctly. It did not make any premature or incorrect changes to the data store. The proactive offer to update the order status, based on an implicit check of inventory, was a helpful addition that anticipated the user's needs without overstepping. The AI also correctly ignored the irrelevant RAG learning provided in the context. The response was clear, efficient, and contextually aware.\n",
            "\n",
            "No clarification questions were asked by the AI, which was appropriate.\n",
            "The data store states confirm no unauthorized changes were made.\n",
            "General learning from this turn? (or 'skip'): skip\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): Please ship my order\n",
            "\\n============================================================\\nUser Message: Please ship my order\\n============================================================\n",
            "--- Classified Query Type: OPERATIONAL ---\n",
            "[Tool Executed] update_order_status: Order O3 Shipped. Inv for P3 reduced by 25 to 1458 (in Storage).\n",
            "[Tool Executed] update_order_status: Order O3 status updated from Processing to Shipped (in Storage).\n",
            "[Context Updated] Entity: orders, ID: O3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_update_order_status_Anthropic, Details: {\"input\": {\"order_id\": \"O3\", \"new_status\": \"Shipped\"}, \"result\": {\"status\": \"success\", \"message\": \"Order O3 status updated from Processing to Shipped.\", \"order_id\": \"O3\", \"product_id\": \"P3\", \"old_status\": \"Processing\", \"new_status\": \"Shipped\", \"inventory_adjusted\": true, \"current_inventory\": 1458, \"order_details\": {\"id\": \"O3\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 25, \"price\": 79.99, \"status\": \"Shipped\"}}}\n",
            "\\n--- Starting Evaluation by Gemini (Query Type: OPERATIONAL) ---\n",
            "Gemini Raw Evaluation:\\nEVALUATION:\n",
            "\n",
            "1.  **Accuracy**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The AI's textual response is accurate and reflects the changes made.\n",
            "        *   \"Order ID: O3 is now marked as \"Shipped\"\": Verified. In the 'Data Store State *Before* AI Action', `orders.O3.status` was \"Processing\". In the 'Data Store State *After* AI Action', `orders.O3.status` is \"Shipped\". This is correct.\n",
            "        *   \"25 Perplexinators are on their way to you\": Verified. `orders.O3.quantity` is 25, and the product is \"Perplexinator\". This is consistent with the order details.\n",
            "        *   \"The inventory has been automatically adjusted\": Verified. Before, `products.P3.inventory_count` (for Perplexinator, ID P3) was 1483. After, it is 1458. The difference is 1483 - 1458 = 25, which matches the quantity of order O3. This is correct.\n",
            "    *   The actions (inferred tool calls) correctly modified the datastore as intended and claimed.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "2.  **Efficiency**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The assistant achieved its goal without asking any clarifying questions. The user's request \"Please ship my order\" was clear given the context of order O3 being \"Processing\".\n",
            "    *   The inferred tool calls (to update order status and product inventory) were appropriate and necessary to fulfill the request.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "3.  **Context Awareness**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The assistant correctly used the conversation history. The \"Last action\" was `tool_get_order_details_Anthropic at 2025-05-19T17:49:55.875181 (Input: {'order_id': 'O3'}, Result Status: success, OrderID: O3)`. The AI correctly identified order O3 as the target for the \"ship\" command.\n",
            "    *   The assistant adhered to the task defined by the OPERATIONAL query type by performing an action (shipping the order and updating the datastore).\n",
            "    *   The \"Relevant RAG Learnings\" provided (\"Learning (ID: 3f8e4e06)...\") were about the AI's process for handling feedback and not relevant to the operational task of shipping an order. The AI correctly did not attempt to use this learning for the current task.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "4.  **Helpfulness**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The assistant fully addressed the user's need to ship their order. The response was clear, confirmed the action taken, and provided relevant details (order ID, product, quantity, status update, inventory adjustment).\n",
            "    *   The offer \"Is there anything else you need help with?\" is appropriate.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "**Overall Score**: 10/10\n",
            "\n",
            "**Reasoning for Overall Score**:\n",
            "The AI assistant performed exceptionally well on this OPERATIONAL query. It correctly identified the order in context (O3), updated its status to \"Shipped\", and correctly adjusted the product inventory. The textual response accurately communicated these actions to the user in a clear and helpful manner. The datastore changes between the 'Before' and 'After' states perfectly match the AI's claims and the user's request. No unnecessary clarifications were asked. The irrelevant RAG learning was appropriately ignored.\n",
            "General learning from this turn? (or 'skip'): skip\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): I'd like to order 15 Widget As, please\n",
            "\\n============================================================\\nUser Message: I'd like to order 15 Widget As, please\\n============================================================\n",
            "--- Classified Query Type: OPERATIONAL ---\n",
            "[Tool Helper] find_product_by_name: Matched 'Widget A' to 'Widget A' (ID: P1) with score 100 (in Storage)\n",
            "[Tool Executed] create_order: Order O4 created for 15 of Widget A (ID: P1). Status: Processing. Remaining inv: 999 (in Storage)\n",
            "[Context Updated] Entity: orders, ID: O4, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_create_order_Anthropic, Details: {\"input\": {\"product_id_or_name\": \"Widget A\", \"quantity\": 15, \"status\": \"Processing\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O4\", \"order_details\": {\"id\": \"O4\", \"product_id\": \"P1\", \"product_name\": \"Widget A\", \"quantity\": 15, \"price\": 19.99, \"status\": \"Processing\"}, \"remaining_inventory\": 999}}\n",
            "\\n--- Starting Evaluation by Gemini (Query Type: OPERATIONAL) ---\n",
            "Gemini Raw Evaluation:\\n**1. Accuracy**\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**:\n",
            "        *   **Textual Response**: The AI's response accurately reflects the creation of a new order.\n",
            "            *   Product: \"Widget A\" (P1 in datastore, price $19.99)\n",
            "            *   Quantity: 15\n",
            "            *   Price per unit: $19.99 (Correct, from P1)\n",
            "            *   Total price: 15 * $19.99 = $299.85 (Correctly calculated)\n",
            "            *   Order ID: \"O4\" (This is a new ID)\n",
            "            *   Status: \"Processing\" (This is an appropriate initial status before explicit shipping confirmation).\n",
            "        *   **Datastore Actions**:\n",
            "            *   Comparing 'Data Store State *Before* AI Action' and 'Data Store State *After* AI Action', a new order \"O4\" has been added to the `orders` table.\n",
            "            *   The details of order \"O4\" in the 'After' state are:\n",
            "                *   `id: \"O4\"`\n",
            "                *   `product_id: \"P1\"` (Corresponds to \"Widget A\")\n",
            "                *   `product_name: \"Widget A\"`\n",
            "                *   `quantity: 15`\n",
            "                *   `price: 19.99`\n",
            "                *   `status: \"Processing\"`\n",
            "            *   All these details match the user's request and the AI's textual summary. The inventory for \"Widget A\" (P1) was 999, which is sufficient for 15 units, so the order creation is valid.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "**2. Efficiency**\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**:\n",
            "        *   The AI did not ask any clarification questions, as the user's query was clear and unambiguous.\n",
            "        *   The AI directly proceeded to create the order using an appropriate tool call (inferred, as the datastore was updated correctly).\n",
            "        *   The goal was achieved in a single, efficient step.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "**3. Context Awareness**\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**:\n",
            "        *   The AI correctly identified the product \"Widget A\" and the quantity \"15\" from the user's query.\n",
            "        *   It correctly used information from the existing datastore (product P1's details like name and price).\n",
            "        *   It generated a new, unique order ID (\"O4\").\n",
            "        *   The AI adhered to the OPERATIONAL task of creating an order.\n",
            "        *   The \"Recent orders\" and \"Last action\" context were not directly relevant to this new order creation and the AI correctly did not misuse them.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "**4. Helpfulness**\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**:\n",
            "        *   The AI successfully fulfilled the user's explicit request to order 15 Widget As.\n",
            "        *   The response provides a clear and concise summary of the created order, including all relevant details (Order ID, quantity, price, total, status).\n",
            "        *   The follow-up question, \"Would you like me to ship this order for you right away?\", is a very helpful and proactive next step, anticipating the user's likely next need.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "**Overall Score**: 10/10\n",
            "\n",
            "**Reasoning for Overall Score**:\n",
            "The AI performed exceptionally well on this OPERATIONAL task.\n",
            "*   **Accuracy**: It correctly interpreted the user's request, accurately calculated the total price, and the 'Data Store State *After* AI Action' confirms that the order \"O4\" was created with all the correct details (product_id \"P1\", product_name \"Widget A\", quantity 15, price 19.99, status \"Processing\").\n",
            "*   **Efficiency**: The task was completed directly without any unnecessary clarification questions.\n",
            "*   **Context Awareness**: The AI correctly used product information from the datastore and generated a new order ID, demonstrating awareness of the existing data and the need for new entities.\n",
            "*   **Helpfulness**: The AI not only fulfilled the request but also provided a clear summary and a proactive follow-up question about shipping, making the interaction very smooth for the user.\n",
            "\n",
            "The assistant correctly created the order as requested, updated the datastore appropriately, and confirmed the action with the user in a clear manner.\n",
            "General learning from this turn? (or 'skip'): When inventory is available, orders should be set immediately to Shipped state. This order is still in \"Processing\" state, which is not what should happen as there is sufficient inventory to ship now. \n",
            "--- Processing New Learning: \"When inventory is available, orders should be set immediately to Shipped state. This order is still in \"Processing\" state, which is not what should happen as there is sufficient inventory to ship now.\" ---\n",
            "Stored new learning. Cache size: 2\n",
            "Persisted 2 learnings to /content/drive/My Drive/AI/Knowledgebases/learnings_20250519_175415_323784.json\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): I'd like to order 5 Widget As, please.\n",
            "\\n============================================================\\nUser Message: I'd like to order 5 Widget As, please.\\n============================================================\n",
            "--- Classified Query Type: OPERATIONAL ---\n",
            "[Tool Helper] find_product_by_name: Matched 'Widget A' to 'Widget A' (ID: P1) with score 100 (in Storage)\n",
            "[Tool Executed] create_order: Inventory for Widget A (ID: P1) reduced by 5 due to 'Shipped' status on creation (in Storage).\n",
            "[Tool Executed] create_order: Order O5 created for 5 of Widget A (ID: P1). Status: Shipped. Remaining inv: 994 (in Storage)\n",
            "[Context Updated] Entity: orders, ID: O5, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: tool_create_order_Anthropic, Details: {\"input\": {\"product_id_or_name\": \"Widget A\", \"quantity\": 5, \"status\": \"Shipped\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O5\", \"order_details\": {\"id\": \"O5\", \"product_id\": \"P1\", \"product_name\": \"Widget A\", \"quantity\": 5, \"price\": 19.99, \"status\": \"Shipped\"}, \"remaining_inventory\": 994}}\n",
            "\\n--- Starting Evaluation by Gemini (Query Type: OPERATIONAL) ---\n",
            "Gemini Raw Evaluation:\\nEVALUATION:\n",
            "\n",
            "1.  **Accuracy**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The AI's textual response is entirely accurate.\n",
            "        *   It states an order (O5) for 5 Widget As was created. The 'Data Store State *After* AI Action' shows a new order O5 with `product_id: \"P1\"` (Widget A), `quantity: 5`.\n",
            "        *   It states the price per unit is $19.99 and total price is $99.95. The 'After' state shows `price: 19.99` for O5. (5 * 19.99 = 99.95). This is correct.\n",
            "        *   It states the status is \"Shipped\". The 'After' state for O5 shows `status: \"Shipped\"`.\n",
            "        *   The 'Data Store State *Before* AI Action' shows \"Widget A\" (P1) had an `inventory_count: 999`.\n",
            "        *   The 'Data Store State *After* AI Action' shows \"Widget A\" (P1) has an `inventory_count: 994`. This correctly reflects the 5 units ordered (999 - 5 = 994).\n",
            "    *   The AI's actions (implied tool call to create an order) correctly modified the datastore as intended and claimed.\n",
            "    *   A new entity ID (O5) was correctly created and referenced.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "2.  **Efficiency**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The AI achieved its goal without any clarifying questions. The user's query \"I'd like to order 5 Widget As, please\" was clear and unambiguous.\n",
            "    *   The AI (implicitly) used the `create_order` tool appropriately and directly fulfilled the request.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "3.  **Context Awareness**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The AI correctly understood the user's request for \"Widget A\" and a quantity of \"5\".\n",
            "    *   Crucially, it correctly applied the \"Relevant Learnings from Knowledge Base\": \"Learning (ID: e6b660f3): When inventory is available, orders should be set immediately to Shipped state.\"\n",
            "        *   The inventory for Widget A was 999 (available for an order of 5).\n",
            "        *   The AI correctly set the order status to \"Shipped\", as confirmed in the 'After' state and the textual response.\n",
            "    *   The AI adhered to the task defined by the OPERATIONAL query type.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "4.  **Helpfulness**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The AI fully addressed the user's needs. The user wanted to order 5 Widget As, and the AI confirmed the order was created and shipped.\n",
            "    *   The response was clear, concise, and provided all relevant information: order ID, quantity, product name (implied by \"Widget As\"), price details, and status.\n",
            "    *   The confirmation \"Your order is on its way!\" and the offer for further assistance (\"Is there anything else you need help with?\") are helpful and good customer service.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "**Overall Score**: 10/10\n",
            "\n",
            "**Reasoning for Overall Score**:\n",
            "The AI's response was exemplary for an OPERATIONAL query.\n",
            "*   It accurately processed the user's request, creating a new order (O5) for 5 units of \"Widget A\".\n",
            "*   The data store was updated correctly: a new order was added, and the product inventory for \"Widget A\" was reduced accordingly.\n",
            "*   The AI correctly applied the provided RAG learning by setting the order status to \"Shipped\" because inventory was available.\n",
            "*   The textual response was clear, confirmed all actions, provided all necessary details (order ID, quantity, price, status), and was polite.\n",
            "*   No clarification questions were needed, and the AI acted efficiently.\n",
            "This is a perfect execution of the requested operational task.\n",
            "General learning from this turn? (or 'skip'): skip\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): Who won the 2020 US presidential election?\n",
            "\\n============================================================\\nUser Message: Who won the 2020 US presidential election?\\n============================================================\n",
            "--- Classified Query Type: OPERATIONAL ---\n",
            "\\n--- Starting Evaluation by Gemini (Query Type: OPERATIONAL) ---\n",
            "Gemini Raw Evaluation:\\nEVALUATION:\n",
            "\n",
            "1.  **Accuracy**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The AI's textual response is accurate. It correctly identifies that the user's query (\"Who won the 2020 US presidential election?\") is outside its scope as an e-commerce customer service assistant. It states its limitations clearly. No tool calls were made, which is appropriate for this type of out-of-scope query. The 'Data Store State *Before* AI Action' and 'Data Store State *After* AI Action' are identical, confirming no unintended modifications occurred.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "2.  **Efficiency**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The AI achieved its goal (responding appropriately to an out-of-scope query) without any clarifying questions. The response was direct and did not involve unnecessary steps.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "3.  **Context Awareness**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The AI correctly understood that the user's query did not pertain to its operational domain (e-commerce). It did not try to misuse the provided context (recent orders, learnings) to answer an unrelated question. It effectively managed an OPERATIONAL query by identifying its inability to perform the requested operation and guiding the user.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "4.  **Helpfulness**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The AI was helpful by clearly stating its limitations and then proactively offering assistance with tasks within its capabilities. This manages user expectations and redirects the conversation productively. While it couldn't answer the specific question asked, it provided the *most helpful response possible* given its design.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "**Overall Score**: 10/10\n",
            "\n",
            "**Reasoning for Overall Score**:\n",
            "The AI's response is excellent for an OPERATIONAL query that falls outside its designated scope.\n",
            "- It accurately identified its inability to answer the political question.\n",
            "- It did so efficiently, without unnecessary questions.\n",
            "- It demonstrated context awareness by not trying to force an e-commerce-related answer.\n",
            "- It was helpful by explaining its limitations and offering alternative, relevant assistance.\n",
            "No tool calls were made, and the data store remained unchanged, which is the correct behavior for this scenario. The AI handled the out-of-domain query perfectly.\n",
            "General learning from this turn? (or 'skip'): This is a great answer for an out of scope question. You should not answer out of scope questions.\n",
            "--- Processing New Learning: \"This is a great answer for an out of scope question. You should not answer out of scope questions.\" ---\n",
            "Stored new learning. Cache size: 3\n",
            "Persisted 3 learnings to /content/drive/My Drive/AI/Knowledgebases/learnings_20250519_175750_694613.json\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount.\n",
            "\\n============================================================\\nUser Message: I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount.\\n============================================================\n",
            "--- Classified Query Type: OPERATIONAL ---\n",
            "[Tool Executed] list_all_products: Found 3 products (in Storage).\n",
            "[Context Updated] Last Action: tool_list_all_products_Anthropic, Details: {\"input\": {}, \"result\": {\"status\": \"success\", \"count\": 3, \"products\": {\"P1\": {\"name\": \"Widget A\", \"description\": \"A simple widget. Very compact.\", \"price\": 19.99, \"inventory_count\": 994}, \"P2\": {\"name\": \"Gadget B\", \"description\": \"A powerful gadget. It spins.\", \"price\": 49.99, \"inventory_count\": 200}, \"P3\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1458}}}}\n",
            "\\n--- Starting Evaluation by Gemini (Query Type: OPERATIONAL) ---\n",
            "Gemini Raw Evaluation:\\nEVALUATION:\n",
            "\n",
            "1.  **Accuracy**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The AI attempted to calculate the total value of all products in inventory. It correctly identified the products (Widget A, Gadget B, Perplexinator) and their respective inventory counts (994, 200, 1458) and prices ($19.99, $49.99, $79.99) from the 'Data Store State *Before* AI Action'.\n",
            "        *   For \"Widget A\": The AI calculated 994 units × $19.99 = $19,879.06. The correct calculation is 994 * $19.99 = $19,870.06. The AI's calculation is off by $9.00.\n",
            "        *   For \"Gadget B\": The AI calculated 200 units × $49.99 = $9,998.00. This is correct (200 * $49.99 = $9,998.00).\n",
            "        *   For \"Perplexinator\": The AI calculated 1,458 units × $79.99 = $116,625.42. This is correct (1458 * $79.99 = $116,625.42).\n",
            "    *   The AI's reported total inventory value is $146,502.48. This sum is consistent with its own (partially incorrect) individual calculations ($19,879.06 + $9,998.00 + $116,625.42 = $146,502.48).\n",
            "    *   The correct total inventory value, based on correct individual calculations, should be $19,870.06 + $9,998.00 + $116,625.42 = $146,493.48. The AI's total is therefore incorrect by $9.00.\n",
            "    *   No tool calls were made, and the 'Data Store State *Before* AI Action' and 'Data Store State *After* AI Action' are identical, which is appropriate as this query only requires reading and calculating data, not modifying it.\n",
            "    *   **Score**: 5/10 (While the method and most calculations were correct, a significant numerical error was made in one calculation, which propagated to the final total. For an operational query requesting a specific monetary value, this level of inaccuracy is problematic.)\n",
            "\n",
            "2.  **Efficiency**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The assistant did not ask any clarifying questions, and none were needed as the user's query was clear and the required data was available in the datastore. It directly provided the answer based on the available data. No tool calls were used or necessary.\n",
            "    *   **Score**: 10/10 (The AI was maximally efficient in its approach.)\n",
            "\n",
            "3.  **Context Awareness**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The AI correctly understood that the user needed the total value of products in inventory. It correctly used the product details (price, inventory_count) from the provided 'Data Store State *Before* AI Action'. It adhered to the OPERATIONAL task by performing calculations based on the current state of the data. The provided RAG learnings were not directly applicable to this calculation, and the AI did not inappropriately try to apply them.\n",
            "    *   **Score**: 10/10 (Excellent use of available data and understanding of the task.)\n",
            "\n",
            "4.  **Helpfulness**:\n",
            "    *   **Query Type**: OPERATIONAL\n",
            "    *   **Assessment**: The response format, breaking down the calculation by product before providing the total, is very clear and helpful for the user to understand how the total was derived. However, the numerical inaccuracy in the calculation for \"Widget A\" and the consequently incorrect total value significantly detracts from the helpfulness, as the user would receive an incorrect figure for their insurance purposes.\n",
            "    *   **Score**: 6/10 (The structure is helpful, but the incorrect financial figure reduces its overall utility.)\n",
            "\n",
            "**Overall Score**: 7.8/10 (Calculated as (5+10+10+6)/4)\n",
            "\n",
            "**Reasoning for Overall Score**:\n",
            "The AI correctly identified the task as an OPERATIONAL query requiring calculation of total inventory value. It efficiently accessed the necessary data from the datastore and presented the information in a clear, itemized format. However, a calculation error for one of the products led to an incorrect subtotal for that product and an incorrect overall total inventory value. For an OPERATIONAL query where a precise financial figure is requested, this inaccuracy is a notable flaw. The data store remained unchanged, which is correct. No clarification questions were asked, which was appropriate. The AI demonstrated good context awareness but fell short on accuracy for the core calculation.\n",
            "General learning from this turn? (or 'skip'): skip\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): Summarize your learnings from our recent interactions.\n",
            "\\n============================================================\\nUser Message: Summarize your learnings from our recent interactions.\\n============================================================\n",
            "--- Classified Query Type: METACOGNITIVE_LEARNINGS_SUMMARY ---\n",
            "\\n--- Starting Evaluation by Gemini (Query Type: METACOGNITIVE_LEARNINGS_SUMMARY) ---\n",
            "Gemini Raw Evaluation:\\nEVALUATION:\n",
            "\n",
            "1.  **Accuracy**:\n",
            "    *   **Query Type**: METACOGNITIVE_LEARNINGS_SUMMARY\n",
            "    *   **Assessment**: The AI was tasked with summarizing the \"Relevant RAG Learnings\" provided in its context.\n",
            "        *   The provided RAG Learnings were:\n",
            "            *   \"Learning (ID: 7e949d2a): When a user query is identified as out-of-scope, the AI should decline to answer the query directly and instead state that the query is out of scope.\"\n",
            "            *   \"Learning (ID: e6b660f3): When inventory is available, orders should be set immediately to Shipped state.\"\n",
            "            *   \"Learning (ID: 3f8e4e06): [statement]`...\": This describes a *process* for the AI to follow when handling new feedback, or a meta-learning about its own task. It is not a piece of domain knowledge (like inventory rules) to be summarized for a user.\"\n",
            "        *   The AI's response summarized the first two learnings:\n",
            "            1.  \"Out-of-Scope Queries: When a user query is outside the scope of the e-commerce system (like the political election question), I should decline to answer directly and clearly state that the query is out of scope. (Learning ID: 7e949d2a)\" - This is an accurate summary of learning 7e949d2a. The illustrative example \"like the political election question\" is an addition by the AI but is consistent with the meaning of \"out-of-scope\" and does not detract from the accuracy of the summary of the core learning.\n",
            "            2.  \"Order Shipping Process: When inventory is available, orders should be set immediately to Shipped state. (Learning ID: e6b660f3)\" - This is an accurate summary of learning e6b660f3.\n",
            "        *   The AI correctly omitted summarizing learning 3f8e4e06, as the context explicitly stated it \"is not a piece of domain knowledge (like inventory rules) to be summarized for a user.\"\n",
            "        *   The summary is faithful to the provided relevant learnings.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "2.  **Efficiency**:\n",
            "    *   **Query Type**: METACOGNITIVE_LEARNINGS_SUMMARY\n",
            "    *   **Assessment**: The AI did not ask any clarifying questions. It directly provided a summary of the relevant learnings as requested by the query type. The summary was concise and to the point.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "3.  **Context Awareness**:\n",
            "    *   **Query Type**: METACOGNITIVE_LEARNINGS_SUMMARY\n",
            "    *   **Assessment**: The AI correctly used the \"Relevant Learnings from Knowledge Base\" section of its context. It understood that its task, as defined by the METACOGNITIVE_LEARNINGS_SUMMARY query type, was to summarize these specific learnings. It successfully distinguished between the learnings that were appropriate for user summary and the meta-learning that was not. The phrase \"Based on the Relevant Learnings provided in the context...\" in its response shows it correctly identified the source for its summary.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "4.  **Helpfulness**:\n",
            "    *   **Query Type**: METACOGNITIVE_LEARNINGS_SUMMARY\n",
            "    *   **Assessment**: The AI's response was highly helpful for the identified query type. It provided a clear, accurate, and concise summary of the specific learnings it was supposed to summarize, fulfilling the user's request as interpreted by the query classification.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "**Overall Score**: 10/10\n",
            "\n",
            "**Reasoning for Overall Score**:\n",
            "The AI assistant performed exceptionally well on the task of summarizing its relevant RAG learnings, as defined by the METACOGNITIVE_LEARNINGS_SUMMARY query type.\n",
            "It accurately identified the pertinent learnings from the provided context, summarized them faithfully, and correctly excluded a meta-learning that was not meant for user summary. The response was efficient, requiring no clarifications, and demonstrated excellent context awareness by focusing solely on the provided RAG learnings for the summary. The output was clear, concise, and directly addressed the user's need according to the specified task. The data store states remained unchanged, which is appropriate for this query type.\n",
            "General learning from this turn? (or 'skip'): skip\n",
            "\\nEnter your query (or 'quit', 'exit', 'stop', 'q' to end): quit\n",
            "Exiting the system. Goodbye!\n",
            "\\n\\n===== EVALUATION SUMMARY =====\n",
            "\\nQuery 1: Show me all the products available\n",
            "  Anthropic Resp: Here are all the products currently available:\n",
            "\n",
            "1. Widget A\n",
            "   - Description: A simple widget. Very compact.\n",
            "   - Price: $19.99\n",
            "   - In stock: 999 units\n",
            "\n",
            "2. Gadget B\n",
            "   - Description: A powerful gadget. It spins.\n",
            "   - Price: $49.99\n",
            "   - In stock: 200...\n",
            "  Score - Anthropic: 0\n",
            "\\nQuery 2: I'd like to order 25 Perplexinators, please\n",
            "  Anthropic Resp: Great! I've created your order for 25 Perplexinators. Here's a summary:\n",
            "- Order ID: O3\n",
            "- Quantity: 25 units\n",
            "- Price per unit: $79.99\n",
            "- Total price: $1,999.75\n",
            "- Status: Processing\n",
            "\n",
            "The order has been successfully placed and is being processed. Would y...\n",
            "  Score - Anthropic: 0\n",
            "\\nQuery 3: Show me the status of my order\n",
            "  Anthropic Resp: Your order status:\n",
            "- Order ID: O3\n",
            "- Product: Perplexinator\n",
            "- Quantity: 25 units\n",
            "- Price per unit: $79.99\n",
            "- Status: Processing\n",
            "\n",
            "Your order is currently being processed. Based on our inventory levels, we should be able to ship this order soon. Would yo...\n",
            "  Score - Anthropic: 0\n",
            "\\nQuery 4: Please ship my order\n",
            "  Anthropic Resp: Great! Your order has been updated:\n",
            "- Order ID: O3 is now marked as \"Shipped\"\n",
            "- 25 Perplexinators are on their way to you\n",
            "- The inventory has been automatically adjusted\n",
            "\n",
            "Is there anything else you need help with?...\n",
            "  Score - Anthropic: 0\n",
            "\\nQuery 5: I'd like to order 15 Widget As, please\n",
            "  Anthropic Resp: Great! I've created your order for 15 Widget As. Here's a summary:\n",
            "- Order ID: O4\n",
            "- Quantity: 15 units\n",
            "- Price per unit: $19.99\n",
            "- Total price: $299.85\n",
            "- Status: Processing\n",
            "\n",
            "Would you like me to ship this order for you right away?...\n",
            "  Score - Anthropic: 0\n",
            "\\nQuery 6: I'd like to order 5 Widget As, please.\n",
            "  Anthropic Resp: Great! Your order has been created and shipped:\n",
            "- Order ID: O5\n",
            "- Quantity: 5 Widget As\n",
            "- Price per unit: $19.99\n",
            "- Total price: $99.95\n",
            "- Status: Shipped\n",
            "\n",
            "Your order is on its way! Is there anything else you need help with?...\n",
            "  Score - Anthropic: 0\n",
            "\\nQuery 7: Who won the 2020 US presidential election?\n",
            "  Anthropic Resp: I apologize, but I am an e-commerce customer service assistant focused on helping with orders, products, and customer information. I cannot provide information about political elections or other topics outside of our e-commerce system. \n",
            "\n",
            "I can help y...\n",
            "  Score - Anthropic: 0\n",
            "\\nQuery 8: I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount.\n",
            "  Anthropic Resp: Here's the total value of all products currently in inventory:\n",
            "\n",
            "1. Widget A: 994 units × $19.99 = $19,879.06\n",
            "2. Gadget B: 200 units × $49.99 = $9,998.00\n",
            "3. Perplexinator: 1,458 units × $79.99 = $116,625.42\n",
            "\n",
            "Total inventory value: $146,502.48\n",
            "\n",
            "This ca...\n",
            "  Score - Anthropic: 0\n",
            "\\nQuery 9: Summarize your learnings from our recent interactions.\n",
            "  Anthropic Resp: Based on the Relevant Learnings provided in the context, there are two key learnings from our interactions:\n",
            "\n",
            "1. Out-of-Scope Queries: When a user query is outside the scope of the e-commerce system (like the political election question), I should dec...\n",
            "  Score - Anthropic: 0\n",
            "\\n----- Overall Performance -----\n",
            "Avg Anthropic Score: 0.00\n",
            "Total Anthropic Score: 0\n",
            "\\nLearnings are stored in: /content/drive/My Drive/AI/Knowledgebases\n",
            "Most recent learnings file: learnings_20250519_175750_694613.json\n",
            "\\nExecution Finished.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}