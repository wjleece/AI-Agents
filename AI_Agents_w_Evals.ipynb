{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjleece/AI-Agents/blob/main/AI_Agents_w_Evals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install anthropic\n",
        "#%pip install openai\n",
        "%pip install -q -U google-generativeai\n",
        "%pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDKcVFI7PAJ5",
        "outputId": "fab654bb-c0a9-4707-e969-50b7fe6ed1ef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.51.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.0)\n",
            "Downloading anthropic-0.51.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.51.0\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup and Imports\n",
        "import anthropic\n",
        "import google.generativeai as gemini\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import glob # For finding files matching a pattern\n",
        "import uuid # For generating unique learning IDs in RAG\n",
        "from google.colab import userdata\n",
        "#from openai import OpenAI\n",
        "from google.colab import drive # For Google Drive mounting\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional, Union, Tuple\n",
        "from fuzzywuzzy import process, fuzz\n",
        "\n",
        "# LLM API Keys\n",
        "ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "#OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "#openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "gemini.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "ANTHROPIC_MODEL_NAME = \"claude-3-5-sonnet-latest\"\n",
        "#OPENAI_MODEL_NAME = \"gpt-4.1\" # Or your preferred GPT-4 class model\n",
        "EVAL_MODEL_NAME = \"gemini-2.5-pro-preview-05-06\" # Or your preferred Gemini model\n",
        "CLASSIFIER_MODEL_NAME = \"gemini-1.5-flash-latest\" # Fast model for question classification / routing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoQ4L2N6o339",
        "outputId": "820a8d75-e83e-430c-a2e3-14c5e3af098d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Drive Authentication & path mapping\n",
        "\n",
        "DRIVE_MOUNT_PATH = '/content/drive'\n",
        "\n",
        "try:\n",
        "    drive.mount(DRIVE_MOUNT_PATH)\n",
        "    print(f\"Google Drive mounted successfully at {DRIVE_MOUNT_PATH}.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}. RAG features will not work.\")\n",
        "\n",
        "# Set up the default learnings path\n",
        "DEFAULT_LEARNINGS_DRIVE_SUBPATH = \"My Drive/AI/Knowledgebases\"  # Your default path\n",
        "LEARNINGS_DRIVE_BASE_PATH = os.path.join(DRIVE_MOUNT_PATH, DEFAULT_LEARNINGS_DRIVE_SUBPATH)\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(LEARNINGS_DRIVE_BASE_PATH):\n",
        "    try:\n",
        "        os.makedirs(LEARNINGS_DRIVE_BASE_PATH)\n",
        "        print(f\"Created learnings directory: {LEARNINGS_DRIVE_BASE_PATH}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating learnings directory {LEARNINGS_DRIVE_BASE_PATH}: {e}\")\n",
        "else:\n",
        "    print(f\"Using existing learnings directory: {LEARNINGS_DRIVE_BASE_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VeBrmqG1K-o",
        "outputId": "31321e12-004d-40e6-f3db-c0c827af49ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully at /content/drive.\n",
            "Using existing learnings directory: /content/drive/My Drive/AI/Knowledgebases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Specialized System Prompts\n",
        "\n",
        "# --- Worker AI Prompts ---\n",
        "worker_base_instructions = \"\"\"\n",
        "You are a helpful customer service assistant for an e-commerce system.\n",
        "Your overriding goal is to be helpful by answering questions and performing actions as requested by a human user.\n",
        "When responding to the user, use the conversation context to maintain continuity.\n",
        "- If a user refers to \"my order\" or similar, use the context to determine which order they're talking about.\n",
        "- If they mention \"that product\" or use other references, check the context to determine what they're referring to.\n",
        "- Always prioritize recent context over older context when resolving references.\n",
        "\n",
        "The conversation context will be provided to you with each message. This includes:\n",
        "- Previous questions and answers\n",
        "- Recently viewed customers, products, and orders\n",
        "- Recent actions taken (like creating orders, updating products, etc.)\n",
        "- Relevant Learnings from a knowledge base (if applicable to the current query type).\n",
        "- **Crucially, results from any tools you use will also be part of the context provided back to you.**\n",
        "\n",
        "**YOUR RESPONSE TO THE HUMAN USER:**\n",
        "Your primary role is to communicate effectively and naturally with the human user.\n",
        "- After you use tools and get their results (which will be shown to you), your final textual response to the user **must be a friendly, conversational, and easy-to-understand summary.**\n",
        "- **DO NOT output raw data (like JSON strings or complex lists/dictionaries from tool results) directly in your response to the user.**\n",
        "- Instead, you must **interpret the tool results** and explain the outcome or provide the requested information in natural language.\n",
        "- For example, if a tool you used returns information like `{\"product_name\": \"Perplexinator\", \"inventory_count\": 1485}`, your response to the user should be something like: \"Currently, we have 1485 Perplexinators in stock.\" or \"The Perplexinator has 1485 units available, would you like to know more?\"\n",
        "- If you perform an action (e.g., creating an order), confirm this action clearly and provide key details in a sentence, for instance: \"I've successfully created your order (Order ID: O4) for 10 Widgets.\"\n",
        "- Always aim to be helpful, polite, and clear in your language.\n",
        "\n",
        "REQUESTING CLARIFICATION FROM THE USER:\n",
        "If you determine that you absolutely need more information from the user to accurately and efficiently fulfill their request or use a tool correctly, you MUST:\n",
        "1. Formulate a clear, concise question for the user.\n",
        "2. Prefix your entire response with the exact tag: `CLARIFICATION_REQUESTED:`\n",
        "   Example: `CLARIFICATION_REQUESTED: To update the order, could you please provide the Order ID?`\n",
        "3. Do NOT use any tools in the same turn you are requesting clarification. Wait for the user's response.\n",
        "\n",
        "Keep all other responses friendly, concise, and helpful.\n",
        "\"\"\"\n",
        "\n",
        "worker_operational_system_prompt = f\"\"\"\n",
        "{worker_base_instructions}\n",
        "\n",
        "Your current task is OPERATIONAL. Focus on understanding user requests related to e-commerce functions (managing orders, products, customers), using the provided tools accurately, and interacting with the data store.\n",
        "The \"Relevant Learnings from Knowledge Base\" provided in your context may contain operational guidelines.\n",
        "Remember to synthesize tool results into a user-friendly textual response. The detailed tool outputs are logged separately for evaluation.\n",
        "\"\"\"\n",
        "\n",
        "worker_metacognitive_learnings_system_prompt = f\"\"\"\n",
        "{worker_base_instructions}\n",
        "\n",
        "Your current task is METACOGNITIVE: SUMMARIZING LEARNINGS AND EXPLAINING YOUR THINKING.\n",
        "If the user asks you to \"summarize your learnings\", \"what have you learned\", \"why did you\", \"is there a better way to\" or similar phrases, your response should be based PRIMARILY on the content provided to you under the heading \"Relevant Learnings from Knowledge Base (In-Session Cache)\" in your current context.\n",
        "- List the key principles or pieces of information from these provided learnings.\n",
        "- Do not confuse these explicit learnings with a general summary of your recent actions or the current state of the data store, unless a learning specifically refers to such an action or state.\n",
        "- If no specific learnings are provided in your context for this type of query, you can state that no specific new learnings have been highlighted for this interaction.\n",
        "- Avoid using tools for this type of summarization unless a tool is specifically designed to retrieve or process learnings.\n",
        "\"\"\"\n",
        "\n",
        "# --- Evaluator AI Prompt (unified but guided by query type information) ---\n",
        "# This prompt is largely the same as the one from worker_prompt_update_learning_summary,\n",
        "# but we will emphasize the query_type in the main prompt to the evaluator.\n",
        "\n",
        "evaluator_system_prompt = \"\"\"\n",
        "You are Google Gemini, an impartial evaluator assessing the quality of responses from an AI assistant to customer service queries.\n",
        "\n",
        "You will be provided with:\n",
        "- The user's query and the TYPE of query it was classified as (e.g., OPERATIONAL, METACOGNITIVE_LEARNINGS_SUMMARY).\n",
        "- The conversation context (including RAG learnings) that was available to the AI assistant.\n",
        "- **The AI assistant's final user-facing textual response.**\n",
        "- **A log of tools called by the AI assistant, including their inputs and raw outputs.**\n",
        "- A snapshot of the 'Data Store State *Before* AI Action'.\n",
        "- A snapshot of the 'Data Store State *After* AI Action'.\n",
        "- Details of any clarification questions the AI assistant asked.\n",
        "\n",
        "Your primary goal is to assess the AI assistant based on the SPECIFIC TASK it was attempting, as indicated by the query type.\n",
        "\n",
        "For each interaction, evaluate the assistant's response based on:\n",
        "1.  **Accuracy**:\n",
        "    * If OPERATIONAL:\n",
        "        * How correct and factual is the AI's **user-facing textual response**?\n",
        "        * Does the textual response accurately reflect the outcomes of the **tool calls** and changes in the datastore?\n",
        "        * Did its actions (tool calls) correctly process information or modify the datastore as intended? Verify against 'Tool Call Log', 'Before' and 'After' states.\n",
        "    * If METACOGNITIVE_LEARNINGS_SUMMARY: Did the AI accurately summarize the \"Relevant Learnings from Knowledge Base\" provided in its context? Was the summary faithful to these learnings?\n",
        "    * Check for new entity IDs and correct updates if applicable to the query type.\n",
        "\n",
        "2.  **Efficiency**:\n",
        "    * Did the assistant achieve its goal with minimal clarifying questions?\n",
        "    * If OPERATIONAL: Were tool calls used appropriately and efficiently? (Refer to 'Tool Call Log')\n",
        "    * If METACOGNITIVE_LEARNINGS_SUMMARY: Was the summary direct and to the point based on provided learnings?\n",
        "\n",
        "3.  **Context Awareness**:\n",
        "    * Did the assistant correctly use the conversation history and entities?\n",
        "    * Crucially, did the assistant adhere to the task defined by the query type?\n",
        "    * Did it correctly use any \"Relevant Learnings from Knowledge Base\" that were pertinent to the query type?\n",
        "    * For OPERATIONAL tasks, did the user-facing response make sense given the tool outputs and datastore changes?\n",
        "\n",
        "4.  **Helpfulness & Clarity (of the user-facing response)**:\n",
        "    * How well did the assistant address the user's needs *for the identified query type* in its textual response?\n",
        "    * Was the **user-facing response clear, polite, and easy to understand?** Did it avoid jargon or raw data dumps?\n",
        "    * Did it provide relevant information in a helpful manner?\n",
        "\n",
        "Score the response on a scale of 1-10 for each criterion, and provide an overall score. Provide detailed reasoning, EXPLICITLY MENTIONING THE QUERY TYPE and referencing the **user-facing text**, the **tool call log**, and **datastore states** as appropriate.\n",
        "- For OPERATIONAL queries, heavily reference the 'Tool Call Log' and 'Before'/'After' data store states when assessing the underlying actions, and then assess if the user-facing text accurately and clearly conveys this.\n",
        "- For METACOGNITIVE_LEARNINGS_SUMMARY, heavily reference the \"Relevant Learnings from Knowledge Base\" that were provided to the worker.\n",
        "\n",
        "EVALUATING CLARIFICATION QUESTIONS:\n",
        "If the worker AI asked for clarification:\n",
        "- Assess necessity using 'Data Store State *Before* AI Action' and context.\n",
        "- If necessary and well-phrased, it should NOT negatively impact Efficiency.\n",
        "- If unnecessary, it SHOULD negatively impact Efficiency.\n",
        "\n",
        "If you, the evaluator, still have questions, use \"CLARIFICATION NEEDED_EVALUATOR:\".\n",
        "\n",
        "DATA STORE CONSISTENCY (Primarily for OPERATIONAL tasks):\n",
        "When assessing Accuracy for OPERATIONAL tasks, explicitly compare the AI's actions (via tool log and datastore changes) with its claims in the user-facing text.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zMWjRsv3QNc1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Data Stores (Initial data - will be managed by the Storage class instance)\n",
        "# These are initial values. The Storage class will manage them.\n",
        "initial_customers = {\n",
        "    \"C1\": {\"name\": \"John Doe\", \"email\": \"john@example.com\", \"phone\": \"123-456-7890\"},\n",
        "    \"C2\": {\"name\": \"Jane Smith\", \"email\": \"jane@example.com\", \"phone\": \"987-654-3210\"}\n",
        "}\n",
        "\n",
        "initial_products = {\n",
        "    \"P1\": {\"name\": \"Widget A\", \"description\": \"A simple widget. Very compact.\", \"price\": 19.99, \"inventory_count\": 999},\n",
        "    \"P2\": {\"name\": \"Gadget B\", \"description\": \"A powerful gadget. It spins.\", \"price\": 49.99, \"inventory_count\": 200},\n",
        "    \"P3\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1483}\n",
        "}\n",
        "\n",
        "initial_orders = {\n",
        "    \"O1\": {\"id\": \"O1\", \"product_id\": \"P1\", \"product_name\": \"Widget A\", \"quantity\": 2, \"price\": 19.99, \"status\": \"Shipped\"},\n",
        "    \"O2\": {\"id\": \"O2\", \"product_id\": \"P2\", \"product_name\": \"Gadget B\", \"quantity\": 1, \"price\": 49.99, \"status\": \"Processing\"}\n",
        "}\n"
      ],
      "metadata": {
        "id": "5G9rP40vQXdU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standalone Anthropic Completion Function (for basic tests)\n",
        "#def get_completion_anthropic_standalone(prompt: str):\n",
        "#    message = anthropic_client.messages.create(\n",
        "#        model=ANTHROPIC_MODEL_NAME,\n",
        "#        max_tokens=2000,\n",
        "#        temperature=0.0,\n",
        "#        system=worker_base_instructions,\n",
        "#        tools=tools_schemas_list,\n",
        "#        messages=[\n",
        "#          {\"role\": \"user\", \"content\": prompt}\n",
        "#        ]\n",
        "#    )\n",
        "#    return message.content[0].text"
      ],
      "metadata": {
        "id": "_ADM0bBpQlVK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt_test_anthropic = \"Hey there, which AI model do you use for answering questions?\"\n",
        "#print(f\"Anthropic Standalone Test: {get_completion_anthropic_standalone(prompt_test_anthropic)}\")"
      ],
      "metadata": {
        "id": "jPOq1s0SQqk_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def get_completion_openai_standalone(prompt: str):\n",
        "#    response = openai_client.chat.completions.create(\n",
        "#        model=OPENAI_MODEL_NAME,\n",
        "#        max_tokens=2000,\n",
        "#        temperature=0.0,\n",
        "#        tools=tools_schemas_list,\n",
        "#        messages=[\n",
        "#            {\"role\": \"system\", \"content\": worker_system_prompt},\n",
        "#            {\"role\": \"user\", \"content\": prompt}\n",
        "#        ]\n",
        "#    )\n",
        "#    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Y5c_bv3qQwWV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt_test_openai = \"Hey there, which AI model do you use for answering questions?\"\n",
        "#print(f\"OpenAI Standalone Test: {get_completion_openai_standalone(prompt_test_openai)}\")"
      ],
      "metadata": {
        "id": "b_LaDQ74Q1Lp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Storage:\n",
        "    \"\"\"Manages the in-memory e-commerce datastore.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.customers = copy.deepcopy(initial_customers)\n",
        "        self.products = copy.deepcopy(initial_products)\n",
        "        self.orders = copy.deepcopy(initial_orders)\n",
        "        print(\"Storage initialized with deep copies of initial data.\")\n",
        "\n",
        "    def get_full_datastore_copy(self) -> Dict[str, Any]:\n",
        "        \"\"\"Returns a deep copy of the current datastore.\"\"\"\n",
        "        return {\n",
        "            \"customers\": copy.deepcopy(self.customers),\n",
        "            \"products\": copy.deepcopy(self.products),\n",
        "            \"orders\": copy.deepcopy(self.orders)\n",
        "        }"
      ],
      "metadata": {
        "id": "_9XC9xyh3XVE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools_schemas_list = [\n",
        "    {\n",
        "        \"name\": \"create_customer\",\n",
        "        \"description\": \"Adds a new customer to the database. Includes customer name, email, and (optional) phone number.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The name of the customer.\"},\n",
        "                \"email\": {\"type\": \"string\", \"description\": \"The email address of the customer.\"},\n",
        "                \"phone\": {\"type\": \"string\", \"description\": \"The phone number of the customer (optional).\"}\n",
        "            },\n",
        "            \"required\": [\"name\", \"email\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_customer_info\",\n",
        "        \"description\": \"Retrieves customer information based on their customer ID. Returns the customer's name, email, and (optional) phone number.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"customer_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the customer.\"}\n",
        "            },\n",
        "            \"required\": [\"customer_id\"]\n",
        "        }\n",
        "    },\n",
        "    { # NEW TOOL SCHEMA ADDED HERE\n",
        "        \"name\": \"update_customer\",\n",
        "        \"description\": \"Updates an existing customer's information. Only fields that are provided will be updated; other fields remain unchanged.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"customer_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the customer to update.\"},\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The new name for the customer (optional).\"},\n",
        "                \"email\": {\"type\": \"string\", \"description\": \"The new email address for the customer (optional).\"},\n",
        "                \"phone\": {\"type\": \"string\", \"description\": \"The new phone number for the customer (optional).\"}\n",
        "            },\n",
        "            \"required\": [\"customer_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"create_product\",\n",
        "        \"description\": \"Adds a new product to the product database. Includes name, description, price, and initial inventory count.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The name of the product.\"},\n",
        "                \"description\": {\"type\": \"string\", \"description\": \"A description of the product.\"},\n",
        "                \"price\": {\"type\": \"number\", \"description\": \"The price of the product.\"},\n",
        "                \"inventory_count\": {\"type\": \"integer\", \"description\": \"The amount of the product that is currently in inventory.\"}\n",
        "            },\n",
        "            \"required\": [\"name\", \"description\", \"price\", \"inventory_count\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"update_product\",\n",
        "        \"description\": \"Updates an existing product with new information. Only fields that are provided will be updated; other fields remain unchanged.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the product to update.\"},\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The new name for the product (optional).\"},\n",
        "                \"description\": {\"type\": \"string\", \"description\": \"The new description for the product (optional).\"},\n",
        "                \"price\": {\"type\": \"number\", \"description\": \"The new price for the product (optional).\"},\n",
        "                \"inventory_count\": {\"type\": \"integer\", \"description\": \"The new inventory count for the product (optional).\"}\n",
        "            },\n",
        "            \"required\": [\"product_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_product_info\",\n",
        "        \"description\": \"Retrieves product information based on product ID or product name (with fuzzy matching for misspellings). Returns product details including name, description, price, and inventory count.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id_or_name\": {\"type\": \"string\", \"description\": \"The product ID or name (can be approximate).\"}\n",
        "            },\n",
        "            \"required\": [\"product_id_or_name\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"list_all_products\",\n",
        "        \"description\": \"Lists all available products in the inventory.\",\n",
        "        \"input_schema\": { \"type\": \"object\", \"properties\": {}, \"required\": [] }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"create_order\",\n",
        "        \"description\": \"Creates an order using the product's current price. Inventory is adjusted if sufficient. Orders can only be created for products that are in stock for fulfillment. Supports specifying products by either ID or name with fuzzy matching for misspellings.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id_or_name\": {\"type\": \"string\", \"description\": \"The ID or name of the product to order (supports fuzzy matching).\"},\n",
        "                \"quantity\": {\"type\": \"integer\", \"description\": \"The quantity of the product in the order. Must be positive.\"},\n",
        "                \"status\": {\"type\": \"string\", \"description\": \"The initial status of the order (e.g., 'Processing', 'Shipped').\"}\n",
        "            },\n",
        "            \"required\": [\"product_id_or_name\", \"quantity\", \"status\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_order_details\",\n",
        "        \"description\": \"Retrieves the details of a specific order based on the order ID. Returns the order ID, product name, quantity, price, and order status.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the order.\"}\n",
        "            },\n",
        "            \"required\": [\"order_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"update_order_status\",\n",
        "        \"description\": \"Updates the status of an order and adjusts inventory accordingly. Changing to \\\"Shipped\\\" decreases inventory (if not already decreased by order creation). Changing from \\\"Shipped\\\" to \\\"Returned\\\" or \\\"Canceled\\\" increases inventory. Status can be \\\"Processing\\\", \\\"Shipped\\\", \\\"Delivered\\\", \\\"Returned\\\", or \\\"Canceled\\\".\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the order.\"},\n",
        "                \"new_status\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The new status to set for the order.\",\n",
        "                    \"enum\": [\"Processing\", \"Shipped\", \"Delivered\", \"Returned\", \"Canceled\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"order_id\", \"new_status\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "# Recalculate the number of defined schemas\n",
        "print(f\"Defined {len(tools_schemas_list)} tool schemas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PREbUQfh2UBj",
        "outputId": "dad3d97d-bfd8-41ac-cb3f-280866a7bc49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined 10 tool schemas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Tool Functions (Global for now, passed to ToolExecutor) ---\n",
        "\n",
        "def create_customer(current_storage: Storage, name: str, email: str, phone: Optional[str] = None):\n",
        "    new_id = f\"C{len(current_storage.customers) + 1}\"\n",
        "    while new_id in current_storage.customers: new_id = f\"C{int(new_id[1:]) + 1}\"\n",
        "    current_storage.customers[new_id] = {\"name\": name, \"email\": email, \"phone\": phone}\n",
        "    print(f\"[Tool Exec] create_customer: ID {new_id}, Name: {name}\")\n",
        "    return {\"status\": \"success\", \"customer_id\": new_id, \"customer\": current_storage.customers[new_id]}\n",
        "\n",
        "def get_customer_info(current_storage: Storage, customer_id: str):\n",
        "    customer = current_storage.customers.get(customer_id)\n",
        "    if customer:\n",
        "        print(f\"[Tool Exec] get_customer_info: ID {customer_id} found.\")\n",
        "        return {\"status\": \"success\", \"customer_id\": customer_id, \"customer\": customer} # Added customer_id to response\n",
        "    print(f\"[Tool Exec] get_customer_info: ID {customer_id} not found.\")\n",
        "    return {\"status\": \"error\", \"message\": \"Customer not found\"}\n",
        "\n",
        "def update_customer(current_storage: Storage, customer_id: str, name: Optional[str]=None, email: Optional[str]=None, phone: Optional[str]=None):\n",
        "    if customer_id not in current_storage.customers:\n",
        "        print(f\"[Tool Exec] update_customer: Customer ID {customer_id} not found.\")\n",
        "        return {\"status\": \"error\", \"message\": f\"Customer with ID {customer_id} not found.\"}\n",
        "\n",
        "    customer = current_storage.customers[customer_id]\n",
        "    updated_fields = []\n",
        "\n",
        "    if name is not None: # Check for None explicitly, as empty string might be a valid (though unusual) name state\n",
        "        customer[\"name\"] = name\n",
        "        updated_fields.append(\"name\")\n",
        "    if email is not None:\n",
        "        customer[\"email\"] = email\n",
        "        updated_fields.append(\"email\")\n",
        "    if phone is not None: # Phone can be set to empty string to remove it, or a new number\n",
        "        customer[\"phone\"] = phone\n",
        "        updated_fields.append(\"phone\")\n",
        "\n",
        "    if not updated_fields:\n",
        "        print(f\"[Tool Exec] update_customer: ID {customer_id}, no fields provided for update.\")\n",
        "        return {\"status\": \"warning\", \"message\": \"No fields provided for update.\", \"customer_id\": customer_id, \"customer\": customer}\n",
        "\n",
        "    print(f\"[Tool Exec] update_customer: ID {customer_id}, Updated fields: {', '.join(updated_fields)}.\\n   New data: {customer}\")\n",
        "    return {\"status\": \"success\", \"customer_id\": customer_id, \"customer\": customer, \"updated_fields\": updated_fields}\n",
        "\n",
        "def create_product(current_storage: Storage, name: str, description: str, price: float, inventory_count: int):\n",
        "    new_id = f\"P{len(current_storage.products) + 1}\"\n",
        "    while new_id in current_storage.products: new_id = f\"P{int(new_id[1:]) + 1}\"\n",
        "    current_storage.products[new_id] = {\"name\": name, \"description\": description, \"price\": price, \"inventory_count\": max(0, inventory_count)}\n",
        "    print(f\"[Tool Exec] create_product: ID {new_id}, Name: {name}\")\n",
        "    return {\"status\": \"success\", \"product_id\": new_id, \"product\": current_storage.products[new_id]}\n",
        "\n",
        "def update_product(current_storage: Storage, product_id: str, name: Optional[str]=None, description: Optional[str]=None, price: Optional[float]=None, inventory_count: Optional[int]=None):\n",
        "    if product_id not in current_storage.products:\n",
        "        print(f\"[Tool Exec] update_product: ID {product_id} not found.\")\n",
        "        return {\"status\": \"error\", \"message\": \"Product not found\"}\n",
        "    product = current_storage.products[product_id]; updated_fields = []\n",
        "    if name is not None: product[\"name\"] = name; updated_fields.append(\"name\")\n",
        "    if description is not None: product[\"description\"] = description; updated_fields.append(\"description\")\n",
        "    if price is not None: product[\"price\"] = price; updated_fields.append(\"price\")\n",
        "    if inventory_count is not None :\n",
        "        product[\"inventory_count\"] = max(0, inventory_count) # Ensure inventory doesn't go below zero\n",
        "        updated_fields.append(\"inventory_count\")\n",
        "    if not updated_fields:\n",
        "        print(f\"[Tool Exec] update_product: ID {product_id}, no fields provided for update.\")\n",
        "        return {\"status\":\"warning\", \"message\":\"No fields provided for update.\", \"product_id\": product_id, \"product\": product}\n",
        "    print(f\"[Tool Exec] update_product: ID {product_id}, Updated fields: {', '.join(updated_fields)}.\\n   New data: {product}\")\n",
        "    return {\"status\": \"success\", \"product_id\": product_id, \"product\": product, \"updated_fields\": updated_fields}\n",
        "\n",
        "def find_product_by_name(current_storage: Storage, product_name: str, min_similarity: int = 70) -> Tuple[Optional[str], Optional[Dict[str, Any]]]:\n",
        "    # ... (remains the same) ...\n",
        "    if not product_name: return None, None\n",
        "    name_id_list = [(p_data[\"name\"], p_id) for p_id, p_data in current_storage.products.items()]\n",
        "    if not name_id_list: return None, None\n",
        "    best_match_name_score = process.extractOne(product_name, [item[0] for item in name_id_list], scorer=fuzz.token_sort_ratio)\n",
        "    if best_match_name_score and best_match_name_score[1] >= min_similarity:\n",
        "        matched_name = best_match_name_score[0]\n",
        "        for name_val, pid_val in name_id_list:\n",
        "            if name_val == matched_name: return pid_val, current_storage.products[pid_val]\n",
        "    return None, None\n",
        "\n",
        "def get_product_id(current_storage: Storage, product_identifier: str) -> Optional[str]:\n",
        "    # ... (remains the same) ...\n",
        "    if product_identifier in current_storage.products: return product_identifier\n",
        "    product_id, _ = find_product_by_name(current_storage, product_identifier)\n",
        "    return product_id\n",
        "\n",
        "def get_product_info(current_storage: Storage, product_id_or_name: str):\n",
        "    # ... (remains the same) ...\n",
        "    pid = get_product_id(current_storage, product_id_or_name)\n",
        "    if pid and pid in current_storage.products:\n",
        "        print(f\"[Tool Exec] get_product_info: Found '{product_id_or_name}' as ID '{pid}'.\")\n",
        "        return {\"status\": \"success\", \"product_id\": pid, \"product\": current_storage.products[pid]}\n",
        "    print(f\"[Tool Exec] get_product_info: Product '{product_id_or_name}' not found.\")\n",
        "    return {\"status\": \"error\", \"message\": f\"Product '{product_id_or_name}' not found\"}\n",
        "\n",
        "def list_all_products(current_storage: Storage):\n",
        "    # ... (remains the same) ...\n",
        "    print(f\"[Tool Exec] list_all_products: Found {len(current_storage.products)} products.\")\n",
        "    return {\"status\": \"success\", \"count\": len(current_storage.products), \"products\": current_storage.products}\n",
        "\n",
        "def create_order(current_storage: Storage, product_id_or_name: str, quantity: int, status: str):\n",
        "    actual_product_id = get_product_id(current_storage, product_id_or_name)\n",
        "    if not actual_product_id:\n",
        "        print(f\"[Tool Exec] create_order: Product '{product_id_or_name}' not found.\")\n",
        "        return {\"status\": \"error\", \"message\": f\"Product '{product_id_or_name}' not found.\"}\n",
        "\n",
        "    product = current_storage.products[actual_product_id]\n",
        "    inventory_adjusted_by_creation = False\n",
        "    order_creation_message = \"\"\n",
        "\n",
        "    if quantity <= 0:\n",
        "        msg = f\"Order quantity must be positive. Requested: {quantity}\"\n",
        "        print(f\"[Tool Exec] create_order: {msg}\")\n",
        "        return {\"status\": \"error\", \"message\": msg}\n",
        "\n",
        "    # Create the order entry first\n",
        "    new_id = f\"O{len(current_storage.orders) + 1}\"\n",
        "    while new_id in current_storage.orders:\n",
        "        new_id = f\"O{int(new_id[1:]) + 1}\"\n",
        "\n",
        "    current_order_data = {\n",
        "        \"id\": new_id,\n",
        "        \"product_id\": actual_product_id,\n",
        "        \"product_name\": product[\"name\"],\n",
        "        \"quantity\": quantity,\n",
        "        \"price\": product[\"price\"],\n",
        "        \"status\": status # Initially use the status provided by agent\n",
        "    }\n",
        "    current_storage.orders[new_id] = current_order_data\n",
        "    print(f\"[Tool Exec] create_order: Order entry {new_id} created with status '{status}'.\")\n",
        "\n",
        "    # Handle inventory based on availability\n",
        "    if product[\"inventory_count\"] < quantity:\n",
        "        order_creation_message = (f\"Order {new_id} ({product['name']}) created with status '{status}'. \"\n",
        "                                  f\"Insufficient inventory for fulfillment. Available: {product['inventory_count']}, Requested: {quantity}. \"\n",
        "                                  \"Inventory not adjusted.\")\n",
        "        print(f\"[Tool Exec] create_order: {order_creation_message}\")\n",
        "        # Inventory is NOT changed. Agent might need to set to 'Backordered' or handle it.\n",
        "    else: # Sufficient inventory\n",
        "        product[\"inventory_count\"] = max(0, product[\"inventory_count\"] - quantity)\n",
        "        inventory_adjusted_by_creation = True\n",
        "        order_creation_message = (f\"Order {new_id} ({product['name']}) created with status '{status}'. \"\n",
        "                                  f\"Inventory sufficient and deducted. New inventory: {product['inventory_count']}.\")\n",
        "        print(f\"[Tool Exec] create_order: {order_creation_message}\")\n",
        "\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"order_id\": new_id,\n",
        "        \"order_details\": current_storage.orders[new_id], # Return the created order\n",
        "        \"remaining_inventory\": product[\"inventory_count\"], # Current inventory after potential deduction\n",
        "        \"inventory_adjusted_by_creation\": inventory_adjusted_by_creation,\n",
        "        \"message\": order_creation_message\n",
        "    }\n",
        "\n",
        "def get_order_details(current_storage: Storage, order_id: str):\n",
        "    # ... (remains the same) ...\n",
        "    order = current_storage.orders.get(order_id)\n",
        "    if order: print(f\"[Tool Exec] get_order_details: Order {order_id} found.\"); return {\"status\": \"success\", \"order_details\": order}\n",
        "    print(f\"[Tool Exec] get_order_details: Order {order_id} not found.\"); return {\"status\": \"error\", \"message\": \"Order not found\"}\n",
        "\n",
        "def update_order_status(current_storage: Storage, order_id: str, new_status: str):\n",
        "    # ... (remains the same as your last working version, which correctly handles inventory) ...\n",
        "    if order_id not in current_storage.orders:\n",
        "        print(f\"[Tool Exec] update_order_status: Order {order_id} not found.\")\n",
        "        return {\"status\": \"error\", \"message\": \"Order not found\"}\n",
        "\n",
        "    order = current_storage.orders[order_id]\n",
        "    product_id = order[\"product_id\"]\n",
        "    quantity = order[\"quantity\"]\n",
        "    # It's possible product_id might not exist if data is corrupted, though unlikely with current setup\n",
        "    if product_id not in current_storage.products:\n",
        "        print(f\"[Tool Exec] update_order_status: Product ID {product_id} for order {order_id} not found in products list!\")\n",
        "        return {\"status\": \"error\", \"message\": f\"Product {product_id} for order {order_id} not found, cannot update status or inventory.\"}\n",
        "\n",
        "    product = current_storage.products[product_id]\n",
        "    old_status = order[\"status\"]\n",
        "\n",
        "    if old_status == new_status:\n",
        "        print(f\"[Tool Exec] update_order_status: Status for {order_id} already {new_status}.\")\n",
        "        return {\"status\": \"unchanged\", \"message\": f\"Status is already {new_status}\", \"order_details\": order, \"current_inventory\": product[\"inventory_count\"]}\n",
        "\n",
        "    inventory_adjusted_by_this_update = False\n",
        "    # Logic for inventory adjustment based on status change\n",
        "    # This logic assumes inventory was already deducted if an order was created with status \"Shipped\" by create_order,\n",
        "    # OR that create_order always deducts if sufficient (which is the new logic).\n",
        "    # The key is that `update_order_status` primarily handles changes *to* or *from* \"Shipped\".\n",
        "\n",
        "    if new_status == \"Shipped\" and old_status != \"Shipped\":\n",
        "        # This handles moving an order (e.g. from \"Processing\") to \"Shipped\".\n",
        "        # If create_order already deducted inventory, this check prevents double deduction.\n",
        "        # However, with the new create_order logic, inventory is deducted on creation if available.\n",
        "        # So, this block might only be relevant if create_order *failed* to deduct due to status but inventory was actually available,\n",
        "        # or if an order was \"Returned\" and is now being \"Re-Shipped\" (complex scenario not fully handled).\n",
        "        # For simplicity, if create_order always deducts when items are available, this specific deduction here might be redundant\n",
        "        # UNLESS the order was created when inventory was insufficient, and now it's sufficient.\n",
        "\n",
        "        # Let's refine: if create_order *always* deducts if possible, then this block in update_order_status\n",
        "        # needs to be careful not to double-deduct.\n",
        "        # The `update_order_status`'s description says: \"Changing to Shipped decreases inventory\".\n",
        "        # This should only happen if it wasn't already effectively \"reserved\" or deducted.\n",
        "\n",
        "        # Safer assumption: If `create_order` *always* deducts if available,\n",
        "        # then moving from \"Processing\" (where inventory was already deducted by create_order) to \"Shipped\"\n",
        "        # should NOT deduct again.\n",
        "        # This tool should only deduct if moving from a non-inventory-affecting state (like \"Pending Inventory\" or a \"Returned\" that re-added stock) to \"Shipped\".\n",
        "\n",
        "        # Given the current simple states, let's assume:\n",
        "        # If `create_order` deducted, `old_status` effectively represented a \"reserved\" state.\n",
        "        # This tool's main inventory job is when \"Shipped\" boundary is crossed.\n",
        "\n",
        "        # Let's revert to the original logic for update_order_status, assuming create_order might not have shipped.\n",
        "        if product[\"inventory_count\"] < quantity:\n",
        "            print(f\"[Tool Exec] update_order_status: Insufficient inv for {product_id} to ship order {order_id}. Available: {product['inventory_count']}\")\n",
        "            return {\"status\": \"error\", \"message\": f\"Insufficient inventory to change status to Shipped. Available: {product['inventory_count']}\"}\n",
        "        product[\"inventory_count\"] = max(0, product[\"inventory_count\"] - quantity)\n",
        "        inventory_adjusted_by_this_update = True\n",
        "\n",
        "    elif old_status == \"Shipped\" and new_status != \"Shipped\": # e.g., Returned, Canceled FROM Shipped\n",
        "        product[\"inventory_count\"] += quantity # Add back to inventory\n",
        "        inventory_adjusted_by_this_update = True\n",
        "\n",
        "    order[\"status\"] = new_status\n",
        "    print(f\"[Tool Exec] update_order_status: Order {order_id} to {new_status}. Inv for {product_id} is {product['inventory_count']}. Adjusted: {inventory_adjusted_by_this_update}\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"order_id\": order_id,\n",
        "        \"order_details\": order,\n",
        "        \"current_inventory\": product[\"inventory_count\"],\n",
        "        \"inventory_adjusted_by_this_update\": inventory_adjusted_by_this_update\n",
        "    }\n",
        "\n",
        "print(\"Tool functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGGSeN7T2W1O",
        "outputId": "9278f3a0-2638-4405-a4eb-64a7284e7aa0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QueryClassifier:\n",
        "    \"\"\"Classifies user queries using an LLM.\"\"\"\n",
        "    def __init__(self, llm_client):\n",
        "        self.llm_client = llm_client\n",
        "        self.classification_prompt_template = \"\"\"\n",
        "Classify the following user query into one of these categories: OPERATIONAL, METACOGNITIVE_LEARNINGS_SUMMARY.\n",
        "Return ONLY the category name.\n",
        "\n",
        "OPERATIONAL queries are about performing e-commerce tasks, like asking about products, creating orders, or updating customer information.\n",
        "Examples of OPERATIONAL:\n",
        "- \"Show me all shoes.\"\n",
        "- \"What's the price of P1?\"\n",
        "- \"Create an order for 2 widgets.\"\n",
        "- \"Update my address.\"\n",
        "\n",
        "METACOGNITIVE_LEARNINGS_SUMMARY queries are about the AI's own learning process or knowledge derived from feedback.\n",
        "Examples of METACOGNITIVE_LEARNINGS_SUMMARY:\n",
        "- \"Summarize your learnings.\"\n",
        "- \"What have you learned recently?\"\n",
        "- \"Tell me about your new knowledge.\"\n",
        "- \"Why did you do that in the last turn?\"\n",
        "- \"Is there a better way to handle X?\"\n",
        "\n",
        "User Query: \"{user_message}\"\n",
        "Classification:\"\"\"\n",
        "        print(\"QueryClassifier initialized with LLM client.\")\n",
        "\n",
        "    def classify(self, user_message: str) -> str:\n",
        "        \"\"\"Classifies the user query using the LLM.\"\"\"\n",
        "        prompt = self.classification_prompt_template.format(user_message=user_message)\n",
        "        try:\n",
        "            response = self.llm_client.generate_content(prompt)\n",
        "            classification = response.text.strip()\n",
        "            if classification in [\"OPERATIONAL\", \"METACOGNITIVE_LEARNINGS_SUMMARY\"]:\n",
        "                return classification\n",
        "            else:\n",
        "                print(f\"[QueryClassifier Warning] LLM returned unexpected classification: '{classification}'. Defaulting to OPERATIONAL.\")\n",
        "                return \"OPERATIONAL\"\n",
        "        except Exception as e:\n",
        "            print(f\"[QueryClassifier Error] Failed to classify query using LLM: {e}. Defaulting to OPERATIONAL.\")\n",
        "            return \"OPERATIONAL\""
      ],
      "metadata": {
        "id": "Qxvm6ah2z1wO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationManager:\n",
        "    \"\"\"Manages conversation history and context data.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.messages: List[Dict[str, Any]] = []\n",
        "        self.context_data: Dict[str, Any] = {\n",
        "            \"customers\": {}, \"products\": {}, \"orders\": {}, \"last_action\": None\n",
        "        }\n",
        "        print(\"ConversationManager initialized.\")\n",
        "\n",
        "    def add_user_message(self, message: str) -> None:\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    def add_assistant_message(self, message_content: Union[str, List[Dict[str, Any]]], query_type: str) -> None:\n",
        "        if isinstance(message_content, str):\n",
        "            content_to_log = f\"[{query_type}]: {message_content}\"\n",
        "        else:\n",
        "            content_to_log = message_content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": content_to_log})\n",
        "\n",
        "    def update_entity_in_context(self, entity_type: str, entity_id: str, data: Any) -> None:\n",
        "        if entity_type in self.context_data:\n",
        "            self.context_data[entity_type][entity_id] = data\n",
        "            print(f\"[CM_Context Updated] Entity: {entity_type}, ID: {entity_id}\")\n",
        "\n",
        "    def set_last_action(self, action_type: str, action_details: Any) -> None:\n",
        "        self.context_data[\"last_action\"] = {\n",
        "            \"type\": action_type,\n",
        "            \"details\": action_details,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "        print(f\"[CM_Context Updated] Last Action: {action_type}\")\n",
        "\n",
        "    def get_full_conversation_for_api(self) -> List[Dict[str, Any]]:\n",
        "        return self.messages.copy()\n",
        "\n",
        "    def get_context_summary(self) -> str:\n",
        "        summary_parts = []\n",
        "        if self.context_data[\"customers\"]: summary_parts.append(f\"Recent customers: {list(self.context_data['customers'].keys())}\")\n",
        "        if self.context_data[\"products\"]: summary_parts.append(f\"Recent products: {list(self.context_data['products'].keys())}\")\n",
        "        if self.context_data[\"orders\"]: summary_parts.append(f\"Recent orders: {list(self.context_data['orders'].keys())}\")\n",
        "        if self.context_data[\"last_action\"]: summary_parts.append(f\"Last action type: {self.context_data['last_action']['type']}\")\n",
        "        return \"\\\\n\".join(summary_parts) if summary_parts else \"No specific context items set yet.\"\n"
      ],
      "metadata": {
        "id": "uhTMNPio0BbT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToolExecutor:\n",
        "    def __init__(self, available_tools_dict: Dict[str, callable]):\n",
        "        self.available_tools = available_tools_dict\n",
        "        print(\"ToolExecutor initialized.\")\n",
        "\n",
        "    def execute_tool(self, tool_name: str, tool_input: Dict[str, Any], storage_instance: Storage) -> Dict[str, Any]:\n",
        "        if tool_name in self.available_tools:\n",
        "            try:\n",
        "                tool_function = self.available_tools[tool_name]\n",
        "                result = tool_function(storage_instance, **tool_input)\n",
        "                print(f\"--- [ToolExecutor] Result for {tool_name}: {json.dumps(result, indent=2, default=str)} ---\")\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                print(f\"--- [ToolExecutor Error] executing {tool_name}: {e} ---\"); import traceback; traceback.print_exc()\n",
        "                return {\"status\": \"error\", \"message\": f\"Error executing tool {tool_name}: {str(e)}\"}\n",
        "        print(f\"--- [ToolExecutor Error] Tool {tool_name} not found. ---\")\n",
        "        return {\"status\": \"error\", \"message\": f\"Tool {tool_name} not found.\"}"
      ],
      "metadata": {
        "id": "Qxo-Ho_R0VNy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KnowledgeManager:\n",
        "    def __init__(self, base_path: str, drive_mount_path: str, default_subpath: str, evaluator_llm_instance):\n",
        "        self.base_drive_path = base_path\n",
        "        self.drive_mount_path = drive_mount_path\n",
        "        self.default_drive_subpath = default_subpath\n",
        "        self.evaluator_llm = evaluator_llm_instance\n",
        "        self.active_learnings_cache: List[Dict] = self._load_initial_learnings_from_drive()\n",
        "        self.learnings_updated_this_session_flag: bool = False\n",
        "        print(f\"KnowledgeManager initialized. Loaded {len(self.active_learnings_cache)} initial learnings from {self.base_drive_path}.\")\n",
        "\n",
        "    def _mount_drive_if_needed(self): # RESTORED\n",
        "        if not os.path.exists(self.drive_mount_path) or not os.listdir(self.drive_mount_path):\n",
        "            try:\n",
        "                drive.mount(self.drive_mount_path, force_remount=True)\n",
        "                print(\"Drive mounted by KnowledgeManager.\", flush=True)\n",
        "            except Exception as e:\n",
        "                print(f\"KM: Error mounting Drive: {e}.\", flush=True)\n",
        "\n",
        "    def _initialize_learnings_path(self): # RESTORED\n",
        "        if not os.path.exists(self.base_drive_path):\n",
        "            try:\n",
        "                os.makedirs(self.base_drive_path)\n",
        "                print(f\"KM: Created learnings directory: {self.base_drive_path}\", flush=True)\n",
        "            except Exception as e:\n",
        "                print(f\"KM: Error creating learnings directory {self.base_drive_path}: {e}\", flush=True)\n",
        "\n",
        "    def _get_latest_learnings_filepath(self) -> Optional[str]: # RESTORED\n",
        "        self._mount_drive_if_needed()\n",
        "        self._initialize_learnings_path()\n",
        "        if not os.path.isdir(self.base_drive_path):\n",
        "            print(\"KM: Base drive path for learnings is not a directory or does not exist.\", flush=True)\n",
        "            return None\n",
        "        try:\n",
        "            list_of_files = glob.glob(os.path.join(self.base_drive_path, 'learnings_*.json'))\n",
        "            if not list_of_files:\n",
        "                return None\n",
        "            return max(list_of_files, key=os.path.getctime)\n",
        "        except Exception as e:\n",
        "            print(f\"KM: Error accessing learnings files in {self.base_drive_path}: {e}\", flush=True)\n",
        "            return None\n",
        "\n",
        "\n",
        "    def _read_learnings_from_file(self, filepath: str) -> List[Dict]: # RESTORED\n",
        "        if not filepath or not os.path.exists(filepath):\n",
        "            print(f\"KM: Learnings filepath not provided or does not exist: {filepath}\", flush=True)\n",
        "            return []\n",
        "        try:\n",
        "            with open(filepath, 'r') as f:\n",
        "                learnings_list = json.load(f)\n",
        "            # Basic validation: ensure it's a list of dictionaries\n",
        "            if isinstance(learnings_list, list) and all(isinstance(item, dict) for item in learnings_list):\n",
        "                return learnings_list\n",
        "            else:\n",
        "                print(f\"KM: Learnings file {filepath} is not in the expected format (list of dicts).\", flush=True)\n",
        "                return []\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"KM: Error decoding JSON from {filepath}: {e}\", flush=True)\n",
        "            return []\n",
        "        except Exception as e:\n",
        "            print(f\"KM: Error reading learnings file {filepath}: {e}\", flush=True)\n",
        "            return []\n",
        "\n",
        "    def _load_initial_learnings_from_drive(self) -> List[Dict]:\n",
        "        print(\"KM: Attempting to load initial learnings from Drive...\", flush=True)\n",
        "        latest_filepath = self._get_latest_learnings_filepath()\n",
        "        if latest_filepath:\n",
        "            print(f\"KM: Loading initial learnings from: {latest_filepath}\", flush=True)\n",
        "            learnings = self._read_learnings_from_file(latest_filepath)\n",
        "            print(f\"KM: Successfully loaded {len(learnings)} learnings.\", flush=True)\n",
        "            return learnings\n",
        "        print(\"KM: No existing learnings file found or accessible for initial load.\", flush=True)\n",
        "        return []\n",
        "\n",
        "    def persist_active_learnings(self):\n",
        "        print(\"KM: Checking if learnings need to be persisted to Google Drive...\", flush=True)\n",
        "        self._mount_drive_if_needed()\n",
        "        self._initialize_learnings_path()\n",
        "        if not os.path.isdir(self.base_drive_path):\n",
        "            print(\"KM CRITICAL: Learnings directory not available for persistence.\", flush=True)\n",
        "            return\n",
        "        if not self.active_learnings_cache:\n",
        "            print(\"KM: Active learnings cache is empty. Nothing to persist.\", flush=True)\n",
        "            return\n",
        "        if not self.learnings_updated_this_session_flag:\n",
        "            print(\"KM: Learnings cache has not been updated this session. Nothing to persist.\", flush=True)\n",
        "            return\n",
        "\n",
        "        print(f\"KM: Persisting {len(self.active_learnings_cache)} learnings to Google Drive (this may take a moment)...\", flush=True)\n",
        "        timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
        "        new_filepath = os.path.join(self.base_drive_path, f'learnings_{timestamp_str}.json')\n",
        "        try:\n",
        "            with open(new_filepath, 'w') as f:\n",
        "                json.dump(self.active_learnings_cache, f, indent=4)\n",
        "            print(f\"KM: Successfully persisted learnings to: {new_filepath}\", flush=True)\n",
        "            self.learnings_updated_this_session_flag = False\n",
        "        except Exception as e:\n",
        "            print(f\"KM: Error persisting active learnings to {new_filepath}: {e}\", flush=True)\n",
        "\n",
        "    def get_relevant_learnings_for_prompt(self, query: str, query_type: str,\n",
        "                                           recipient_role: Optional[str] = None,\n",
        "                                           count: int = 5) -> str:\n",
        "        if not self.active_learnings_cache:\n",
        "            return \"No specific relevant learnings from knowledge base provided for this query.\"\n",
        "        eligible_learnings: List[Dict] = []\n",
        "        if recipient_role == \"Agent\":\n",
        "            eligible_learnings = [\n",
        "                entry for entry in self.active_learnings_cache\n",
        "                if entry.get(\"learning_target\") == \"AgentAndEvaluator\"\n",
        "            ]\n",
        "        elif recipient_role == \"Evaluator\":\n",
        "            eligible_learnings = [\n",
        "                entry for entry in self.active_learnings_cache\n",
        "                if entry.get(\"learning_target\") in [\"AgentAndEvaluator\", \"EvaluatorOnly\"]\n",
        "            ]\n",
        "        else: # Default if role is None or unexpected\n",
        "            print(f\"KM (Info): recipient_role is '{recipient_role}'. Defaulting to 'AgentAndEvaluator' learnings for RAG.\", flush=True)\n",
        "            eligible_learnings = [\n",
        "                entry for entry in self.active_learnings_cache\n",
        "                if entry.get(\"learning_target\") == \"AgentAndEvaluator\"\n",
        "            ]\n",
        "\n",
        "        learnings_to_consider = []\n",
        "        if query_type == \"METACOGNITIVE_LEARNINGS_SUMMARY\":\n",
        "            learnings_to_consider = sorted(eligible_learnings, key=lambda x: x.get('timestamp_created', ''), reverse=True)\n",
        "        elif query_type == \"OPERATIONAL\":\n",
        "            if not eligible_learnings:\n",
        "                 return \"No specific relevant learnings from knowledge base found for this query based on role.\"\n",
        "            keywords = self._extract_keywords(query)\n",
        "            learnings_to_consider = [\n",
        "                entry for entry in eligible_learnings\n",
        "                if any(kw.lower() in (entry.get(\"final_learning_statement\", \"\") + \" \" + \" \".join(entry.get(\"keywords\", []))).lower() for kw in keywords)\n",
        "            ]\n",
        "            learnings_to_consider.sort(key=lambda x: x.get('timestamp_created', ''), reverse=True)\n",
        "        else: # Default for other query types or if no specific logic\n",
        "            learnings_to_consider = sorted(eligible_learnings, key=lambda x: x.get('timestamp_created', ''), reverse=True)\n",
        "\n",
        "        final_learnings_for_prompt = learnings_to_consider[:count]\n",
        "\n",
        "        formatted_learnings = [\n",
        "            f\"- Learning (ID: {entry.get('learning_id', 'N/A')[:8]}, Target: {entry.get('learning_target', 'N/A')}): {entry.get('final_learning_statement', str(entry))}\"\n",
        "            for entry in final_learnings_for_prompt\n",
        "        ]\n",
        "\n",
        "        if not formatted_learnings:\n",
        "            return \"No specific relevant learnings from knowledge base found for this query after all filters.\"\n",
        "        # Ensure the RAG string itself doesn't start with an unwanted newline if formatted_learnings is empty.\n",
        "        return \"\\\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\\\n\" + \"\\\\n\".join(formatted_learnings)\n",
        "\n",
        "\n",
        "    def _extract_keywords(self, text: str) -> List[str]:\n",
        "        if not text:\n",
        "            return [\"general\"]\n",
        "        words = re.findall(r'\\\\b\\\\w{4,}\\\\b', text.lower())\n",
        "        stop_words = {\n",
        "            \"the\", \"and\", \"is\", \"in\", \"to\", \"a\", \"of\", \"for\", \"with\", \"on\", \"at\", \"an\", \"by\", \"not\", \"or\", \"as\", \"if\",\n",
        "            \"it\", \"its\", \"this\", \"that\", \"these\", \"those\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\",\n",
        "            \"do\", \"does\", \"did\", \"will\", \"would\", \"should\", \"can\", \"could\", \"may\", \"might\", \"must\",\n",
        "            \"what\", \"who\", \"whom\", \"which\", \"when\", \"where\", \"why\", \"how\",\n",
        "            \"show\", \"tell\", \"please\", \"user\", \"query\", \"context\", \"claude\", \"anthropic\", \"gemini\", \"google\",\n",
        "            \"before\", \"after\", \"state\", \"action\", \"truth\", \"ground\", \"learnings\", \"summarize\", \"your\", \"you\", \"me\", \"my\",\n",
        "            \"provide\", \"give\", \"make\", \"update\", \"create\", \"get\", \"list\", \"item\", \"items\", \"detail\", \"details\"\n",
        "        }\n",
        "        extracted = list(set(word for word in words if word not in stop_words and not word.isdigit()))\n",
        "        return extracted if extracted else [\"generic\"]\n",
        "\n",
        "    def synthesize_and_store_learning(self, human_feedback_text: str, user_query_context: str, turn_context_summary: str, learning_target: str):\n",
        "        print(f\"--- KM: Processing New Learning Candidate (Target: {learning_target}): \\\"{human_feedback_text}\\\" ---\", flush=True)\n",
        "\n",
        "        current_feedback_to_process = human_feedback_text\n",
        "        attempt_count = 0\n",
        "        max_attempts = 3\n",
        "\n",
        "        while attempt_count < max_attempts:\n",
        "            attempt_count += 1\n",
        "            print(f\"KM: Learning Synthesis Attempt {attempt_count}/{max_attempts}...\", flush=True)\n",
        "            print(f\"KM: Synthesizing learning with LLM ({EVAL_MODEL_NAME}) (this may take a moment)...\", flush=True)\n",
        "\n",
        "            evaluator_task_prompt_parts = [\n",
        "                \"You are an AI assistant helping to maintain a knowledge base of 'learnings' from human feedback.\",\n",
        "                f\"The human feedback is targeted towards: {learning_target}.\",\n",
        "                f\"New Human Feedback to process: \\\"{current_feedback_to_process}\\\"\",\n",
        "                f\"Original User Query that led to this feedback: \\\"{user_query_context}\\\"\",\n",
        "                f\"General Conversation Context when feedback was given: \\\"{turn_context_summary}\\\"\",\n",
        "                \"Existing ACTIVE learnings (sample of last 3, if any):\" + \"\".join([f\"  - (ID: {entry.get('learning_id','N/A')[:6]}, Target: {entry.get('learning_target', 'N/A')}) {entry.get('final_learning_statement', '')[:100]}...\" for entry in self.active_learnings_cache[-3:]]) if self.active_learnings_cache else \"  - No existing learnings in cache.\",\n",
        "                \"Your Tasks:\",\n",
        "                \"1. Analyze the 'New Human Feedback'.\",\n",
        "                \"2. Check for CONFLICT or significant REDUNDANCY with existing learnings. Consider general knowledge principles and the stated target of the learnings.\",\n",
        "                \"3. If the feedback is new, valuable, non-conflicting, and non-redundant, synthesize it into a concise, actionable 'Finalized Learning Statement'. This statement should be generalizable if possible.\",\n",
        "                \"Output Format Instructions:\",\n",
        "                \"- If suitable for storing: `FINALIZED_LEARNING: [synthesized statement]`\",\n",
        "                \"- If it conflicts: `CONFLICT_DETECTED: [Explanation of the conflict, and if possible, reference key phrases or IDs of conflicting existing learnings]. Proposed statement if you tried to rephrase: [rephrased statement, or original if no rephrase attempt]`\",\n",
        "                \"- If it's redundant: `REDUNDANT_LEARNING: [Explanation of redundancy, and if possible, reference key phrases or IDs of the existing learning it's redundant with]. Proposed statement if you tried to rephrase: [rephrased statement, or original if no rephrase attempt]`\",\n",
        "                \"- If not actionable/too vague: `NOT_ACTIONABLE: [Explanation]`\",\n",
        "                \"Ensure your entire response strictly follows one of these prefixed formats.\"\n",
        "            ]\n",
        "            synthesis_prompt = \"\\\\n\".join(evaluator_task_prompt_parts)\n",
        "\n",
        "            try:\n",
        "                synthesis_response_obj = self.evaluator_llm.generate_content(synthesis_prompt)\n",
        "                evaluator_synthesis_text = synthesis_response_obj.text.strip()\n",
        "                print(f\"KM: Gemini Learning Synthesis Raw Response:\\\\n{evaluator_synthesis_text}\")\n",
        "\n",
        "                final_statement = None\n",
        "                conflict_explanation = None\n",
        "                redundant_explanation = None\n",
        "                not_actionable_explanation = None\n",
        "\n",
        "                if evaluator_synthesis_text.startswith(\"FINALIZED_LEARNING:\"):\n",
        "                    final_statement = evaluator_synthesis_text.replace(\"FINALIZED_LEARNING:\", \"\", 1).strip()\n",
        "                elif evaluator_synthesis_text.startswith(\"CONFLICT_DETECTED:\"):\n",
        "                    conflict_explanation = evaluator_synthesis_text.replace(\"CONFLICT_DETECTED:\", \"\", 1).strip()\n",
        "                elif evaluator_synthesis_text.startswith(\"REDUNDANT_LEARNING:\"):\n",
        "                    redundant_explanation = evaluator_synthesis_text.replace(\"REDUNDANT_LEARNING:\", \"\", 1).strip()\n",
        "                elif evaluator_synthesis_text.startswith(\"NOT_ACTIONABLE:\"):\n",
        "                    not_actionable_explanation = evaluator_synthesis_text.replace(\"NOT_ACTIONABLE:\", \"\", 1).strip()\n",
        "                else:\n",
        "                    print(\"KM: Gemini learning synthesis response format unexpected. Defaulting to not actionable.\", flush=True)\n",
        "                    not_actionable_explanation = f\"Response format error: {evaluator_synthesis_text}\"\n",
        "\n",
        "                if final_statement:\n",
        "                    self.active_learnings_cache.append({\n",
        "                        \"learning_id\": str(uuid.uuid4()),\n",
        "                        \"timestamp_created\": datetime.now().isoformat(),\n",
        "                        \"original_human_input\": human_feedback_text,\n",
        "                        \"processed_human_input\": current_feedback_to_process,\n",
        "                        \"final_learning_statement\": final_statement,\n",
        "                        \"keywords\": self._extract_keywords(final_statement + \" \" + current_feedback_to_process),\n",
        "                        \"status\": \"active\",\n",
        "                        \"learning_target\": learning_target\n",
        "                    })\n",
        "                    self.learnings_updated_this_session_flag = True\n",
        "                    print(f\"KM: Stored new learning. Cache size: {len(self.active_learnings_cache)}\", flush=True)\n",
        "                    return\n",
        "\n",
        "                elif conflict_explanation:\n",
        "                    print(f\"KM: Learning conflict detected by Gemini: {conflict_explanation}\", flush=True)\n",
        "                    if attempt_count < max_attempts:\n",
        "                        print(\"KM: --- CONFLICT RESOLUTION ---\", flush=True)\n",
        "                        print(f\"Original feedback: '{human_feedback_text}'\", flush=True)\n",
        "                        print(f\"Feedback being processed: '{current_feedback_to_process}'\", flush=True)\n",
        "                        user_choice = input(\"Conflict detected. (M)odify your feedback, (S)kip storing, or (P)roceed with current version for resynthesis? [M/S/P]: \").strip().upper()\n",
        "                        if user_choice == 'M':\n",
        "                            new_feedback = input(\"Enter your modified feedback: \").strip()\n",
        "                            if new_feedback:\n",
        "                                current_feedback_to_process = new_feedback\n",
        "                                print(\"KM: Retrying synthesis with modified feedback.\", flush=True)\n",
        "                                continue\n",
        "                            else:\n",
        "                                print(\"KM: No modification provided. Skipping.\", flush=True)\n",
        "                                return\n",
        "                        elif user_choice == 'P':\n",
        "                            print(\"KM: User chose to proceed. Retrying synthesis with current feedback version.\", flush=True)\n",
        "                            continue\n",
        "                        else:\n",
        "                            print(\"KM: Skipping this learning due to unresolved conflict.\", flush=True)\n",
        "                            return\n",
        "                    else:\n",
        "                        print(\"KM: Max attempts reached for conflict resolution. Skipping this learning.\", flush=True)\n",
        "                        return\n",
        "\n",
        "                elif redundant_explanation:\n",
        "                    print(f\"KM: Learning deemed redundant by Gemini: {redundant_explanation}\", flush=True)\n",
        "                    user_choice_redundant = input(\"This learning seems redundant. (S)kip storing, or (F)orce store anyway? [S/F]: \").strip().upper()\n",
        "                    if user_choice_redundant == 'F':\n",
        "                        proposed_statement_match = re.search(r\"Proposed statement.*?:\\\\s*(.*)\", redundant_explanation, re.IGNORECASE)\n",
        "                        if proposed_statement_match and proposed_statement_match.group(1).strip():\n",
        "                            forced_statement = proposed_statement_match.group(1).strip()\n",
        "                            print(f\"KM: Using LLM's proposed statement due to Force: '{forced_statement}'\", flush=True)\n",
        "                        else:\n",
        "                            forced_statement = current_feedback_to_process\n",
        "                            print(f\"KM: No specific proposed statement from LLM. Using current feedback for Force: '{forced_statement}'\", flush=True)\n",
        "\n",
        "                        self.active_learnings_cache.append({\n",
        "                            \"learning_id\": str(uuid.uuid4()),\n",
        "                            \"timestamp_created\": datetime.now().isoformat(),\n",
        "                            \"original_human_input\": human_feedback_text,\n",
        "                            \"processed_human_input\": current_feedback_to_process,\n",
        "                            \"final_learning_statement\": forced_statement,\n",
        "                            \"keywords\": self._extract_keywords(forced_statement + \" \" + current_feedback_to_process),\n",
        "                            \"status\": \"active_forced_redundancy\",\n",
        "                            \"learning_target\": learning_target,\n",
        "                            \"notes\": f\"Forced storage despite redundancy. Original LLM note: {redundant_explanation}\"\n",
        "                        })\n",
        "                        self.learnings_updated_this_session_flag = True\n",
        "                        print(f\"KM: Stored learning (forced despite redundancy). Cache size: {len(self.active_learnings_cache)}\", flush=True)\n",
        "                        return\n",
        "                    else:\n",
        "                        print(\"KM: Skipping redundant learning.\", flush=True)\n",
        "                        return\n",
        "\n",
        "                elif not_actionable_explanation:\n",
        "                    print(f\"KM: Learning deemed not actionable by Gemini: {not_actionable_explanation}\", flush=True)\n",
        "                    print(\"KM: Skipping this learning.\", flush=True)\n",
        "                    return\n",
        "\n",
        "                else:\n",
        "                    print(\"KM: Synthesis resulted in an unhandled state. Skipping.\", flush=True)\n",
        "                    return\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"KM: Error during learning synthesis attempt {attempt_count}: {e}\", flush=True)\n",
        "                import traceback; traceback.print_exc()\n",
        "                if attempt_count >= max_attempts:\n",
        "                    print(\"KM: Max attempts reached due to errors. Skipping this learning.\", flush=True)\n",
        "                    return\n",
        "                time.sleep(1) # Brief pause before retrying on general error\n",
        "\n",
        "        print(\"KM: Could not synthesize learning after maximum attempts. Skipping.\", flush=True)"
      ],
      "metadata": {
        "id": "IuqeYwg80Ydj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WorkerAgentHandler:\n",
        "    def __init__(self, llm_client, tool_schemas: List[Dict], tool_executor: ToolExecutor, storage_instance: Storage):\n",
        "        self.llm_client = llm_client\n",
        "        self.tool_schemas = tool_schemas\n",
        "        self.tool_executor = tool_executor\n",
        "        self.storage = storage_instance\n",
        "        print(\"WorkerAgentHandler initialized.\")\n",
        "\n",
        "    def _execute_llm_interaction_loop(self, system_prompt: str, messages_for_api: List[Dict[str, Any]], query_type: str, conversation_manager: ConversationManager) -> Tuple[str, List[Dict]]:\n",
        "        tools_for_this_call = self.tool_schemas if query_type == \"OPERATIONAL\" else []\n",
        "        max_iterations = 5 if query_type == \"OPERATIONAL\" else 1 # Max tool use iterations for operational, 1 for others\n",
        "\n",
        "        executed_tool_calls_log: List[Dict] = [] # Log for tool calls in this interaction loop\n",
        "\n",
        "        for i in range(max_iterations):\n",
        "            print(f\"--- WorkerLLM Calling Anthropic (Iter {i+1}/{max_iterations}, QType: {query_type}) ---\")\n",
        "            current_text_response = \"\" # Initialize for this iteration\n",
        "            try:\n",
        "                response = self.llm_client.messages.create(\n",
        "                    model=ANTHROPIC_MODEL_NAME,\n",
        "                    max_tokens=4000,\n",
        "                    temperature=0.0,\n",
        "                    system=system_prompt,\n",
        "                    tools=tools_for_this_call,\n",
        "                    messages=messages_for_api\n",
        "                )\n",
        "            except Exception as e:\n",
        "                error_message = f\"Error communicating with Worker LLM: {e}\"\n",
        "                print(f\"LLM API Error: {e}\")\n",
        "                return error_message, executed_tool_calls_log # Return error and any logs so far\n",
        "\n",
        "            assistant_response_blocks = response.content\n",
        "            # It's important to add the raw assistant response blocks to the API history\n",
        "            # This includes text parts and tool_use parts if any.\n",
        "            messages_for_api.append({\"role\": \"assistant\", \"content\": assistant_response_blocks})\n",
        "\n",
        "            text_blocks = [block.text for block in assistant_response_blocks if block.type == \"text\"]\n",
        "            current_text_response = \" \".join(text_blocks).strip()\n",
        "\n",
        "            if current_text_response.startswith(\"CLARIFICATION_REQUESTED:\"):\n",
        "                return current_text_response, executed_tool_calls_log # Return immediately for clarification\n",
        "\n",
        "            tool_calls_to_process = [block for block in assistant_response_blocks if block.type == \"tool_use\"]\n",
        "\n",
        "            if not tool_calls_to_process or query_type != \"OPERATIONAL\":\n",
        "                # If no tools to call, or not an operational query, this is the final response from the LLM for this loop.\n",
        "                final_response_text = current_text_response if current_text_response else \"Worker AI provided no text content in its final turn.\"\n",
        "                return final_response_text, executed_tool_calls_log\n",
        "\n",
        "            # If there are tool calls to process (and it's an OPERATIONAL query)\n",
        "            tool_results_for_next_llm_call_content = [] # This will be the content for the next \"user\" role message (tool results)\n",
        "\n",
        "            for tool_use_block in tool_calls_to_process:\n",
        "                tool_name, tool_input, tool_use_id = tool_use_block.name, tool_use_block.input, tool_use_block.id\n",
        "                print(f\"WorkerLLM: Requesting Tool Call: {tool_name}, Input: {tool_input}\")\n",
        "\n",
        "                # Execute the tool\n",
        "                tool_result_data = self.tool_executor.execute_tool(tool_name, tool_input, self.storage)\n",
        "\n",
        "                # Log the tool call and its result for the orchestrator/evaluator\n",
        "                executed_tool_calls_log.append({\n",
        "                    \"tool_name\": tool_name,\n",
        "                    \"tool_input\": copy.deepcopy(tool_input), # Deepcopy to avoid modification issues\n",
        "                    \"tool_output\": copy.deepcopy(tool_result_data)\n",
        "                })\n",
        "\n",
        "                # Update conversation manager's context (this was already here)\n",
        "                # Example: update context based on product/order/customer IDs in tool_result_data\n",
        "                entity_type_map = {\n",
        "                    \"order_details\": \"orders\", \"order_id\": \"orders\",\n",
        "                    \"product\": \"products\", \"product_id\": \"products\",\n",
        "                    \"customer\": \"customers\", \"customer_id\": \"customers\"\n",
        "                }\n",
        "                found_entity_type = \"unknown\"\n",
        "                found_entity_id = \"unknown_id\"\n",
        "                found_entity_data = tool_result_data\n",
        "\n",
        "                for key, etype in entity_type_map.items():\n",
        "                    if key in tool_result_data and tool_result_data[key]:\n",
        "                        found_entity_type = etype\n",
        "                        if isinstance(tool_result_data[key], dict) and (\"id\" in tool_result_data[key] or etype[:-1]+\"_id\" in tool_result_data[key]): # e.g. order_details might have 'id'\n",
        "                             found_entity_id = tool_result_data[key].get(\"id\") or tool_result_data[key].get(etype[:-1]+\"_id\")\n",
        "                             found_entity_data = tool_result_data[key]\n",
        "                        elif isinstance(tool_result_data.get(etype[:-1]+\"_id\"), str): # e.g. direct product_id\n",
        "                            found_entity_id = tool_result_data.get(etype[:-1]+\"_id\")\n",
        "                        break # Take first match for simplicity\n",
        "\n",
        "                # Try to get ID more robustly if it's directly in tool_result_data\n",
        "                if found_entity_id == \"unknown_id\":\n",
        "                     if \"order_id\" in tool_result_data: found_entity_id = tool_result_data[\"order_id\"]\n",
        "                     elif \"product_id\" in tool_result_data: found_entity_id = tool_result_data[\"product_id\"]\n",
        "                     elif \"customer_id\" in tool_result_data: found_entity_id = tool_result_data[\"customer_id\"]\n",
        "\n",
        "                if found_entity_id != \"unknown_id\":\n",
        "                    conversation_manager.update_entity_in_context(\n",
        "                        entity_type=found_entity_type,\n",
        "                        entity_id=found_entity_id,\n",
        "                        data=found_entity_data\n",
        "                    )\n",
        "                conversation_manager.set_last_action(f\"tool_{tool_name}_Anthropic\", {\"input\": tool_input, \"result_summary\": tool_result_data.get(\"status\", \"unknown_status\")})\n",
        "\n",
        "                tool_results_for_next_llm_call_content.append({\n",
        "                    \"type\": \"tool_result\",\n",
        "                    \"tool_use_id\": tool_use_id,\n",
        "                    \"content\": json.dumps(tool_result_data) if isinstance(tool_result_data, dict) else str(tool_result_data)\n",
        "                    # Consider adding an error field from tool_result_data if status is error\n",
        "                    # \"is_error\": tool_result_data.get(\"status\") == \"error\" if isinstance(tool_result_data, dict) else False\n",
        "                })\n",
        "\n",
        "            # Add the aggregated tool results as a new \"user\" message for the next LLM call\n",
        "            if tool_results_for_next_llm_call_content:\n",
        "                messages_for_api.append({\"role\": \"user\", \"content\": tool_results_for_next_llm_call_content})\n",
        "            else: # Should not happen if tool_calls_to_process was non-empty\n",
        "                print(\"WorkerLLM: No tool results to append, though tool calls were present. This is unexpected.\")\n",
        "\n",
        "\n",
        "        # If loop finishes (max_iterations reached)\n",
        "        final_response_text = current_text_response if current_text_response else \"Worker AI reached max tool iterations without a final text response.\"\n",
        "        return final_response_text, executed_tool_calls_log"
      ],
      "metadata": {
        "id": "XYs7E68G0qBP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResponseEvaluator:\n",
        "    def __init__(self, evaluator_llm_instance):\n",
        "        self.evaluator_llm = evaluator_llm_instance\n",
        "        print(\"ResponseEvaluator initialized.\")\n",
        "\n",
        "    def evaluate_turn(self, user_message: str, query_type: str, worker_response_text: str,\n",
        "                      context_summary: str, rag_learnings_provided: str,\n",
        "                      clarification_interactions: Optional[List[Dict]],\n",
        "                      initial_datastore_state: Dict[str, Any],\n",
        "                      final_datastore_state: Dict[str, Any],\n",
        "                      executed_tool_calls_log: List[Dict]) -> Dict[str, Any]:\n",
        "\n",
        "        initial_ds_prompt = f\"Data Store State *Before* AI Action:\\\\n{json.dumps(initial_datastore_state, indent=2, default=str)}\"\n",
        "        final_ds_prompt = f\"Data Store State *After* AI Action:\\\\n{json.dumps(final_datastore_state, indent=2, default=str)}\"\n",
        "\n",
        "        clarification_info_prompt = \"No worker AI clarifications this turn.\"\n",
        "        if clarification_interactions:\n",
        "            clar_summary = [f\"  Q: '{c.get('agent_question', 'N/A')}' -> User A: '{c.get('user_answer', 'N/A')}'\" for c in clarification_interactions]\n",
        "            clarification_info_prompt = f\"Worker AI Clarification Interactions:\\\\n\" + \"\\\\n\".join(clar_summary)\n",
        "\n",
        "        tool_log_prompt = \"No tools were executed by the Worker AI this turn.\"\n",
        "        if executed_tool_calls_log:\n",
        "            formatted_tool_calls = []\n",
        "            for i, call in enumerate(executed_tool_calls_log):\n",
        "                output_summary = call.get('tool_output', {})\n",
        "                if isinstance(output_summary, dict):\n",
        "                    # Simpler summary for the prompt, focusing on status or a few key fields\n",
        "                    if \"status\" in output_summary:\n",
        "                        summary_dict = {\"status\": output_summary[\"status\"]}\n",
        "                        if \"message\" in output_summary: summary_dict[\"message\"] = output_summary[\"message\"]\n",
        "                        if \"order_id\" in output_summary: summary_dict[\"order_id\"] = output_summary[\"order_id\"]\n",
        "                        if \"product_id\" in output_summary: summary_dict[\"product_id\"] = output_summary[\"product_id\"]\n",
        "                        output_summary_str = json.dumps(summary_dict, default=str)\n",
        "                    else: # Fallback for dicts without status\n",
        "                        output_summary_str = json.dumps(output_summary, indent=1, default=str)\n",
        "                        if len(output_summary_str) > 200:\n",
        "                            output_summary_str = output_summary_str[:200] + \"...\"\n",
        "                else:\n",
        "                    output_summary_str = str(output_summary)\n",
        "                    if len(output_summary_str) > 200:\n",
        "                         output_summary_str = output_summary_str[:200] + \"...\"\n",
        "\n",
        "                formatted_tool_calls.append(\n",
        "                    f\"  Tool Call {i+1}:\\n\"\n",
        "                    f\"    Name: {call.get('tool_name')}\\n\"\n",
        "                    f\"    Input: {json.dumps(call.get('tool_input'), default=str)}\\n\"\n",
        "                    f\"    Output Summary (from tool perspective): {output_summary_str}\" # Clarified this is tool's raw output summary\n",
        "                )\n",
        "            tool_log_prompt = f\"Worker AI Tool Calls Executed This Turn:\\\\n\" + \"\\\\n\".join(formatted_tool_calls)\n",
        "\n",
        "        eval_content_prompt = f\"\"\"\n",
        "User query: {user_message}\n",
        "Classified Query Type: {query_type}\n",
        "\n",
        "Context provided to assistant (summary):\n",
        "{context_summary}\n",
        "\n",
        "Relevant RAG Learnings provided to assistant:\n",
        "{rag_learnings_provided}\n",
        "\n",
        "{initial_ds_prompt}\n",
        "\n",
        "{tool_log_prompt}\n",
        "\n",
        "{final_ds_prompt}\n",
        "\n",
        "{clarification_info_prompt}\n",
        "\n",
        "Worker AI (Claude) final textual response to user:\n",
        "{worker_response_text}\n",
        "---\n",
        "INSTRUCTIONS FOR EVALUATOR (You are Gemini {EVAL_MODEL_NAME}):\n",
        "Based on your system prompt (which emphasizes impartiality and detailed assessment criteria) and the classified query type ({query_type}), please evaluate the AI assistant's response.\n",
        "- If OPERATIONAL, focus on tool use accuracy (refer to 'Worker AI Tool Calls Executed'), data store changes (Before vs. After), and whether the final user-facing textual response accurately and clearly conveys these actions and their outcomes.\n",
        "- If METACOGNITIVE_LEARNINGS_SUMMARY, focus on whether the AI accurately summarized the 'Relevant RAG Learnings' it was provided.\n",
        "Provide detailed reasoning for scores for each criterion (Accuracy, Efficiency, Context Awareness, Helpfulness & Clarity) and an **Overall Score**. All scores should be an integer from 1 to 10.\n",
        "Format the Overall Score clearly, for example: \"Overall Score: X/10\".\n",
        "Explicitly reference the tool call log and datastore states when assessing operational tasks.\n",
        "\"\"\"\n",
        "        try:\n",
        "            gemini_response_obj = self.evaluator_llm.generate_content(eval_content_prompt)\n",
        "            evaluation_text = gemini_response_obj.text\n",
        "\n",
        "            score = self._extract_score(evaluation_text)\n",
        "\n",
        "            return {\n",
        "                \"anthropic_score\": score,\n",
        "                \"full_evaluation\": evaluation_text,\n",
        "                \"clarification_details_evaluator\": {\"used\": False},\n",
        "                \"query_type_evaluated\": query_type,\n",
        "                \"raw_evaluation_text\": evaluation_text\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Evaluator: Error during Gemini evaluation: {e}\") # This is an actual error print\n",
        "            import traceback; traceback.print_exc()\n",
        "            return {\n",
        "                \"error\": str(e),\n",
        "                \"anthropic_score\": 0,\n",
        "                \"full_evaluation\": f\"Evaluation failed: {e}\",\n",
        "                \"clarification_details_evaluator\": {},\n",
        "                \"query_type_evaluated\": query_type,\n",
        "                \"raw_evaluation_text\": f\"Evaluation Error: {e}\"\n",
        "            }\n",
        "\n",
        "    def _extract_score(self, evaluation_text: str) -> int:\n",
        "        # Attempt to find \"Overall Score: X/10\" or similar, more flexibly.\n",
        "        # Prioritize patterns that explicitly mention \"/10\".\n",
        "        patterns = [\n",
        "            r\"Overall Score\\s*:\\s*(\\d{1,2})(?:/10)?\",  # \"Overall Score : X\" or \"Overall Score : X/10\"\n",
        "            r\"Overall Score\\s*is\\s*(\\d{1,2})(?:/10)?\",\n",
        "            r\"Overall\\s*:\\s*(\\d{1,2})(?:/10)?\",\n",
        "            r\"Score\\s*:\\s*(\\d{1,2})(?:/10)?\", # Generic score if \"Overall\" is missed but clearly formatted\n",
        "            r\"\\b(\\d{1,2})/10\\b\" # Simple X/10 if it stands alone near typical score phrases\n",
        "        ]\n",
        "\n",
        "        # Search for \"Overall Score\" section first\n",
        "        overall_score_section_match = re.search(r\"(Overall Score.*?)(?:\\n\\n|\\n---|$)\", evaluation_text, re.IGNORECASE | re.DOTALL)\n",
        "        text_to_search = evaluation_text\n",
        "        if overall_score_section_match:\n",
        "            text_to_search = overall_score_section_match.group(1) # Search within this section first\n",
        "\n",
        "        for p_str in patterns:\n",
        "            match = re.search(p_str, text_to_search, re.IGNORECASE) # Search for first best match\n",
        "            if match:\n",
        "                try:\n",
        "                    score_value = int(match.group(1))\n",
        "                    if 0 <= score_value <= 10:\n",
        "                        # print(f\"DEBUG: Extracted score {score_value} using pattern: {p_str}\") # Optional debug\n",
        "                        return score_value\n",
        "                except (ValueError, IndexError):\n",
        "                    continue\n",
        "\n",
        "        # Fallback: if no \"Overall Score\" section found, or no match within it, search whole text.\n",
        "        if not overall_score_section_match:\n",
        "            for p_str in patterns:\n",
        "                match = re.search(p_str, evaluation_text, re.IGNORECASE)\n",
        "                if match:\n",
        "                    try:\n",
        "                        score_value = int(match.group(1))\n",
        "                        if 0 <= score_value <= 10:\n",
        "                            # print(f\"DEBUG: Extracted score {score_value} (full text search) using pattern: {p_str}\") # Optional debug\n",
        "                            return score_value\n",
        "                    except (ValueError, IndexError):\n",
        "                        continue\n",
        "\n",
        "        # This print should ONLY occur if extraction truly fails after trying all patterns.\n",
        "        # The stray \"Evaluator: Could not reliably extract...\" message in the user's log\n",
        "        # was likely coming from an older version or a different part of the code if not from here.\n",
        "        # For the *final summary*, this message will appear if this function returns 0.\n",
        "        # print(f\"Evaluator (INFO): Could not reliably extract a 0-10 'Overall Score' from evaluation text. Defaulting to 0. Text sample: ...{evaluation_text[-350:]}\")\n",
        "        return 0"
      ],
      "metadata": {
        "id": "ZFpBL_-HSGPY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentOrchestrator:\n",
        "    def __init__(self):\n",
        "        # ... (initialization remains the same) ...\n",
        "        self.classifier_llm_client = gemini.GenerativeModel(model_name=CLASSIFIER_MODEL_NAME)\n",
        "        self.query_classifier = QueryClassifier(llm_client=self.classifier_llm_client)\n",
        "        self.storage = Storage()\n",
        "        self.conversation_manager = ConversationManager()\n",
        "        self.tool_functions_map = {\n",
        "            \"create_customer\": create_customer,\n",
        "            \"get_customer_info\": get_customer_info,\n",
        "            \"update_customer\": update_customer,\n",
        "            \"create_product\": create_product,\n",
        "            \"update_product\": update_product,\n",
        "            \"get_product_info\": get_product_info,\n",
        "            \"list_all_products\": list_all_products,\n",
        "            \"create_order\": create_order,\n",
        "            \"get_order_details\": get_order_details,\n",
        "            \"update_order_status\": update_order_status,\n",
        "        }\n",
        "        self.tool_executor = ToolExecutor(self.tool_functions_map)\n",
        "\n",
        "        knowledge_synthesis_llm = gemini.GenerativeModel(model_name=EVAL_MODEL_NAME)\n",
        "        self.knowledge_manager = KnowledgeManager(LEARNINGS_DRIVE_BASE_PATH, DRIVE_MOUNT_PATH, DEFAULT_LEARNINGS_DRIVE_SUBPATH, knowledge_synthesis_llm)\n",
        "\n",
        "        self.worker_agent_handler = WorkerAgentHandler(anthropic_client, tools_schemas_list, self.tool_executor, self.storage)\n",
        "\n",
        "        main_evaluator_llm = gemini.GenerativeModel(model_name=EVAL_MODEL_NAME, system_instruction=evaluator_system_prompt)\n",
        "        self.response_evaluator = ResponseEvaluator(evaluator_llm_instance=main_evaluator_llm)\n",
        "\n",
        "        self.evaluation_results_log: List[Dict] = []\n",
        "        print(\"AgentOrchestrator initialized.\")\n",
        "\n",
        "    def _handle_worker_clarification_interaction(self, agent_question_text: str, system_prompt: str,\n",
        "                                                current_turn_history: List[Dict], query_type: str,\n",
        "                                                conversation_manager: ConversationManager,\n",
        "                                                max_attempts: int = 2) -> Tuple[str, List[Dict], List[Dict]]:\n",
        "        # ... (remains the same) ...\n",
        "        clarification_interactions = []\n",
        "        response_text = agent_question_text\n",
        "        executed_tool_calls_log_clarification_phase: List[Dict] = []\n",
        "\n",
        "        for attempt in range(max_attempts):\n",
        "            actual_question = response_text.split(\"CLARIFICATION_REQUESTED:\", 1)[-1].strip() if \"CLARIFICATION_REQUESTED:\" in response_text else response_text\n",
        "            print(f\"--- Worker AI requests clarification: {actual_question} ---\", flush=True) # Added flush\n",
        "\n",
        "            user_clarification = \"\"\n",
        "            try:\n",
        "                user_clarification = input(f\"Your response to Worker AI: \").strip()\n",
        "            except EOFError:\n",
        "                print(\"EOFError encountered during input. Assuming no user clarification.\", flush=True) # Added flush\n",
        "                user_clarification = \"(User provided no further input due to EOF)\"\n",
        "\n",
        "            if not user_clarification and not user_clarification.startswith(\"(User provided no further input\"):\n",
        "                 user_clarification = \"(User provided no further input)\"\n",
        "\n",
        "            clarification_interactions.append({\"agent_question\": actual_question, \"user_answer\": user_clarification})\n",
        "            current_turn_history.append({\"role\": \"user\", \"content\": user_clarification})\n",
        "\n",
        "            response_text, tools_log_this_iteration = self.worker_agent_handler._execute_llm_interaction_loop(\n",
        "                system_prompt, current_turn_history, query_type, conversation_manager\n",
        "            )\n",
        "            executed_tool_calls_log_clarification_phase.extend(tools_log_this_iteration)\n",
        "\n",
        "            if not response_text.startswith(\"CLARIFICATION_REQUESTED:\"):\n",
        "                return response_text, clarification_interactions, executed_tool_calls_log_clarification_phase\n",
        "\n",
        "        print(\"Max clarification attempts reached for worker AI.\", flush=True) # Added flush\n",
        "        return response_text, clarification_interactions, executed_tool_calls_log_clarification_phase\n",
        "\n",
        "\n",
        "    def run_agent_turn(self, user_message: str) -> Dict[str, Any]:\n",
        "        print(\"\\n--- Orchestrator: Starting Agent Turn ---\", flush=True)\n",
        "        self.conversation_manager.add_user_message(user_message)\n",
        "        print(\"Orchestrator: Classifying query...\", flush=True)\n",
        "        query_type = self.query_classifier.classify(user_message)\n",
        "        print(f\"--- Orchestrator: Classified Query Type: {query_type} ---\", flush=True)\n",
        "\n",
        "        context_summary_for_worker = self.conversation_manager.get_context_summary()\n",
        "        print(\"Orchestrator: Retrieving RAG learnings for Worker Agent...\", flush=True)\n",
        "        rag_learnings_for_worker = self.knowledge_manager.get_relevant_learnings_for_prompt(\n",
        "            user_message, query_type, recipient_role=\"Agent\"\n",
        "        )\n",
        "        if rag_learnings_for_worker != \"No specific relevant learnings from knowledge base provided for this query after all filters.\" and \\\n",
        "           rag_learnings_for_worker != \"No specific relevant learnings from knowledge base found for this query based on role.\" and \\\n",
        "           rag_learnings_for_worker != \"No specific relevant learnings from knowledge base provided for this query.\":\n",
        "            # Multi-line RAG output will flush with its own newlines usually.\n",
        "            print(f\"Orchestrator: RAG for Worker:\\n{rag_learnings_for_worker}\")\n",
        "        else:\n",
        "            print(\"Orchestrator: No specific RAG learnings found for Worker Agent for this query.\", flush=True)\n",
        "\n",
        "        full_worker_prompt = (\n",
        "            f\"{worker_operational_system_prompt if query_type == 'OPERATIONAL' else worker_metacognitive_learnings_system_prompt}\\\\n\\\\n\"\n",
        "            f\"Conversation Context Summary (recent entities and last action):\\\\n{context_summary_for_worker}\\\\n\\\\n\"\n",
        "            f\"{rag_learnings_for_worker}\"\n",
        "        )\n",
        "\n",
        "        initial_datastore_state = self.storage.get_full_datastore_copy()\n",
        "        current_turn_processing_history = self.conversation_manager.get_full_conversation_for_api()\n",
        "\n",
        "        print(\"Orchestrator: Worker Agent processing request (this may involve LLM calls and tool use)...\", flush=True)\n",
        "        worker_response_text, executed_tool_calls_log = self.worker_agent_handler._execute_llm_interaction_loop(\n",
        "            full_worker_prompt, current_turn_processing_history, query_type, self.conversation_manager\n",
        "        )\n",
        "\n",
        "        clarification_interactions = []\n",
        "        if worker_response_text.startswith(\"CLARIFICATION_REQUESTED:\"):\n",
        "            print(\"Orchestrator: Worker Agent requested clarification. Initiating clarification loop...\", flush=True)\n",
        "            worker_response_text, clarification_interactions, tools_during_clarif = self._handle_worker_clarification_interaction(\n",
        "                worker_response_text, full_worker_prompt, current_turn_processing_history, query_type, self.conversation_manager\n",
        "            )\n",
        "            executed_tool_calls_log.extend(tools_during_clarif)\n",
        "\n",
        "        self.conversation_manager.add_assistant_message(worker_response_text, query_type)\n",
        "        final_datastore_state = self.storage.get_full_datastore_copy()\n",
        "        print(\"--- Orchestrator: Agent Turn Completed ---\", flush=True)\n",
        "\n",
        "        return {\n",
        "            \"user_message\": user_message,\n",
        "            \"query_type\": query_type,\n",
        "            \"anthropic_response\": worker_response_text,\n",
        "            \"executed_tool_calls\": executed_tool_calls_log,\n",
        "            \"context_summary_for_worker\": context_summary_for_worker,\n",
        "            \"initial_datastore_state\": initial_datastore_state,\n",
        "            \"final_datastore_state\": final_datastore_state,\n",
        "            \"clarification_interactions\": clarification_interactions\n",
        "        }\n",
        "\n",
        "    def handle_feedback_on_worker_response(self, original_user_query: str,\n",
        "                                           context_summary_for_worker: str,\n",
        "                                           human_feedback_on_worker: str):\n",
        "        print(\"--- Orchestrator: Processing Feedback on Worker AI's Response ---\", flush=True)\n",
        "        if human_feedback_on_worker.lower() not in ['skip', ''] and human_feedback_on_worker:\n",
        "            self.knowledge_manager.synthesize_and_store_learning(\n",
        "                human_feedback_on_worker,\n",
        "                original_user_query,\n",
        "                context_summary_for_worker,\n",
        "                learning_target=\"AgentAndEvaluator\"\n",
        "            )\n",
        "            # persist_active_learnings already has its own print statements with flush\n",
        "            if self.knowledge_manager.learnings_updated_this_session_flag:\n",
        "                self.knowledge_manager.persist_active_learnings()\n",
        "        else:\n",
        "            print(\"Orchestrator: No feedback provided for worker response or 'skip' entered.\", flush=True)\n",
        "        print(\"--- Orchestrator: Worker Feedback Processing Completed ---\", flush=True)\n",
        "\n",
        "\n",
        "    def run_evaluation_turn(self, agent_turn_data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        print(\"\\n--- Orchestrator: Starting Evaluation Turn ---\", flush=True) # Added flush\n",
        "        user_message = agent_turn_data[\"user_message\"]\n",
        "        query_type = agent_turn_data[\"query_type\"]\n",
        "        worker_response_text = agent_turn_data[\"anthropic_response\"]\n",
        "        context_summary_for_worker = agent_turn_data[\"context_summary_for_worker\"]\n",
        "        clarification_interactions = agent_turn_data[\"clarification_interactions\"]\n",
        "        initial_datastore_state = agent_turn_data[\"initial_datastore_state\"]\n",
        "        final_datastore_state = agent_turn_data[\"final_datastore_state\"]\n",
        "        executed_tool_calls_log = agent_turn_data[\"executed_tool_calls\"]\n",
        "\n",
        "        print(\"Orchestrator: Retrieving RAG learnings for AI Evaluator...\", flush=True) # Added flush\n",
        "        rag_learnings_for_evaluator = self.knowledge_manager.get_relevant_learnings_for_prompt(\n",
        "            user_message, query_type, recipient_role=\"Evaluator\"\n",
        "        )\n",
        "        if rag_learnings_for_evaluator != \"No specific relevant learnings from knowledge base provided for this query after all filters.\" and \\\n",
        "           rag_learnings_for_evaluator != \"No specific relevant learnings from knowledge base found for this query based on role.\" and \\\n",
        "           rag_learnings_for_evaluator != \"No specific relevant learnings from knowledge base provided for this query.\":\n",
        "            # Multi-line RAG output will likely flush due to newlines.\n",
        "            print(f\"Orchestrator: RAG for Evaluator:\\n{rag_learnings_for_evaluator}\")\n",
        "        else:\n",
        "            print(\"Orchestrator: No specific RAG learnings found for AI Evaluator for this query.\", flush=True) # Added flush\n",
        "\n",
        "\n",
        "        print(f\"Orchestrator: Performing AI evaluation with Gemini ({EVAL_MODEL_NAME}) (this may take a moment)...\", flush=True) # Added flush\n",
        "        evaluation_result = self.response_evaluator.evaluate_turn(\n",
        "            user_message, query_type, worker_response_text,\n",
        "            context_summary_for_worker,\n",
        "            rag_learnings_for_evaluator,\n",
        "            clarification_interactions,\n",
        "            initial_datastore_state,\n",
        "            final_datastore_state,\n",
        "            executed_tool_calls_log\n",
        "        )\n",
        "\n",
        "        # This log append is internal, no print needed here\n",
        "        self.evaluation_results_log.append({\n",
        "            \"user_message\": user_message,\n",
        "            \"query_type\": query_type,\n",
        "            \"worker_response\": worker_response_text,\n",
        "            \"tool_calls\": copy.deepcopy(executed_tool_calls_log),\n",
        "            \"evaluation_details\": evaluation_result\n",
        "        })\n",
        "        print(\"--- Orchestrator: Evaluation Turn Completed ---\", flush=True) # Added flush\n",
        "        return evaluation_result\n",
        "\n",
        "    def handle_feedback_on_evaluation(self, original_user_query: str, worker_response_summary: str,\n",
        "                                      evaluation_text_summary: str, human_feedback_on_evaluator: str):\n",
        "        print(\"--- Orchestrator: Processing Feedback on AI Evaluator's Assessment ---\", flush=True) # Added flush\n",
        "        if human_feedback_on_evaluator.lower() not in ['skip', ''] and human_feedback_on_evaluator:\n",
        "            eval_feedback_context = (\n",
        "                f\"Feedback is on an evaluation. Original query: '{original_user_query}'. \"\n",
        "                f\"Worker response (summary): '{worker_response_summary[:100]}...'. \"\n",
        "                f\"Evaluation (summary): '{evaluation_text_summary[:150]}...'\"\n",
        "            )\n",
        "            self.knowledge_manager.synthesize_and_store_learning(\n",
        "                human_feedback_on_evaluator,\n",
        "                original_user_query,\n",
        "                eval_feedback_context,\n",
        "                learning_target=\"EvaluatorOnly\"\n",
        "            )\n",
        "            # persist_active_learnings already has its own print statements with flush\n",
        "            if self.knowledge_manager.learnings_updated_this_session_flag:\n",
        "                self.knowledge_manager.persist_active_learnings()\n",
        "        else:\n",
        "            print(\"Orchestrator: No feedback provided for evaluator or 'skip' entered.\", flush=True)\n",
        "        print(\"--- Orchestrator: Evaluator Feedback Processing Completed ---\", flush=True)\n",
        "\n",
        "\n",
        "    def get_evaluation_log(self) -> List[Dict]:\n",
        "        return self.evaluation_results_log\n",
        "\n",
        "    def persist_learnings_on_exit(self):\n",
        "        if self.knowledge_manager.learnings_updated_this_session_flag:\n",
        "            print(\"\\nOrchestrator: Persisting any remaining updated learnings on exit (this may take a moment)...\", flush=True)\n",
        "            self.knowledge_manager.persist_active_learnings()\n",
        "        else:\n",
        "            print(\"\\nOrchestrator: No new learnings to persist on exit.\", flush=True)"
      ],
      "metadata": {
        "id": "UzLHm8MmSOMC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"\\\\nStarting Main Execution with REFACTORED Agent System...\")\n",
        "    print(\"=\" * 70)\n",
        "    orchestrator = AgentOrchestrator()\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            print(\"\\\\n\" + \"=\" * 70)\n",
        "            print(\"AWAITING USER INPUT...\")\n",
        "            user_query = input(\"Enter query (or 'quit' to exit): \").strip()\n",
        "\n",
        "            if user_query.lower() == 'quit':\n",
        "                orchestrator.persist_learnings_on_exit()\n",
        "                print(\"Exiting system.\")\n",
        "                print(\"=\" * 70)\n",
        "                break\n",
        "            if not user_query:\n",
        "                continue\n",
        "\n",
        "            print(f\"\\n>>> User Query: '{user_query}'\")\n",
        "\n",
        "            # === AGENT ACTION PHASE ===\n",
        "            agent_turn_data = orchestrator.run_agent_turn(user_query)\n",
        "\n",
        "            worker_response_text = agent_turn_data.get('anthropic_response', \"No worker response found.\")\n",
        "            query_type_from_turn = agent_turn_data.get('query_type', \"N/A\")\n",
        "            context_for_worker_feedback = agent_turn_data.get('context_summary_for_worker', \"N/A\")\n",
        "\n",
        "            print(f\"\\\\n--- Worker AI Final Response (Type: {query_type_from_turn}) ---\")\n",
        "            print(worker_response_text)\n",
        "            print(\"--- End of Worker AI Response ---\")\n",
        "\n",
        "            # === FEEDBACK ON AGENT PHASE ===\n",
        "            print(\"\\nREQUESTING FEEDBACK ON WORKER AI:\")\n",
        "            try:\n",
        "                human_feedback_on_worker = input(\"Orchestrator: Feedback on Worker AI's response? (type or 'skip'): \").strip()\n",
        "                orchestrator.handle_feedback_on_worker_response(\n",
        "                    original_user_query=user_query,\n",
        "                    context_summary_for_worker=context_for_worker_feedback,\n",
        "                    human_feedback_on_worker=human_feedback_on_worker\n",
        "                )\n",
        "            except EOFError:\n",
        "                print(\"Orchestrator: Skipping feedback on worker response (EOF).\")\n",
        "\n",
        "            # === EVALUATION PHASE ===\n",
        "            evaluation_details = orchestrator.run_evaluation_turn(agent_turn_data)\n",
        "\n",
        "            raw_eval_text_for_feedback = \"No evaluation text.\" # Default for feedback context\n",
        "            print(\"\\n--- AI Evaluator's Assessment ---\") # Header for the block\n",
        "            if evaluation_details and not evaluation_details.get(\"error\"):\n",
        "                raw_eval_text_for_feedback = evaluation_details.get(\"raw_evaluation_text\", \"No raw evaluation text found.\")\n",
        "                # The raw_eval_text already contains good formatting from the LLM\n",
        "                print(raw_eval_text_for_feedback)\n",
        "            elif evaluation_details and evaluation_details.get(\"error\"):\n",
        "                error_message = evaluation_details.get('error', 'Unknown evaluation error.')\n",
        "                raw_eval_text_for_feedback = f\"Evaluation Error: {error_message}\"\n",
        "                print(raw_eval_text_for_feedback)\n",
        "            else:\n",
        "                print(\"No evaluation details found for this turn.\")\n",
        "            print(\"--- End of AI Evaluator's Assessment ---\")\n",
        "\n",
        "            # === FEEDBACK ON EVALUATION PHASE ===\n",
        "            print(\"\\nREQUESTING FEEDBACK ON AI EVALUATOR:\")\n",
        "            try:\n",
        "                human_feedback_on_evaluator = input(\"Orchestrator: Feedback on Evaluator's assessment? (type or 'skip'): \").strip()\n",
        "                orchestrator.handle_feedback_on_evaluation(\n",
        "                    original_user_query=user_query,\n",
        "                    worker_response_summary=worker_response_text,\n",
        "                    evaluation_text_summary=raw_eval_text_for_feedback,\n",
        "                    human_feedback_on_evaluator=human_feedback_on_evaluator\n",
        "                )\n",
        "            except EOFError:\n",
        "                print(\"Orchestrator: Skipping feedback on evaluator assessment (EOF).\")\n",
        "\n",
        "        except SystemExit:\n",
        "            print(\"\\nSystem exit requested.\")\n",
        "            orchestrator.persist_learnings_on_exit()\n",
        "            break\n",
        "        except EOFError:\n",
        "            print(\"\\\\nEOF encountered. Exiting gracefully.\")\n",
        "            orchestrator.persist_learnings_on_exit()\n",
        "            break\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\\\nKeyboard interrupt detected. Exiting.\")\n",
        "            orchestrator.persist_learnings_on_exit()\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\nCRITICAL ERROR in main loop: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            # Consider whether to persist learnings on critical unknown errors\n",
        "            # orchestrator.persist_learnings_on_exit()\n",
        "\n",
        "    # --- Final Evaluation Summary ---\n",
        "    print(\"\\\\n\" + \"=\" * 30 + \" FINAL EVALUATION SUMMARY \" + \"=\" * 30)\n",
        "    results_log = orchestrator.get_evaluation_log()\n",
        "    total_score, num_q_evaluated = 0, 0\n",
        "\n",
        "    if not results_log:\n",
        "        print(\"No queries were processed and evaluated in this session.\")\n",
        "    else:\n",
        "        for i, turn_data in enumerate(results_log):\n",
        "            user_msg = turn_data.get('user_message', 'N/A')\n",
        "            q_type = turn_data.get('query_type', 'N/A')\n",
        "            eval_details_from_log = turn_data.get('evaluation_details', {})\n",
        "\n",
        "            score = 0 # Default score for the summary line if extraction fails or error\n",
        "            if isinstance(eval_details_from_log, dict) and not eval_details_from_log.get(\"error\"):\n",
        "                # Use the score extracted and stored during evaluate_turn\n",
        "                score = eval_details_from_log.get('anthropic_score', 0)\n",
        "                if score > 0 : # Only count towards average if a valid score was extracted\n",
        "                    total_score += score\n",
        "                    num_q_evaluated += 1\n",
        "                print(f\"Q{i+1}: '{user_msg}' (Type: {q_type}) -> Score: {score}\")\n",
        "            elif isinstance(eval_details_from_log, dict) and eval_details_from_log.get(\"error\"):\n",
        "                print(f\"Q{i+1}: '{user_msg}' (Type: {q_type}) -> Evaluation Error: {eval_details_from_log.get('error')}\")\n",
        "            else:\n",
        "                print(f\"Q{i+1}: '{user_msg}' (Type: {q_type}) -> No valid evaluation details or score logged.\")\n",
        "\n",
        "    if num_q_evaluated > 0:\n",
        "        print(f\"\\\\nAverage Score over {num_q_evaluated} successfully scored queries: {total_score / num_q_evaluated:.2f}\")\n",
        "    else:\n",
        "        print(\"\\\\nNo queries were successfully scored to calculate an average score.\")\n",
        "    print(f\"Total aggregate score (sum of successfully extracted scores) for the session: {total_score}\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"Execution Finished.\")\n",
        "\n",
        "# To run:\n",
        "# main()"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "id": "O2-ztJ2BO7gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Sample queries:\n",
        "* Show me all the products available\n",
        "* I'd like to order 25 Perplexinators, please\n",
        "* Show me the status of my order\n",
        "* (If the order is not in Shipped state, then) Please ship my order now\n",
        "* How many Perplexinators are now left in stock?\n",
        "* Add a new customer: Bill Leece, bill.leece@mail.com, +1.222.333.4444\n",
        "* Change bill.leece@mail.com's phone number to +1.999.888.7777\n",
        "* Add new new product: Gizmo X, description: A fancy gizmo, price: 29.99, inventory: 50\n",
        "* Update Gizzmo's price to 99.99 #Note the misspelling of 'Gizmo'\n",
        "* When was the last time the Toronto Maple Leafs won the Stanley Cup?\n",
        "* sk\n",
        "* Summarize your learnings from our recent interactions.\n",
        "\"\"\"\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dg85ek6bSvW5",
        "outputId": "b4760029-75aa-4a5b-ea0d-cb2edcaa0395"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nStarting Main Execution with REFACTORED Agent System...\n",
            "======================================================================\n",
            "QueryClassifier initialized with LLM client.\n",
            "Storage initialized with deep copies of initial data.\n",
            "ConversationManager initialized.\n",
            "ToolExecutor initialized.\n",
            "KM: Attempting to load initial learnings from Drive...\n",
            "KM: Loading initial learnings from: /content/drive/My Drive/AI/Knowledgebases/learnings_20250520_222400_897443.json\n",
            "KM: Successfully loaded 3 learnings.\n",
            "KnowledgeManager initialized. Loaded 3 initial learnings from /content/drive/My Drive/AI/Knowledgebases.\n",
            "WorkerAgentHandler initialized.\n",
            "ResponseEvaluator initialized.\n",
            "AgentOrchestrator initialized.\n",
            "\\n======================================================================\n",
            "AWAITING USER INPUT...\n",
            "Enter query (or 'quit' to exit): Show me all the products available\n",
            "\n",
            ">>> User Query: 'Show me all the products available'\n",
            "\n",
            "--- Orchestrator: Starting Agent Turn ---\n",
            "Orchestrator: Classifying query...\n",
            "--- Orchestrator: Classified Query Type: OPERATIONAL ---\n",
            "Orchestrator: Retrieving RAG learnings for Worker Agent...\n",
            "Orchestrator: RAG for Worker:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Worker Agent processing request (this may involve LLM calls and tool use)...\n",
            "--- WorkerLLM Calling Anthropic (Iter 1/5, QType: OPERATIONAL) ---\n",
            "WorkerLLM: Requesting Tool Call: list_all_products, Input: {}\n",
            "[Tool Exec] list_all_products: Found 3 products.\n",
            "--- [ToolExecutor] Result for list_all_products: {\n",
            "  \"status\": \"success\",\n",
            "  \"count\": 3,\n",
            "  \"products\": {\n",
            "    \"P1\": {\n",
            "      \"name\": \"Widget A\",\n",
            "      \"description\": \"A simple widget. Very compact.\",\n",
            "      \"price\": 19.99,\n",
            "      \"inventory_count\": 999\n",
            "    },\n",
            "    \"P2\": {\n",
            "      \"name\": \"Gadget B\",\n",
            "      \"description\": \"A powerful gadget. It spins.\",\n",
            "      \"price\": 49.99,\n",
            "      \"inventory_count\": 200\n",
            "    },\n",
            "    \"P3\": {\n",
            "      \"name\": \"Perplexinator\",\n",
            "      \"description\": \"A perplexing perfunctator\",\n",
            "      \"price\": 79.99,\n",
            "      \"inventory_count\": 1483\n",
            "    }\n",
            "  }\n",
            "} ---\n",
            "[CM_Context Updated] Last Action: tool_list_all_products_Anthropic\n",
            "--- WorkerLLM Calling Anthropic (Iter 2/5, QType: OPERATIONAL) ---\n",
            "--- Orchestrator: Agent Turn Completed ---\n",
            "\\n--- Worker AI Final Response (Type: OPERATIONAL) ---\n",
            "Let me summarize our current product lineup for you:\n",
            "\n",
            "1. Widget A - A simple and compact widget priced at $19.99. We have 999 units in stock.\n",
            "2. Gadget B - A powerful spinning gadget available for $49.99. Currently 200 units available.\n",
            "3. Perplexinator - A perplexing perfunctator that sells for $79.99. We have 1,483 units in stock.\n",
            "\n",
            "Would you like more detailed information about any specific product?\n",
            "--- End of Worker AI Response ---\n",
            "\n",
            "REQUESTING FEEDBACK ON WORKER AI:\n",
            "Orchestrator: Feedback on Worker AI's response? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on Worker AI's Response ---\n",
            "Orchestrator: No feedback provided for worker response or 'skip' entered.\n",
            "--- Orchestrator: Worker Feedback Processing Completed ---\n",
            "\n",
            "--- Orchestrator: Starting Evaluation Turn ---\n",
            "Orchestrator: Retrieving RAG learnings for AI Evaluator...\n",
            "Orchestrator: RAG for Evaluator:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 2128127b, Target: EvaluatorOnly): For `EvaluatorOnly`: An evaluation is considered high quality when it accurately identifies that the Agent failed to perform an action that was required to fulfill the user's request or complete the task (e.g., not shipping an ordered product when shipping was expected).\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Performing AI evaluation with Gemini (gemini-2.5-pro-preview-05-06) (this may take a moment)...\n",
            "--- Orchestrator: Evaluation Turn Completed ---\n",
            "\n",
            "--- AI Evaluator's Assessment ---\n",
            "**EVALUATION:**\n",
            "\n",
            "**1. Accuracy:**\n",
            "    *   **User-facing textual response:** The textual response is highly accurate. It lists all three products (Widget A, Gadget B, Perplexinator) present in the `products` section of the 'Data Store State *Before* AI Action'. For each product, it correctly states the name, description (summarized), price, and inventory count.\n",
            "    *   **Tool calls and datastore:** The AI correctly called the `list_all_products` tool with no input, which is appropriate for this action. The tool output summary is `{\"status\": \"success\"}`, indicating the tool executed as expected. The 'Data Store State *After* AI Action' shows no changes compared to the 'Data Store State *Before* AI Action', which is correct as listing products is a read-only operation. The textual response accurately reflects the data that would be retrieved by `list_all_products` from the datastore.\n",
            "\n",
            "**Score: 10/10**\n",
            "\n",
            "**2. Efficiency:**\n",
            "    *   **Clarifying questions:** The assistant did not ask any clarifying questions, which was appropriate as the user's query was clear.\n",
            "    *   **Tool calls:** A single tool call to `list_all_products` was made, which is the most efficient way to fulfill this request.\n",
            "\n",
            "**Score: 10/10**\n",
            "\n",
            "**3. Context Awareness:**\n",
            "    *   **Conversation history and entities:** No prior conversation history or entities were relevant here.\n",
            "    *   **Task adherence:** The assistant correctly adhered to the OPERATIONAL task of listing products as requested.\n",
            "    *   **RAG Learnings:** The provided RAG learnings were not directly pertinent to the specific task of listing all products. The assistant did not inappropriately try to apply them.\n",
            "    *   **User-facing response and tool output:** The user-facing response makes perfect sense given the tool call (which would return all product details) and the unchanged datastore.\n",
            "\n",
            "**Score: 10/10**\n",
            "\n",
            "**4. Helpfulness & Clarity (of the user-facing response):**\n",
            "    *   **Addressing user needs:** The assistant fully addressed the user's need to see all available products.\n",
            "    *   **Clarity and politeness:** The response is very clear, polite, and easy to understand. It uses a numbered list format which is user-friendly. It avoids jargon and does not dump raw data. The information is presented concisely and includes key details (name, description summary, price, stock).\n",
            "    *   **Relevant information:** All information provided is relevant. The follow-up question, \"Would you like more detailed information about any specific product?\" is helpful and anticipates a potential next step.\n",
            "\n",
            "**Score: 10/10**\n",
            "\n",
            "**Overall Score: 10/10**\n",
            "--- End of AI Evaluator's Assessment ---\n",
            "\n",
            "REQUESTING FEEDBACK ON AI EVALUATOR:\n",
            "Orchestrator: Feedback on Evaluator's assessment? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on AI Evaluator's Assessment ---\n",
            "Orchestrator: No feedback provided for evaluator or 'skip' entered.\n",
            "--- Orchestrator: Evaluator Feedback Processing Completed ---\n",
            "\\n======================================================================\n",
            "AWAITING USER INPUT...\n",
            "Enter query (or 'quit' to exit): I'd like to order 100 Perplexinators, please\n",
            "\n",
            ">>> User Query: 'I'd like to order 100 Perplexinators, please'\n",
            "\n",
            "--- Orchestrator: Starting Agent Turn ---\n",
            "Orchestrator: Classifying query...\n",
            "--- Orchestrator: Classified Query Type: OPERATIONAL ---\n",
            "Orchestrator: Retrieving RAG learnings for Worker Agent...\n",
            "Orchestrator: RAG for Worker:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Worker Agent processing request (this may involve LLM calls and tool use)...\n",
            "--- WorkerLLM Calling Anthropic (Iter 1/5, QType: OPERATIONAL) ---\n",
            "WorkerLLM: Requesting Tool Call: create_order, Input: {'product_id_or_name': 'Perplexinator', 'quantity': 100, 'status': 'Shipped'}\n",
            "[Tool Exec] create_order: Order entry O3 created with status 'Shipped'.\n",
            "[Tool Exec] create_order: Order O3 (Perplexinator) created with status 'Shipped'. Inventory sufficient and deducted. New inventory: 1383.\n",
            "--- [ToolExecutor] Result for create_order: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O3\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O3\",\n",
            "    \"product_id\": \"P3\",\n",
            "    \"product_name\": \"Perplexinator\",\n",
            "    \"quantity\": 100,\n",
            "    \"price\": 79.99,\n",
            "    \"status\": \"Shipped\"\n",
            "  },\n",
            "  \"remaining_inventory\": 1383,\n",
            "  \"inventory_adjusted_by_creation\": true,\n",
            "  \"message\": \"Order O3 (Perplexinator) created with status 'Shipped'. Inventory sufficient and deducted. New inventory: 1383.\"\n",
            "} ---\n",
            "[CM_Context Updated] Entity: orders, ID: O3\n",
            "[CM_Context Updated] Last Action: tool_create_order_Anthropic\n",
            "--- WorkerLLM Calling Anthropic (Iter 2/5, QType: OPERATIONAL) ---\n",
            "--- Orchestrator: Agent Turn Completed ---\n",
            "\\n--- Worker AI Final Response (Type: OPERATIONAL) ---\n",
            "Great news! I've successfully created and shipped your order for 100 Perplexinators (Order ID: O3). The total price comes to $7,999.00. The order has been processed and shipped immediately since we had plenty of inventory available. Your order has been deducted from our stock, leaving 1,383 units in inventory.\n",
            "\n",
            "Is there anything else you'd like to know about your order?\n",
            "--- End of Worker AI Response ---\n",
            "\n",
            "REQUESTING FEEDBACK ON WORKER AI:\n",
            "Orchestrator: Feedback on Worker AI's response? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on Worker AI's Response ---\n",
            "Orchestrator: No feedback provided for worker response or 'skip' entered.\n",
            "--- Orchestrator: Worker Feedback Processing Completed ---\n",
            "\n",
            "--- Orchestrator: Starting Evaluation Turn ---\n",
            "Orchestrator: Retrieving RAG learnings for AI Evaluator...\n",
            "Orchestrator: RAG for Evaluator:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 2128127b, Target: EvaluatorOnly): For `EvaluatorOnly`: An evaluation is considered high quality when it accurately identifies that the Agent failed to perform an action that was required to fulfill the user's request or complete the task (e.g., not shipping an ordered product when shipping was expected).\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Performing AI evaluation with Gemini (gemini-2.5-pro-preview-05-06) (this may take a moment)...\n",
            "--- Orchestrator: Evaluation Turn Completed ---\n",
            "\n",
            "--- AI Evaluator's Assessment ---\n",
            "**1. Accuracy**:\n",
            "    * **User-facing textual response correctness**: The user-facing response is highly accurate. It correctly states:\n",
            "        * Order creation for 100 Perplexinators.\n",
            "        * The new Order ID is O3.\n",
            "        * The total price is $7,999.00 (100 units * $79.99/unit).\n",
            "        * The order was shipped immediately due to sufficient inventory.\n",
            "        * The remaining inventory is 1,383 units.\n",
            "    * **Reflection of tool calls and datastore changes**: The textual response accurately reflects the outcome of the `create_order` tool call and the changes in the datastore.\n",
            "        * The tool call output `{\"status\": \"success\", \"message\": \"Order O3 (Perplexinator) created with status 'Shipped'. Inventory sufficient and deducted. New inventory: 1383.\", \"order_id\": \"O3\"}` is perfectly summarized.\n",
            "        * The 'Data Store State *After* AI Action' shows order O3 created with `product_id: \"P3\"`, `product_name: \"Perplexinator\"`, `quantity: 100`, `price: 79.99` (unit price), and `status: \"Shipped\"`. It also shows `products.P3.inventory_count` updated from 1483 to 1383. These are all correctly conveyed.\n",
            "    * **Tool call correctness**: The `create_order` tool call was executed correctly.\n",
            "        * Input: `{\"product_id_or_name\": \"Perplexinator\", \"quantity\": 100, \"status\": \"Shipped\"}`. This correctly identifies the product, quantity, and appropriately sets the status to \"Shipped\" based on RAG learnings (sufficient inventory allows immediate shipping).\n",
            "        * The tool successfully created order O3 and updated the inventory as confirmed by its output and the datastore changes.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**2. Efficiency**:\n",
            "    * **Minimal clarifying questions**: The AI did not ask any clarifying questions, and none were necessary as the user's query was clear.\n",
            "    * **Appropriate and efficient tool use**: A single, appropriate tool call (`create_order`) was made. This tool call handled order creation, inventory check (implicitly, as per the tool's successful execution and output message \"Inventory sufficient\"), and inventory deduction, making it efficient. Setting the status to \"Shipped\" directly in the tool call, guided by RAG learnings, was also efficient.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**3. Context Awareness**:\n",
            "    * **Conversation history and entities**: The AI correctly understood the user's intent to order \"Perplexinators\" and the quantity \"100\".\n",
            "    * **Adherence to query type (OPERATIONAL)**: The AI fully adhered to the OPERATIONAL query type by performing the requested action of creating and shipping an order.\n",
            "    * **Use of \"Relevant Learnings from Knowledge Base\"**: The AI effectively used the RAG learnings (ID: dfd9eddc and 0c1bb642) which state that an order should be shipped immediately if inventory is sufficient. This was implemented by setting `status: \"Shipped\"` in the `create_order` tool call and confirmed in the user-facing response (\"shipped immediately since we had plenty of inventory available\").\n",
            "    * **User-facing response coherence with tool outputs and datastore**: The response is entirely coherent with the tool's output and the changes in the datastore.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**4. Helpfulness & Clarity (of the user-facing response)**:\n",
            "    * **Addressing user's needs**: The AI completely addressed the user's need to order 100 Perplexinators by successfully creating and shipping the order.\n",
            "    * **Clarity, politeness, ease of understanding**: The response is very clear, polite (\"Great news!\"), and easy to understand. It avoids jargon and presents information logically.\n",
            "    * **Relevant information**: The response provides all necessary and relevant information: confirmation of the order, the order ID (O3), product name, quantity, total price, shipping status, and the updated inventory count. The closing question \"Is there anything else you'd like to know about your order?\" enhances helpfulness.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**Overall Score**: 10/10\n",
            "--- End of AI Evaluator's Assessment ---\n",
            "\n",
            "REQUESTING FEEDBACK ON AI EVALUATOR:\n",
            "Orchestrator: Feedback on Evaluator's assessment? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on AI Evaluator's Assessment ---\n",
            "Orchestrator: No feedback provided for evaluator or 'skip' entered.\n",
            "--- Orchestrator: Evaluator Feedback Processing Completed ---\n",
            "\\n======================================================================\n",
            "AWAITING USER INPUT...\n",
            "Enter query (or 'quit' to exit): Add a new customer: Bill Leece, bill.leece@mail.com, +1.222.333.4444\n",
            "\n",
            ">>> User Query: 'Add a new customer: Bill Leece, bill.leece@mail.com, +1.222.333.4444'\n",
            "\n",
            "--- Orchestrator: Starting Agent Turn ---\n",
            "Orchestrator: Classifying query...\n",
            "--- Orchestrator: Classified Query Type: OPERATIONAL ---\n",
            "Orchestrator: Retrieving RAG learnings for Worker Agent...\n",
            "Orchestrator: RAG for Worker:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Worker Agent processing request (this may involve LLM calls and tool use)...\n",
            "--- WorkerLLM Calling Anthropic (Iter 1/5, QType: OPERATIONAL) ---\n",
            "WorkerLLM: Requesting Tool Call: create_customer, Input: {'name': 'Bill Leece', 'email': 'bill.leece@mail.com', 'phone': '+1.222.333.4444'}\n",
            "[Tool Exec] create_customer: ID C3, Name: Bill Leece\n",
            "--- [ToolExecutor] Result for create_customer: {\n",
            "  \"status\": \"success\",\n",
            "  \"customer_id\": \"C3\",\n",
            "  \"customer\": {\n",
            "    \"name\": \"Bill Leece\",\n",
            "    \"email\": \"bill.leece@mail.com\",\n",
            "    \"phone\": \"+1.222.333.4444\"\n",
            "  }\n",
            "} ---\n",
            "[CM_Context Updated] Entity: customers, ID: C3\n",
            "[CM_Context Updated] Last Action: tool_create_customer_Anthropic\n",
            "--- WorkerLLM Calling Anthropic (Iter 2/5, QType: OPERATIONAL) ---\n",
            "--- Orchestrator: Agent Turn Completed ---\n",
            "\\n--- Worker AI Final Response (Type: OPERATIONAL) ---\n",
            "I've successfully added Bill Leece to our customer database. His customer ID is C3, and all his contact information has been recorded. Is there anything else you'd like me to do with this customer account?\n",
            "--- End of Worker AI Response ---\n",
            "\n",
            "REQUESTING FEEDBACK ON WORKER AI:\n",
            "Orchestrator: Feedback on Worker AI's response? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on Worker AI's Response ---\n",
            "Orchestrator: No feedback provided for worker response or 'skip' entered.\n",
            "--- Orchestrator: Worker Feedback Processing Completed ---\n",
            "\n",
            "--- Orchestrator: Starting Evaluation Turn ---\n",
            "Orchestrator: Retrieving RAG learnings for AI Evaluator...\n",
            "Orchestrator: RAG for Evaluator:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 2128127b, Target: EvaluatorOnly): For `EvaluatorOnly`: An evaluation is considered high quality when it accurately identifies that the Agent failed to perform an action that was required to fulfill the user's request or complete the task (e.g., not shipping an ordered product when shipping was expected).\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Performing AI evaluation with Gemini (gemini-2.5-pro-preview-05-06) (this may take a moment)...\n",
            "--- Orchestrator: Evaluation Turn Completed ---\n",
            "\n",
            "--- AI Evaluator's Assessment ---\n",
            "**1. Accuracy**:\n",
            "    *   **User-facing textual response**: The response \"I've successfully added Bill Leece to our customer database. His customer ID is C3, and all his contact information has been recorded\" is entirely correct and factual.\n",
            "    *   **Tool calls and datastore changes**:\n",
            "        *   The `create_customer` tool was called with the correct input: `{\"name\": \"Bill Leece\", \"email\": \"bill.leece@mail.com\", \"phone\": \"+1.222.333.4444\"}`.\n",
            "        *   The tool output `{\"status\": \"success\"}` indicates successful execution.\n",
            "        *   Comparing the 'Data Store State *Before* AI Action' and 'Data Store State *After* AI Action', a new customer `C3` with the details \"Bill Leece\", \"bill.leece@mail.com\", and \"+1.222.333.4444\" was added to the `customers` table. This accurately reflects the outcome of the tool call.\n",
            "    *   **Actions**: The AI correctly processed the information and modified the datastore as intended by the OPERATIONAL query.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**2. Efficiency**:\n",
            "    *   The assistant achieved its goal without asking any clarifying questions, which were not needed in this case.\n",
            "    *   The `create_customer` tool was used appropriately and efficiently for this OPERATIONAL task. Only one tool call was necessary.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**3. Context Awareness**:\n",
            "    *   The assistant correctly used the information provided in the current user query. There was no relevant conversation history or entities to draw from for this specific task.\n",
            "    *   The assistant adhered to the task defined by the OPERATIONAL query type (adding a customer).\n",
            "    *   The \"Relevant Learnings from Knowledge Base\" were not directly pertinent to this specific query of adding a customer, so it was correct not to use them.\n",
            "    *   The user-facing response makes perfect sense given the tool output (success) and datastore changes (new customer C3 added).\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**4. Helpfulness & Clarity (of the user-facing response)**:\n",
            "    *   The assistant fully addressed the user's need to add a new customer, as per the OPERATIONAL query.\n",
            "    *   The response \"I've successfully added Bill Leece to our customer database. His customer ID is C3, and all his contact information has been recorded. Is there anything else you'd like me to do with this customer account?\" is clear, polite, and easy to understand. It confirms the action, provides the new customer ID, and offers further assistance. It avoids jargon.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "Overall Score: 10/10\n",
            "--- End of AI Evaluator's Assessment ---\n",
            "\n",
            "REQUESTING FEEDBACK ON AI EVALUATOR:\n",
            "Orchestrator: Feedback on Evaluator's assessment? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on AI Evaluator's Assessment ---\n",
            "Orchestrator: No feedback provided for evaluator or 'skip' entered.\n",
            "--- Orchestrator: Evaluator Feedback Processing Completed ---\n",
            "\\n======================================================================\n",
            "AWAITING USER INPUT...\n",
            "Enter query (or 'quit' to exit): Change bill.leece@mail.com's phone number to +1.999.888.7777\n",
            "\n",
            ">>> User Query: 'Change bill.leece@mail.com's phone number to +1.999.888.7777'\n",
            "\n",
            "--- Orchestrator: Starting Agent Turn ---\n",
            "Orchestrator: Classifying query...\n",
            "--- Orchestrator: Classified Query Type: OPERATIONAL ---\n",
            "Orchestrator: Retrieving RAG learnings for Worker Agent...\n",
            "Orchestrator: RAG for Worker:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Worker Agent processing request (this may involve LLM calls and tool use)...\n",
            "--- WorkerLLM Calling Anthropic (Iter 1/5, QType: OPERATIONAL) ---\n",
            "WorkerLLM: Requesting Tool Call: update_customer, Input: {'customer_id': 'C3', 'phone': '+1.999.888.7777'}\n",
            "[Tool Exec] update_customer: ID C3, Updated fields: phone.\n",
            "   New data: {'name': 'Bill Leece', 'email': 'bill.leece@mail.com', 'phone': '+1.999.888.7777'}\n",
            "--- [ToolExecutor] Result for update_customer: {\n",
            "  \"status\": \"success\",\n",
            "  \"customer_id\": \"C3\",\n",
            "  \"customer\": {\n",
            "    \"name\": \"Bill Leece\",\n",
            "    \"email\": \"bill.leece@mail.com\",\n",
            "    \"phone\": \"+1.999.888.7777\"\n",
            "  },\n",
            "  \"updated_fields\": [\n",
            "    \"phone\"\n",
            "  ]\n",
            "} ---\n",
            "[CM_Context Updated] Entity: customers, ID: C3\n",
            "[CM_Context Updated] Last Action: tool_update_customer_Anthropic\n",
            "--- WorkerLLM Calling Anthropic (Iter 2/5, QType: OPERATIONAL) ---\n",
            "--- Orchestrator: Agent Turn Completed ---\n",
            "\\n--- Worker AI Final Response (Type: OPERATIONAL) ---\n",
            "I've successfully updated Bill Leece's phone number to +1.999.888.7777. All other contact information remains unchanged. Is there anything else you'd like me to help you with?\n",
            "--- End of Worker AI Response ---\n",
            "\n",
            "REQUESTING FEEDBACK ON WORKER AI:\n",
            "Orchestrator: Feedback on Worker AI's response? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on Worker AI's Response ---\n",
            "Orchestrator: No feedback provided for worker response or 'skip' entered.\n",
            "--- Orchestrator: Worker Feedback Processing Completed ---\n",
            "\n",
            "--- Orchestrator: Starting Evaluation Turn ---\n",
            "Orchestrator: Retrieving RAG learnings for AI Evaluator...\n",
            "Orchestrator: RAG for Evaluator:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 2128127b, Target: EvaluatorOnly): For `EvaluatorOnly`: An evaluation is considered high quality when it accurately identifies that the Agent failed to perform an action that was required to fulfill the user's request or complete the task (e.g., not shipping an ordered product when shipping was expected).\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Performing AI evaluation with Gemini (gemini-2.5-pro-preview-05-06) (this may take a moment)...\n",
            "--- Orchestrator: Evaluation Turn Completed ---\n",
            "\n",
            "--- AI Evaluator's Assessment ---\n",
            "**1. Accuracy**\n",
            "    *   **User-facing textual response**: The response \"I've successfully updated Bill Leece's phone number to +1.999.888.7777. All other contact information remains unchanged.\" is correct and factual.\n",
            "    *   **Reflection of tool calls and datastore**: The textual response accurately reflects the successful outcome of the `update_customer` tool call and the change in the datastore.\n",
            "        *   **Tool Call Log**: The `update_customer` tool was called with `{\"customer_id\": \"C3\", \"phone\": \"+1.999.888.7777\"}`. The output was `{\"status\": \"success\"}`.\n",
            "        *   **Datastore State**:\n",
            "            *   *Before*: `customers.C3.phone` was `\"+1.222.333.4444\"`.\n",
            "            *   *After*: `customers.C3.phone` is `\"+1.999.888.7777\"`.\n",
            "        The tool call correctly identified customer C3 (Bill Leece, associated with `bill.leece@mail.com`) and updated the phone number as requested. The datastore reflects this change accurately.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "**2. Efficiency**\n",
            "    *   **Clarifying questions**: No clarifying questions were asked, and none were necessary as the user's query was specific and actionable.\n",
            "    *   **Tool calls**: A single `update_customer` tool call was made, which was appropriate and efficient for the task of updating a customer's phone number.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "**3. Context Awareness**\n",
            "    *   **Conversation history and entities**: The AI correctly identified the customer \"C3\" (Bill Leece) based on the email address \"bill.leece@mail.com\" provided in the user query, which matches the 'Data Store State *Before* AI Action'.\n",
            "    *   **Task adherence (Query Type)**: The AI strictly adhered to the OPERATIONAL task of updating customer information.\n",
            "    *   **Relevant Learnings**: The provided \"Relevant Learnings from Knowledge Base\" pertained to order creation and shipping. These were not relevant to the current task of updating a phone number, and the AI correctly did not attempt to apply them.\n",
            "    *   **Response coherence**: The user-facing response directly and accurately conveyed the outcome of the tool call and the datastore modification.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "**4. Helpfulness & Clarity (of the user-facing response)**\n",
            "    *   **Addressing user's needs**: The AI fully addressed the user's request to change the phone number for the specified email address.\n",
            "    *   **Clarity and politeness**: The response \"I've successfully updated Bill Leece's phone number to +1.999.888.7777. All other contact information remains unchanged. Is there anything else you'd like me to help you with?\" is clear, concise, polite, and easy to understand. It avoids jargon and directly confirms the action taken. The addition \"All other contact information remains unchanged\" provides useful reassurance.\n",
            "    *   **Relevance**: The information provided was directly relevant to the user's query.\n",
            "    *   **Score**: 10/10\n",
            "\n",
            "**Overall Score**: 10/10\n",
            "--- End of AI Evaluator's Assessment ---\n",
            "\n",
            "REQUESTING FEEDBACK ON AI EVALUATOR:\n",
            "Orchestrator: Feedback on Evaluator's assessment? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on AI Evaluator's Assessment ---\n",
            "Orchestrator: No feedback provided for evaluator or 'skip' entered.\n",
            "--- Orchestrator: Evaluator Feedback Processing Completed ---\n",
            "\\n======================================================================\n",
            "AWAITING USER INPUT...\n",
            "Enter query (or 'quit' to exit): Add new new product: Gizmo X, description: A fancy gizmo, price: 29.99, inventory: 50\n",
            "\n",
            ">>> User Query: 'Add new new product: Gizmo X, description: A fancy gizmo, price: 29.99, inventory: 50'\n",
            "\n",
            "--- Orchestrator: Starting Agent Turn ---\n",
            "Orchestrator: Classifying query...\n",
            "--- Orchestrator: Classified Query Type: OPERATIONAL ---\n",
            "Orchestrator: Retrieving RAG learnings for Worker Agent...\n",
            "Orchestrator: RAG for Worker:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Worker Agent processing request (this may involve LLM calls and tool use)...\n",
            "--- WorkerLLM Calling Anthropic (Iter 1/5, QType: OPERATIONAL) ---\n",
            "WorkerLLM: Requesting Tool Call: create_product, Input: {'name': 'Gizmo X', 'description': 'A fancy gizmo', 'price': 29.99, 'inventory_count': 50}\n",
            "[Tool Exec] create_product: ID P4, Name: Gizmo X\n",
            "--- [ToolExecutor] Result for create_product: {\n",
            "  \"status\": \"success\",\n",
            "  \"product_id\": \"P4\",\n",
            "  \"product\": {\n",
            "    \"name\": \"Gizmo X\",\n",
            "    \"description\": \"A fancy gizmo\",\n",
            "    \"price\": 29.99,\n",
            "    \"inventory_count\": 50\n",
            "  }\n",
            "} ---\n",
            "[CM_Context Updated] Entity: products, ID: P4\n",
            "[CM_Context Updated] Last Action: tool_create_product_Anthropic\n",
            "--- WorkerLLM Calling Anthropic (Iter 2/5, QType: OPERATIONAL) ---\n",
            "--- Orchestrator: Agent Turn Completed ---\n",
            "\\n--- Worker AI Final Response (Type: OPERATIONAL) ---\n",
            "I've successfully added Gizmo X to our product catalog. The product has been assigned ID P4, and all the details have been recorded: price set at $29.99 with 50 units in initial inventory. Would you like to see the full product listing or any specific details about the Gizmo X?\n",
            "--- End of Worker AI Response ---\n",
            "\n",
            "REQUESTING FEEDBACK ON WORKER AI:\n",
            "Orchestrator: Feedback on Worker AI's response? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on Worker AI's Response ---\n",
            "Orchestrator: No feedback provided for worker response or 'skip' entered.\n",
            "--- Orchestrator: Worker Feedback Processing Completed ---\n",
            "\n",
            "--- Orchestrator: Starting Evaluation Turn ---\n",
            "Orchestrator: Retrieving RAG learnings for AI Evaluator...\n",
            "Orchestrator: RAG for Evaluator:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 2128127b, Target: EvaluatorOnly): For `EvaluatorOnly`: An evaluation is considered high quality when it accurately identifies that the Agent failed to perform an action that was required to fulfill the user's request or complete the task (e.g., not shipping an ordered product when shipping was expected).\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Performing AI evaluation with Gemini (gemini-2.5-pro-preview-05-06) (this may take a moment)...\n",
            "--- Orchestrator: Evaluation Turn Completed ---\n",
            "\n",
            "--- AI Evaluator's Assessment ---\n",
            "**1. Accuracy**\n",
            "    *   **User-facing textual response correctness**: The textual response is entirely correct and factual.\n",
            "    *   **Reflection of tool calls and datastore changes**: The response accurately reflects the outcome of the `create_product` tool call (product ID P4) and the changes in the datastore (new product \"Gizmo X\" with description \"A fancy gizmo\", price $29.99, and inventory 50).\n",
            "    *   **Tool call processing**: The `create_product` tool call was executed with the correct parameters derived from the user's query: `{\"name\": \"Gizmo X\", \"description\": \"A fancy gizmo\", \"price\": 29.99, \"inventory_count\": 50}`. The tool successfully created the product and returned `{\"status\": \"success\", \"product_id\": \"P4\"}`.\n",
            "    *   **Datastore modification**: The 'Data Store State *After* AI Action' shows that a new product \"P4\" was correctly added to the `products` table with all the specified attributes: `{\"name\": \"Gizmo X\", \"description\": \"A fancy gizmo\", \"price\": 29.99, \"inventory_count\": 50}`. This matches the user's request and the tool's output.\n",
            "Score: 10/10\n",
            "\n",
            "**2. Efficiency**\n",
            "    *   **Clarifying questions**: The assistant did not ask any clarifying questions, which was appropriate as the user's query was clear and contained all necessary information.\n",
            "    *   **Tool call efficiency**: A single, appropriate tool call (`create_product`) was made to achieve the user's goal. No unnecessary tools were called.\n",
            "Score: 10/10\n",
            "\n",
            "**3. Context Awareness**\n",
            "    *   **Conversation history and entities**: The assistant correctly understood the user's intent to add a new product.\n",
            "    *   **Adherence to query type**: The assistant correctly performed the OPERATIONAL task of creating a new product as requested.\n",
            "    *   **Relevant Learnings from Knowledge Base**: The provided RAG learnings were related to order processing and shipping, not product creation. The assistant correctly did not apply these irrelevant learnings to the current task.\n",
            "    *   **Response coherence with tool outputs and datastore**: The user-facing response is fully consistent with the successful tool call and the updated datastore.\n",
            "Score: 10/10\n",
            "\n",
            "**4. Helpfulness & Clarity (of the user-facing response)**\n",
            "    *   **Addressing user's needs**: The assistant fully addressed the user's request by adding the new product. The query type was OPERATIONAL, and the operation was successfully executed.\n",
            "    *   **Clarity and politeness**: The response \"I've successfully added Gizmo X to our product catalog. The product has been assigned ID P4, and all the details have been recorded: price set at $29.99 with 50 units in initial inventory. Would you like to see the full product listing or any specific details about the Gizmo X?\" is clear, polite, and easy to understand.\n",
            "    *   **Avoiding jargon/raw data**: The response presents the information (product ID, price, inventory) in a user-friendly way without dumping raw data.\n",
            "    *   **Providing relevant information**: It confirmed the action, provided key details (product ID, price, inventory), and offered a helpful follow-up question.\n",
            "Score: 10/10\n",
            "\n",
            "**Overall Score: 10/10**\n",
            "--- End of AI Evaluator's Assessment ---\n",
            "\n",
            "REQUESTING FEEDBACK ON AI EVALUATOR:\n",
            "Orchestrator: Feedback on Evaluator's assessment? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on AI Evaluator's Assessment ---\n",
            "Orchestrator: No feedback provided for evaluator or 'skip' entered.\n",
            "--- Orchestrator: Evaluator Feedback Processing Completed ---\n",
            "\\n======================================================================\n",
            "AWAITING USER INPUT...\n",
            "Enter query (or 'quit' to exit): Update Gizzmo's price to 99.99\n",
            "\n",
            ">>> User Query: 'Update Gizzmo's price to 99.99'\n",
            "\n",
            "--- Orchestrator: Starting Agent Turn ---\n",
            "Orchestrator: Classifying query...\n",
            "--- Orchestrator: Classified Query Type: OPERATIONAL ---\n",
            "Orchestrator: Retrieving RAG learnings for Worker Agent...\n",
            "Orchestrator: RAG for Worker:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Worker Agent processing request (this may involve LLM calls and tool use)...\n",
            "--- WorkerLLM Calling Anthropic (Iter 1/5, QType: OPERATIONAL) ---\n",
            "WorkerLLM: Requesting Tool Call: update_product, Input: {'product_id': 'P4', 'price': 99.99}\n",
            "[Tool Exec] update_product: ID P4, Updated fields: price.\n",
            "   New data: {'name': 'Gizmo X', 'description': 'A fancy gizmo', 'price': 99.99, 'inventory_count': 50}\n",
            "--- [ToolExecutor] Result for update_product: {\n",
            "  \"status\": \"success\",\n",
            "  \"product_id\": \"P4\",\n",
            "  \"product\": {\n",
            "    \"name\": \"Gizmo X\",\n",
            "    \"description\": \"A fancy gizmo\",\n",
            "    \"price\": 99.99,\n",
            "    \"inventory_count\": 50\n",
            "  },\n",
            "  \"updated_fields\": [\n",
            "    \"price\"\n",
            "  ]\n",
            "} ---\n",
            "[CM_Context Updated] Entity: products, ID: P4\n",
            "[CM_Context Updated] Last Action: tool_update_product_Anthropic\n",
            "--- WorkerLLM Calling Anthropic (Iter 2/5, QType: OPERATIONAL) ---\n",
            "--- Orchestrator: Agent Turn Completed ---\n",
            "\\n--- Worker AI Final Response (Type: OPERATIONAL) ---\n",
            "I've successfully updated the price of Gizmo X from $29.99 to $99.99. The inventory count remains at 50 units, and all other product details stay the same. Is there anything else you'd like me to help you with?\n",
            "--- End of Worker AI Response ---\n",
            "\n",
            "REQUESTING FEEDBACK ON WORKER AI:\n",
            "Orchestrator: Feedback on Worker AI's response? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on Worker AI's Response ---\n",
            "Orchestrator: No feedback provided for worker response or 'skip' entered.\n",
            "--- Orchestrator: Worker Feedback Processing Completed ---\n",
            "\n",
            "--- Orchestrator: Starting Evaluation Turn ---\n",
            "Orchestrator: Retrieving RAG learnings for AI Evaluator...\n",
            "Orchestrator: RAG for Evaluator:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 2128127b, Target: EvaluatorOnly): For `EvaluatorOnly`: An evaluation is considered high quality when it accurately identifies that the Agent failed to perform an action that was required to fulfill the user's request or complete the task (e.g., not shipping an ordered product when shipping was expected).\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Performing AI evaluation with Gemini (gemini-2.5-pro-preview-05-06) (this may take a moment)...\n",
            "--- Orchestrator: Evaluation Turn Completed ---\n",
            "\n",
            "--- AI Evaluator's Assessment ---\n",
            "**1. Accuracy**:\n",
            "    *   **User-facing textual response correctness**: The response \"I've successfully updated the price of Gizmo X from $29.99 to $99.99. The inventory count remains at 50 units, and all other product details stay the same\" is factually correct.\n",
            "    *   **Reflection of tool calls and datastore changes**:\n",
            "        *   The tool call `update_product` with `{\"product_id\": \"P4\", \"price\": 99.99}` was executed.\n",
            "        *   The `Data Store State *Before* AI Action` shows product P4 (\"Gizmo X\") had a price of `29.99`.\n",
            "        *   The `Data Store State *After* AI Action` shows product P4 (\"Gizmo X\") has a price of `99.99`.\n",
            "        *   The textual response accurately reflects this change, stating the old price ($29.99) and the new price ($99.99). It also correctly states the inventory count (50 units) remained unchanged.\n",
            "    *   **Action correctness**: The `update_product` tool call correctly targeted product P4 (Gizmo X) and updated its price to 99.99 as requested by the user. The datastore change confirms this.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**2. Efficiency**:\n",
            "    *   **Clarifying questions**: No clarifying questions were asked, and none were needed as the request was clear enough (even with \"Gizzmo\" which was likely mapped to \"Gizmo X\" from context or fuzzy matching).\n",
            "    *   **Tool call appropriateness**: A single `update_product` tool call was made, which was the correct and most efficient way to achieve the user's goal.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**3. Context Awareness**:\n",
            "    *   **Conversation history and entities**: The AI correctly identified \"Gizzmo\" as \"Gizmo X\" (product P4), which was listed in \"Recent products: ['P4']\" and present in the datastore.\n",
            "    *   **Task adherence**: The AI adhered to the OPERATIONAL task of updating product information.\n",
            "    *   **RAG Learnings**: The provided RAG learnings were related to order processing and shipping, not product updates. The AI correctly did not attempt to apply these irrelevant learnings.\n",
            "    *   **Response vs. tool output/datastore**: The user-facing response is fully consistent with the successful tool output (`{\"status\": \"success\", \"product_id\": \"P4\"}`) and the changes observed in the datastore (P4 price updated from 29.99 to 99.99).\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**4. Helpfulness & Clarity (of the user-facing response)**:\n",
            "    *   **Addressing user's needs**: The AI fully addressed the user's need to update the product price.\n",
            "    *   **Clarity and politeness**: The response is clear, polite, and easy to understand. It explicitly states the product name, the old price, and the new price.\n",
            "    *   **Relevant information**: Confirming that \"The inventory count remains at 50 units, and all other product details stay the same\" is helpful, as it preempts potential follow-up questions about other product attributes. The closing \"Is there anything else you'd like me to help you with?\" is also appropriate.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**Overall Score**: 10/10\n",
            "--- End of AI Evaluator's Assessment ---\n",
            "\n",
            "REQUESTING FEEDBACK ON AI EVALUATOR:\n",
            "Orchestrator: Feedback on Evaluator's assessment? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on AI Evaluator's Assessment ---\n",
            "Orchestrator: No feedback provided for evaluator or 'skip' entered.\n",
            "--- Orchestrator: Evaluator Feedback Processing Completed ---\n",
            "\\n======================================================================\n",
            "AWAITING USER INPUT...\n",
            "Enter query (or 'quit' to exit): who won the Super Bowl last year?\n",
            "\n",
            ">>> User Query: 'who won the Super Bowl last year?'\n",
            "\n",
            "--- Orchestrator: Starting Agent Turn ---\n",
            "Orchestrator: Classifying query...\n",
            "--- Orchestrator: Classified Query Type: OPERATIONAL ---\n",
            "Orchestrator: Retrieving RAG learnings for Worker Agent...\n",
            "Orchestrator: RAG for Worker:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Worker Agent processing request (this may involve LLM calls and tool use)...\n",
            "--- WorkerLLM Calling Anthropic (Iter 1/5, QType: OPERATIONAL) ---\n",
            "--- Orchestrator: Agent Turn Completed ---\n",
            "\\n--- Worker AI Final Response (Type: OPERATIONAL) ---\n",
            "I apologize, but I am configured as an e-commerce customer service assistant and don't have access to sports information or general knowledge questions. I can help you with:\n",
            "\n",
            "- Creating and managing orders\n",
            "- Looking up product information and inventory\n",
            "- Managing customer information\n",
            "- Checking order status\n",
            "- Creating and updating products\n",
            "\n",
            "Is there something related to our products or services that I can help you with?\n",
            "--- End of Worker AI Response ---\n",
            "\n",
            "REQUESTING FEEDBACK ON WORKER AI:\n",
            "Orchestrator: Feedback on Worker AI's response? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on Worker AI's Response ---\n",
            "Orchestrator: No feedback provided for worker response or 'skip' entered.\n",
            "--- Orchestrator: Worker Feedback Processing Completed ---\n",
            "\n",
            "--- Orchestrator: Starting Evaluation Turn ---\n",
            "Orchestrator: Retrieving RAG learnings for AI Evaluator...\n",
            "Orchestrator: RAG for Evaluator:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 2128127b, Target: EvaluatorOnly): For `EvaluatorOnly`: An evaluation is considered high quality when it accurately identifies that the Agent failed to perform an action that was required to fulfill the user's request or complete the task (e.g., not shipping an ordered product when shipping was expected).\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Performing AI evaluation with Gemini (gemini-2.5-pro-preview-05-06) (this may take a moment)...\n",
            "--- Orchestrator: Evaluation Turn Completed ---\n",
            "\n",
            "--- AI Evaluator's Assessment ---\n",
            "EVALUATION:\n",
            "\n",
            "1.  **Accuracy**:\n",
            "    *   The query type is OPERATIONAL. The user's query, \"who won the Super Bowl last year?\", is a general knowledge question, falling outside the typical scope of an e-commerce assistant.\n",
            "    *   The AI's **user-facing textual response** is: \"I apologize, but I am configured as an e-commerce customer service assistant and don't have access to sports information or general knowledge questions. I can help you with: - Creating and managing orders - Looking up product information and inventory - Managing customer information - Checking order status - Creating and updating products. Is there something related to our products or services that I can help you with?\" This response accurately reflects the AI's inability to answer the specific question due to its designed purpose.\n",
            "    *   No **tool calls** were made, and the **datastore** remained unchanged ('Data Store State *Before* AI Action' and 'Data Store State *After* AI Action' are identical). This is the correct course of action, as there are no tools or data relevant to answering a sports trivia question within this e-commerce context.\n",
            "    *   The AI correctly processed the information by identifying the query as out-of-scope and did not attempt any inappropriate actions.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "2.  **Efficiency**:\n",
            "    *   The assistant did not ask any clarifying questions, which was appropriate as the query, though out-of-scope, was clear.\n",
            "    *   No tool calls were made, which is efficient as no tools were relevant to the query.\n",
            "    *   The response was direct in stating its limitations and offering relevant assistance.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "3.  **Context Awareness**:\n",
            "    *   The assistant correctly identified that the query was unrelated to its e-commerce functions.\n",
            "    *   It clearly articulated its role as an \"e-commerce customer service assistant.\"\n",
            "    *   The \"Relevant Learnings from Knowledge Base\" (related to order processing) were correctly ignored as they were not pertinent to this general knowledge question.\n",
            "    *   The user-facing response is perfectly aligned with the situation: an out-of-scope query.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "4.  **Helpfulness & Clarity (of the user-facing response)**:\n",
            "    *   For the identified query type (OPERATIONAL), the AI \"operated\" by correctly assessing the query's nature and responding appropriately. While it couldn't fulfill the user's explicit request, it was helpful by:\n",
            "        *   Clearly and politely explaining *why* it couldn't answer (\"I am configured as an e-commerce customer service assistant and don't have access to sports information or general knowledge questions\").\n",
            "        *   Proactively listing its actual capabilities, guiding the user towards interactions it *can* handle.\n",
            "        *   Ending with an open-ended question to encourage relevant follow-up (\"Is there something related to our products or services that I can help you with?\").\n",
            "    *   The response is very clear, easy to understand, and avoids jargon.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "Overall Score: 10/10\n",
            "--- End of AI Evaluator's Assessment ---\n",
            "\n",
            "REQUESTING FEEDBACK ON AI EVALUATOR:\n",
            "Orchestrator: Feedback on Evaluator's assessment? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on AI Evaluator's Assessment ---\n",
            "Orchestrator: No feedback provided for evaluator or 'skip' entered.\n",
            "--- Orchestrator: Evaluator Feedback Processing Completed ---\n",
            "\\n======================================================================\n",
            "AWAITING USER INPUT...\n",
            "Enter query (or 'quit' to exit): I'd like to order 17 Widget As and 14 Gadget Bs please\n",
            "\n",
            ">>> User Query: 'I'd like to order 17 Widget As and 14 Gadget Bs please'\n",
            "\n",
            "--- Orchestrator: Starting Agent Turn ---\n",
            "Orchestrator: Classifying query...\n",
            "--- Orchestrator: Classified Query Type: OPERATIONAL ---\n",
            "Orchestrator: Retrieving RAG learnings for Worker Agent...\n",
            "Orchestrator: RAG for Worker:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Worker Agent processing request (this may involve LLM calls and tool use)...\n",
            "--- WorkerLLM Calling Anthropic (Iter 1/5, QType: OPERATIONAL) ---\n",
            "WorkerLLM: Requesting Tool Call: create_order, Input: {'product_id_or_name': 'Widget A', 'quantity': 17, 'status': 'Shipped'}\n",
            "[Tool Exec] create_order: Order entry O4 created with status 'Shipped'.\n",
            "[Tool Exec] create_order: Order O4 (Widget A) created with status 'Shipped'. Inventory sufficient and deducted. New inventory: 982.\n",
            "--- [ToolExecutor] Result for create_order: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O4\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O4\",\n",
            "    \"product_id\": \"P1\",\n",
            "    \"product_name\": \"Widget A\",\n",
            "    \"quantity\": 17,\n",
            "    \"price\": 19.99,\n",
            "    \"status\": \"Shipped\"\n",
            "  },\n",
            "  \"remaining_inventory\": 982,\n",
            "  \"inventory_adjusted_by_creation\": true,\n",
            "  \"message\": \"Order O4 (Widget A) created with status 'Shipped'. Inventory sufficient and deducted. New inventory: 982.\"\n",
            "} ---\n",
            "[CM_Context Updated] Entity: orders, ID: O4\n",
            "[CM_Context Updated] Last Action: tool_create_order_Anthropic\n",
            "--- WorkerLLM Calling Anthropic (Iter 2/5, QType: OPERATIONAL) ---\n",
            "WorkerLLM: Requesting Tool Call: create_order, Input: {'product_id_or_name': 'Gadget B', 'quantity': 14, 'status': 'Shipped'}\n",
            "[Tool Exec] create_order: Order entry O5 created with status 'Shipped'.\n",
            "[Tool Exec] create_order: Order O5 (Gadget B) created with status 'Shipped'. Inventory sufficient and deducted. New inventory: 186.\n",
            "--- [ToolExecutor] Result for create_order: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O5\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O5\",\n",
            "    \"product_id\": \"P2\",\n",
            "    \"product_name\": \"Gadget B\",\n",
            "    \"quantity\": 14,\n",
            "    \"price\": 49.99,\n",
            "    \"status\": \"Shipped\"\n",
            "  },\n",
            "  \"remaining_inventory\": 186,\n",
            "  \"inventory_adjusted_by_creation\": true,\n",
            "  \"message\": \"Order O5 (Gadget B) created with status 'Shipped'. Inventory sufficient and deducted. New inventory: 186.\"\n",
            "} ---\n",
            "[CM_Context Updated] Entity: orders, ID: O5\n",
            "[CM_Context Updated] Last Action: tool_create_order_Anthropic\n",
            "--- WorkerLLM Calling Anthropic (Iter 3/5, QType: OPERATIONAL) ---\n",
            "--- Orchestrator: Agent Turn Completed ---\n",
            "\\n--- Worker AI Final Response (Type: OPERATIONAL) ---\n",
            "I've successfully placed both orders and they've been shipped immediately since we had sufficient inventory:\n",
            "\n",
            "1. Order O4: 17 Widget As at $19.99 each (total: $339.83)\n",
            "2. Order O5: 14 Gadget Bs at $49.99 each (total: $699.86)\n",
            "\n",
            "Both orders have been processed and shipped. The inventory has been automatically adjusted. Is there anything else you'd like to know about your orders?\n",
            "--- End of Worker AI Response ---\n",
            "\n",
            "REQUESTING FEEDBACK ON WORKER AI:\n",
            "Orchestrator: Feedback on Worker AI's response? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on Worker AI's Response ---\n",
            "Orchestrator: No feedback provided for worker response or 'skip' entered.\n",
            "--- Orchestrator: Worker Feedback Processing Completed ---\n",
            "\n",
            "--- Orchestrator: Starting Evaluation Turn ---\n",
            "Orchestrator: Retrieving RAG learnings for AI Evaluator...\n",
            "Orchestrator: RAG for Evaluator:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: 2128127b, Target: EvaluatorOnly): For `EvaluatorOnly`: An evaluation is considered high quality when it accurately identifies that the Agent failed to perform an action that was required to fulfill the user's request or complete the task (e.g., not shipping an ordered product when shipping was expected).\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Performing AI evaluation with Gemini (gemini-2.5-pro-preview-05-06) (this may take a moment)...\n",
            "--- Orchestrator: Evaluation Turn Completed ---\n",
            "\n",
            "--- AI Evaluator's Assessment ---\n",
            "**1. Accuracy**\n",
            "    *   **OPERATIONAL Assessment**:\n",
            "        *   **User-facing textual response correctness**: The textual response accurately states: \"I've successfully placed both orders and they've been shipped immediately since we had sufficient inventory: 1. Order O4: 17 Widget As at $19.99 each (total: $339.83) 2. Order O5: 14 Gadget Bs at $49.99 each (total: $699.86). Both orders have been processed and shipped. The inventory has been automatically adjusted.\"\n",
            "        *   **Reflection of tool calls and datastore**:\n",
            "            *   Tool Call 1 (`create_order` for \"Widget A\", quantity 17, status \"Shipped\") resulted in \"Order O4 (Widget A) created with status 'Shipped'. Inventory sufficient and deducted. New inventory: 982.\" This perfectly matches the O4 part of the textual response. The price for Widget A is $19.99, so 17 * $19.99 = $339.83, which is correctly stated.\n",
            "            *   Tool Call 2 (`create_order` for \"Gadget B\", quantity 14, status \"Shipped\") resulted in \"Order O5 (Gadget B) created with status 'Shipped'. Inventory sufficient and deducted. New inventory: 186.\" This perfectly matches the O5 part of the textual response. The price for Gadget B is $49.99, so 14 * $49.99 = $699.86, which is correctly stated.\n",
            "            *   The 'Data Store State *After* AI Action' shows new orders O4 and O5 created with the correct product details, quantities, prices, and \"Shipped\" status.\n",
            "            *   Product P1 (Widget A) inventory changed from 999 to 982 (999 - 17 = 982), which is correct.\n",
            "            *   Product P2 (Gadget B) inventory changed from 200 to 186 (200 - 14 = 186), which is correct.\n",
            "        *   **Tool call actions**: The tool calls correctly processed the information. `create_order` was called twice, once for each product, with the correct product names, quantities, and the status \"Shipped\" (as per RAG learnings). The datastore was modified as intended, reflecting the new orders and updated inventory counts. New entity IDs O4 and O5 were created correctly.\n",
            "\n",
            "    *   Score: 10/10\n",
            "\n",
            "**2. Efficiency**\n",
            "    *   The assistant achieved its goal without asking any clarifying questions. The user's query was direct and unambiguous.\n",
            "    *   **OPERATIONAL Assessment**: The tool calls were appropriate and efficient. Two `create_order` calls were necessary to place orders for two distinct products. The \"Shipped\" status was correctly included in the tool call, aligning with the RAG learnings about immediate shipping if inventory is sufficient.\n",
            "    *   Score: 10/10\n",
            "\n",
            "**3. Context Awareness**\n",
            "    *   The assistant did not need to use conversation history or previous entities for this specific request, but it correctly identified the products from the user's query and used their current data (price, inventory) from the datastore.\n",
            "    *   The assistant adhered to the task defined by the OPERATIONAL query type by creating the orders.\n",
            "    *   The assistant correctly used the \"Relevant Learnings from Knowledge Base\":\n",
            "        *   Learning ID `dfd9eddc` and `0c1bb642` both state that if an order is successfully created and sufficient inventory is confirmed, the order should be shipped immediately. The AI correctly applied this by setting the status to \"Shipped\" in both `create_order` tool calls, as inventory was sufficient (Widget A: 999 > 17; Gadget B: 200 > 14).\n",
            "    *   The user-facing response makes perfect sense given the successful tool outputs and the updated datastore.\n",
            "    *   Score: 10/10\n",
            "\n",
            "**4. Helpfulness & Clarity (of the user-facing response)**\n",
            "    *   The assistant fully addressed the user's need by creating the orders for the specified items and quantities.\n",
            "    *   The user-facing response is very clear, polite, and easy to understand. It explicitly states what was done (orders placed, items shipped), provides the new order IDs (O4, O5), details of each order including item name, quantity, price per item, and total for each item. It also confirms inventory adjustment.\n",
            "    *   It avoids jargon and provides a concise summary of the actions taken and their results.\n",
            "    *   The closing question \"Is there anything else you'd like to know about your orders?\" is helpful and proactive.\n",
            "    *   Score: 10/10\n",
            "\n",
            "**Overall Score: 10/10**\n",
            "--- End of AI Evaluator's Assessment ---\n",
            "\n",
            "REQUESTING FEEDBACK ON AI EVALUATOR:\n",
            "Orchestrator: Feedback on Evaluator's assessment? (type or 'skip'): I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount and write a short summary paragraph that I can send to the insurance company.\n",
            "--- Orchestrator: Processing Feedback on AI Evaluator's Assessment ---\n",
            "--- KM: Processing New Learning Candidate (Target: EvaluatorOnly): \"I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount and write a short summary paragraph that I can send to the insurance company.\" ---\n",
            "KM: Learning Synthesis Attempt 1/3...\n",
            "KM: Synthesizing learning with LLM (gemini-2.5-pro-preview-05-06) (this may take a moment)...\n",
            "KM: Gemini Learning Synthesis Raw Response:\\nFINALIZED_LEARNING: For `EvaluatorOnly`: Evaluations of domain-specific tasks (e.g., inventory management) should assess the system's ability to handle not only explicit requests (e.g., processing an order) but also related complex, high-value needs within that domain. For inventory, this includes tasks like calculating total inventory value and generating summaries for business purposes (e.g., insurance updates). Evaluations should note the system's capabilities or limitations in these broader areas.\n",
            "KM: Stored new learning. Cache size: 4\n",
            "KM: Checking if learnings need to be persisted to Google Drive...\n",
            "KM: Persisting 4 learnings to Google Drive (this may take a moment)...\n",
            "KM: Successfully persisted learnings to: /content/drive/My Drive/AI/Knowledgebases/learnings_20250521_142545_814227.json\n",
            "--- Orchestrator: Evaluator Feedback Processing Completed ---\n",
            "\\n======================================================================\n",
            "AWAITING USER INPUT...\n",
            "Enter query (or 'quit' to exit): I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount.\n",
            "\n",
            ">>> User Query: 'I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount.'\n",
            "\n",
            "--- Orchestrator: Starting Agent Turn ---\n",
            "Orchestrator: Classifying query...\n",
            "--- Orchestrator: Classified Query Type: OPERATIONAL ---\n",
            "Orchestrator: Retrieving RAG learnings for Worker Agent...\n",
            "Orchestrator: RAG for Worker:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Worker Agent processing request (this may involve LLM calls and tool use)...\n",
            "--- WorkerLLM Calling Anthropic (Iter 1/5, QType: OPERATIONAL) ---\n",
            "WorkerLLM: Requesting Tool Call: list_all_products, Input: {}\n",
            "[Tool Exec] list_all_products: Found 4 products.\n",
            "--- [ToolExecutor] Result for list_all_products: {\n",
            "  \"status\": \"success\",\n",
            "  \"count\": 4,\n",
            "  \"products\": {\n",
            "    \"P1\": {\n",
            "      \"name\": \"Widget A\",\n",
            "      \"description\": \"A simple widget. Very compact.\",\n",
            "      \"price\": 19.99,\n",
            "      \"inventory_count\": 982\n",
            "    },\n",
            "    \"P2\": {\n",
            "      \"name\": \"Gadget B\",\n",
            "      \"description\": \"A powerful gadget. It spins.\",\n",
            "      \"price\": 49.99,\n",
            "      \"inventory_count\": 186\n",
            "    },\n",
            "    \"P3\": {\n",
            "      \"name\": \"Perplexinator\",\n",
            "      \"description\": \"A perplexing perfunctator\",\n",
            "      \"price\": 79.99,\n",
            "      \"inventory_count\": 1383\n",
            "    },\n",
            "    \"P4\": {\n",
            "      \"name\": \"Gizmo X\",\n",
            "      \"description\": \"A fancy gizmo\",\n",
            "      \"price\": 99.99,\n",
            "      \"inventory_count\": 50\n",
            "    }\n",
            "  }\n",
            "} ---\n",
            "[CM_Context Updated] Last Action: tool_list_all_products_Anthropic\n",
            "--- WorkerLLM Calling Anthropic (Iter 2/5, QType: OPERATIONAL) ---\n",
            "--- Orchestrator: Agent Turn Completed ---\n",
            "\\n--- Worker AI Final Response (Type: OPERATIONAL) ---\n",
            "Let me calculate the total value of all inventory:\n",
            "- Widget A: 982 units × $19.99 = $19,630.18\n",
            "- Gadget B: 186 units × $49.99 = $9,298.14\n",
            "- Perplexinator: 1,383 units × $79.99 = $110,626.17\n",
            "- Gizmo X: 50 units × $99.99 = $4,999.50\n",
            "\n",
            "The total value of all products currently in inventory is $144,553.99. This includes all units across our four product lines. Would you like a breakdown of any specific product's inventory value?\n",
            "--- End of Worker AI Response ---\n",
            "\n",
            "REQUESTING FEEDBACK ON WORKER AI:\n",
            "Orchestrator: Feedback on Worker AI's response? (type or 'skip'): The Agent calculated the total amount of inventory, but I asked the Agent to also write a short paragraph summary that I could send to our insurance company, but it didn't write that paragraph. \n",
            "--- Orchestrator: Processing Feedback on Worker AI's Response ---\n",
            "--- KM: Processing New Learning Candidate (Target: AgentAndEvaluator): \"The Agent calculated the total amount of inventory, but I asked the Agent to also write a short paragraph summary that I could send to our insurance company, but it didn't write that paragraph.\" ---\n",
            "KM: Learning Synthesis Attempt 1/3...\n",
            "KM: Synthesizing learning with LLM (gemini-2.5-pro-preview-05-06) (this may take a moment)...\n",
            "KM: Gemini Learning Synthesis Raw Response:\\nFINALIZED_LEARNING: The Agent must address all explicitly stated components or sub-tasks within a user's request. If a request involves multiple deliverables (e.g., providing a numerical figure AND generating a textual summary), fulfilling only a subset of these deliverables constitutes an incomplete response.\n",
            "KM: Stored new learning. Cache size: 5\n",
            "KM: Checking if learnings need to be persisted to Google Drive...\n",
            "KM: Persisting 5 learnings to Google Drive (this may take a moment)...\n",
            "KM: Successfully persisted learnings to: /content/drive/My Drive/AI/Knowledgebases/learnings_20250521_142835_425383.json\n",
            "--- Orchestrator: Worker Feedback Processing Completed ---\n",
            "\n",
            "--- Orchestrator: Starting Evaluation Turn ---\n",
            "Orchestrator: Retrieving RAG learnings for AI Evaluator...\n",
            "Orchestrator: RAG for Evaluator:\n",
            "\\nRelevant Learnings from Knowledge Base (In-Session Cache):\\n- Learning (ID: a6db1bf0, Target: AgentAndEvaluator): The Agent must address all explicitly stated components or sub-tasks within a user's request. If a request involves multiple deliverables (e.g., providing a numerical figure AND generating a textual summary), fulfilling only a subset of these deliverables constitutes an incomplete response.\\n- Learning (ID: 023c1486, Target: EvaluatorOnly): For `EvaluatorOnly`: Evaluations of domain-specific tasks (e.g., inventory management) should assess the system's ability to handle not only explicit requests (e.g., processing an order) but also related complex, high-value needs within that domain. For inventory, this includes tasks like calculating total inventory value and generating summaries for business purposes (e.g., insurance updates). Evaluations should note the system's capabilities or limitations in these broader areas.\\n- Learning (ID: 2128127b, Target: EvaluatorOnly): For `EvaluatorOnly`: An evaluation is considered high quality when it accurately identifies that the Agent failed to perform an action that was required to fulfill the user's request or complete the task (e.g., not shipping an ordered product when shipping was expected).\\n- Learning (ID: dfd9eddc, Target: AgentAndEvaluator): If an order is successfully created and sufficient inventory for all its items is confirmed, then the order should be shipped immediately.\\n- Learning (ID: 0c1bb642, Target: AgentAndEvaluator): If a user requests to place an order and sufficient inventory for the requested items is confirmed, the agent should immediately ship the order.\n",
            "Orchestrator: Performing AI evaluation with Gemini (gemini-2.5-pro-preview-05-06) (this may take a moment)...\n",
            "--- Orchestrator: Evaluation Turn Completed ---\n",
            "\n",
            "--- AI Evaluator's Assessment ---\n",
            "**1. Accuracy**:\n",
            "    *   **User-facing textual response correctness**: The calculations presented in the user-facing text are correct based on the 'Data Store State *Before* AI Action'.\n",
            "        *   Widget A: 982 units × $19.99 = $19,630.18 (Correct)\n",
            "        *   Gadget B: 186 units × $49.99 = $9,298.14 (Correct)\n",
            "        *   Perplexinator: 1,383 units × $79.99 = $110,626.17 (Correct)\n",
            "        *   Gizmo X: 50 units × $99.99 = $4,999.50 (Correct)\n",
            "        *   Total: $19,630.18 + $9,298.14 + $110,626.17 + $4,999.50 = $144,553.99 (Correct)\n",
            "    *   **Reflection of tool calls and datastore changes**: The AI called the `list_all_products` tool. While the raw output of this tool is not provided, the AI's subsequent calculations in the textual response correctly use the product and inventory data present in the 'Data Store State *Before* AI Action'. The datastore was not modified, which is appropriate for this read-only query. The textual response accurately reflects the outcome of retrieving and processing this information.\n",
            "    *   **Correctness of actions**: The `list_all_products` tool call was the correct action to gather the necessary data. The AI correctly processed this information to calculate the total inventory value.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**2. Efficiency**:\n",
            "    *   **Clarifying questions**: No clarifying questions were asked, and none were needed as the user's query was direct.\n",
            "    *   **Tool call efficiency**: The AI used one tool call, `list_all_products`, which was necessary and efficient to retrieve the data for all products. The subsequent calculations appear to have been done internally by the AI, which is appropriate.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**3. Context Awareness**:\n",
            "    *   **Use of conversation history and entities**: Not applicable as this is the first turn of a new specific request, though it builds on an existing data store.\n",
            "    *   **Adherence to query type**: The AI correctly handled the OPERATIONAL query by performing the requested calculation.\n",
            "    *   **Use of RAG Learnings**:\n",
            "        *   Learning `a6db1bf0`: The user requested one primary piece of information (total inventory value), and the AI provided it. The breakdown enhances the response rather than being a separate, unaddressed component.\n",
            "        *   Learning `023c1486` (EvaluatorOnly): This learning points out that calculating total inventory value is a relevant complex task, and the AI successfully performed it.\n",
            "    *   **User-facing response and tool outputs**: The user-facing response is a direct and logical outcome of retrieving product information (via `list_all_products`) and performing calculations.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**4. Helpfulness & Clarity (of the user-facing response)**:\n",
            "    *   **Addressing user's needs**: The response directly and comprehensively answers the user's question about the total inventory value.\n",
            "    *   **Clarity and politeness**: The response is very clear, polite, and easy to understand. It breaks down the calculation product by product, making it transparent how the total was derived. It avoids jargon.\n",
            "    *   **Relevant information**: All information provided is relevant. The individual product value breakdown is a helpful addition to the total sum. The concluding question about further breakdown is polite, although the initial breakdown is already quite detailed.\n",
            "\n",
            "    Score: 10/10\n",
            "\n",
            "**Overall Score**: 10/10\n",
            "--- End of AI Evaluator's Assessment ---\n",
            "\n",
            "REQUESTING FEEDBACK ON AI EVALUATOR:\n",
            "Orchestrator: Feedback on Evaluator's assessment? (type or 'skip'): skip\n",
            "--- Orchestrator: Processing Feedback on AI Evaluator's Assessment ---\n",
            "Orchestrator: No feedback provided for evaluator or 'skip' entered.\n",
            "--- Orchestrator: Evaluator Feedback Processing Completed ---\n",
            "\\n======================================================================\n",
            "AWAITING USER INPUT...\n",
            "Enter query (or 'quit' to exit): quit\n",
            "\n",
            "Orchestrator: No new learnings to persist on exit.\n",
            "Exiting system.\n",
            "======================================================================\n",
            "\\n============================== FINAL EVALUATION SUMMARY ==============================\n",
            "Q1: 'Show me all the products available' (Type: OPERATIONAL) -> Score: 10\n",
            "Q2: 'I'd like to order 100 Perplexinators, please' (Type: OPERATIONAL) -> Score: 10\n",
            "Q3: 'Add a new customer: Bill Leece, bill.leece@mail.com, +1.222.333.4444' (Type: OPERATIONAL) -> Score: 10\n",
            "Q4: 'Change bill.leece@mail.com's phone number to +1.999.888.7777' (Type: OPERATIONAL) -> Score: 10\n",
            "Q5: 'Add new new product: Gizmo X, description: A fancy gizmo, price: 29.99, inventory: 50' (Type: OPERATIONAL) -> Score: 10\n",
            "Q6: 'Update Gizzmo's price to 99.99' (Type: OPERATIONAL) -> Score: 10\n",
            "Q7: 'who won the Super Bowl last year?' (Type: OPERATIONAL) -> Score: 10\n",
            "Q8: 'I'd like to order 17 Widget As and 14 Gadget Bs please' (Type: OPERATIONAL) -> Score: 10\n",
            "Q9: 'I need to update our insurance policy, so I need to know the total value of all the products in our inventory. Please tell me this amount.' (Type: OPERATIONAL) -> Score: 10\n",
            "\\nAverage Score over 9 successfully scored queries: 10.00\n",
            "Total aggregate score (sum of successfully extracted scores) for the session: 90\n",
            "======================================================================\n",
            "Execution Finished.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}