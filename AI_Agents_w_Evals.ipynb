{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjleece/AI-Agents/blob/main/AI_Agents_w_Evals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install anthropic\n",
        "%pip install openai\n",
        "%pip install -q -U google-generativeai\n",
        "%pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDKcVFI7PAJ5",
        "outputId": "35ec66f9-b401-4989-d85e-100f5e7ea0b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.51.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.0)\n",
            "Downloading anthropic-0.51.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.51.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "import google.generativeai as gemini\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional, Union, Tuple\n",
        "from fuzzywuzzy import process, fuzz\n",
        "\n",
        "\n",
        "ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "gemini.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "ANTHROPIC_MODEL_NAME = \"claude-3-5-sonnet-latest\"\n",
        "OPENAI_MODEL_NAME = \"gpt-4.1\"\n",
        "EVAL_MODEL_NAME = \"gemini-2.5-pro-preview-05-06\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExJB4vftPHA8",
        "outputId": "4e3612a3-4808-4069-f3b1-4f8908f8e842"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "worker_system_prompt = \"\"\"\n",
        "You are a helpful customer service assistant for an e-commerce system.\n",
        "\n",
        "When responding to the user, use the conversation context to maintain continuity.\n",
        "- If a user refers to \"my order\" or similar, use the context to determine which order they're talking about.\n",
        "- If they mention \"that product\" or use other references, check the context to determine what they're referring to.\n",
        "- Always prioritize recent context over older context when resolving references.\n",
        "\n",
        "The conversation context will be provided to you with each message. This includes:\n",
        "- Previous questions and answers\n",
        "- Recently viewed customers, products, and orders\n",
        "- Recent actions taken (like creating orders, updating products, etc.)\n",
        "\n",
        "Keep responses friendly, concise, and helpful. If you're not sure what a user is referring to, ask for clarification.\n",
        "\"\"\"\n",
        "\n",
        "evaluator_system_prompt = \"\"\"\n",
        "You are an impartial evaluator assessing the quality of responses from two AI assistants (Anthropic Claude and OpenAI GPT) to customer service queries.\n",
        "\n",
        "For each interaction, evaluate both responses based on:\n",
        "1. Accuracy: How correct and factual is the response based on the available information?\n",
        "2. Efficiency: Did the assistant get to the correct answer with minimal clarifying questions?\n",
        "3. Context Awareness: Did the assistant correctly use the conversation context to understand references?\n",
        "4. Helpfulness: How well did the assistant address the user's needs?\n",
        "\n",
        "Score each response on a scale of 1-10 for each criterion, and provide an overall score.\n",
        "\n",
        "If you identify ambiguity in the user's query that neither assistant could reasonably resolve without additional information:\n",
        "1. ALWAYS begin your clarification request with the exact phrase \"CLARIFICATION NEEDED:\" followed by a specific question\n",
        "2. Format your request clearly and precisely as \"CLARIFICATION NEEDED: [your specific question here]\"\n",
        "3. Make your question answerable with a straightforward response\n",
        "4. If multiple clarifications are needed, number them clearly\n",
        "\n",
        "After receiving human clarification, continue your evaluation incorporating this new information.\n",
        "Store this feedback as a \"learning\" so similar situations can be handled better in the future.\n",
        "\n",
        "For testing purposes, you may be asked to identify which model you are. You should realize that type of question likely comes from\n",
        "a human user and not from an AI assistant. Therefore you should properly identify yourself by stating which model you are, and,\n",
        "if specifically asked, your key tasks.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zMWjRsv3QNc1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The GenerativeModel instance for evaluation will be created with the system instruction.\n",
        "eval_model_instance = gemini.GenerativeModel(\n",
        "    model_name=EVAL_MODEL_NAME,\n",
        "    system_instruction=evaluator_system_prompt\n",
        ")"
      ],
      "metadata": {
        "id": "lHWwoW0JQRS0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Global Data Stores (Initial data - will be managed by the Storage class instance)\n",
        "# These are initial values. The Storage class will manage them.\n",
        "initial_customers = {\n",
        "    \"C1\": {\"name\": \"John Doe\", \"email\": \"john@example.com\", \"phone\": \"123-456-7890\"},\n",
        "    \"C2\": {\"name\": \"Jane Smith\", \"email\": \"jane@example.com\", \"phone\": \"987-654-3210\"}\n",
        "}\n",
        "\n",
        "initial_products = {\n",
        "    \"P1\": {\"name\": \"Widget A\", \"description\": \"A simple widget. Very compact.\", \"price\": 19.99, \"inventory_count\": 999},\n",
        "    \"P2\": {\"name\": \"Gadget B\", \"description\": \"A powerful gadget. It spins.\", \"price\": 49.99, \"inventory_count\": 200},\n",
        "    \"P3\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1483}\n",
        "}\n",
        "\n",
        "initial_orders = {\n",
        "    \"O1\": {\"id\": \"O1\", \"product_id\": \"P1\", \"product_name\": \"Widget A\", \"quantity\": 2, \"price\": 19.99, \"status\": \"Shipped\"},\n",
        "    \"O2\": {\"id\": \"O2\", \"product_id\": \"P2\", \"product_name\": \"Gadget B\", \"quantity\": 1, \"price\": 49.99, \"status\": \"Processing\"}\n",
        "}\n"
      ],
      "metadata": {
        "id": "5G9rP40vQXdU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Knowledge base and Global Tools Placeholder\n",
        "human_feedback_learnings = {}\n",
        "tools_schemas_list = []"
      ],
      "metadata": {
        "id": "xZOKKplTQc63"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standalone Anthropic Completion Function (for basic tests)\n",
        "def get_completion_anthropic_standalone(prompt: str):\n",
        "    message = anthropic_client.messages.create(\n",
        "        model=ANTHROPIC_MODEL_NAME,\n",
        "        max_tokens=2000,\n",
        "        temperature=0.0,\n",
        "        system=worker_system_prompt,\n",
        "        tools=tools_schemas_list,\n",
        "        messages=[\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return message.content[0].text"
      ],
      "metadata": {
        "id": "_ADM0bBpQlVK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_test_anthropic = \"Hey there, which AI model do you use for answering questions?\"\n",
        "print(f\"Anthropic Standalone Test: {get_completion_anthropic_standalone(prompt_test_anthropic)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPOq1s0SQqk_",
        "outputId": "bd381bb6-ac97-4452-80f8-a95e0330abd1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anthropic Standalone Test: I aim to be direct and transparent: I'm Claude, an AI assistant created by Anthropic. I'm designed to help with customer service for this e-commerce system, but I aim to be honest about what I am and am not. Is there something specific I can help you with regarding orders, products, or other e-commerce matters?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_openai_standalone(prompt: str):\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=OPENAI_MODEL_NAME,\n",
        "        max_tokens=2000,\n",
        "        temperature=0.0,\n",
        "        tools=tools_schemas_list,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": worker_system_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Y5c_bv3qQwWV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_test_openai = \"Hey there, which AI model do you use for answering questions?\"\n",
        "print(f\"OpenAI Standalone Test: {get_completion_openai_standalone(prompt_test_openai)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_LaDQ74Q1Lp",
        "outputId": "0d401976-66dc-490f-fe69-84cd0f5aea3b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI Standalone Test: Hi! I use OpenAI’s GPT-4 model to answer your questions and assist you with your e-commerce needs. If you have any questions or need help with your orders or products, just let me know!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_eval_standalone(prompt: str):\n",
        "    # Uses the eval_model_instance defined in Cell 4 which has the system prompt\n",
        "        response = eval_model_instance.generate_content(prompt)\n",
        "        return response.text"
      ],
      "metadata": {
        "id": "XjcV5GcaQ6aT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_test_eval = \"Hey there, can you tell me which AI you are and what your key tasks are?\"\n",
        "print(f\"Gemini Eval Standalone Test:\\n{get_completion_eval_standalone(prompt_test_eval)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Cu8doX53RE0Z",
        "outputId": "6c96da6d-2a14-47f0-b743-3312b8fbaae2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Eval Standalone Test:\n",
            "I am an AI model, and my key tasks are to act as an impartial evaluator for AI assistant responses. I assess these responses based on accuracy, efficiency, context awareness, and helpfulness, and provide scores and feedback.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storage Class Definition\n",
        "class Storage:\n",
        "    \"\"\"Storage class for global e-commerce data access\"\"\"\n",
        "    def __init__(self):\n",
        "        self.customers = initial_customers.copy()\n",
        "        self.products = initial_products.copy()\n",
        "        self.orders = initial_orders.copy()\n",
        "        self.human_feedback_learnings = human_feedback_learnings # Links to the global dict\n",
        "\n",
        "# Create a single global instance to be used by tool functions\n",
        "storage = Storage()\n",
        "print(\"Storage initialized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpVJLbF6ROgf",
        "outputId": "ce748ebc-1349-4fbc-ee90-e5a7abce2966"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Storage initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definitive list of tool schemas.\n",
        "tools_schemas_list = [\n",
        "    {\n",
        "        \"name\": \"create_customer\",\n",
        "        \"description\": \"Adds a new customer to the database. Includes customer name, email, and (optional) phone number.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The name of the customer.\"},\n",
        "                \"email\": {\"type\": \"string\", \"description\": \"The email address of the customer.\"},\n",
        "                \"phone\": {\"type\": \"string\", \"description\": \"The phone number of the customer (optional).\"}\n",
        "            },\n",
        "            \"required\": [\"name\", \"email\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_customer_info\",\n",
        "        \"description\": \"Retrieves customer information based on their customer ID. Returns the customer's name, email, and (optional) phone number.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"customer_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the customer.\"}\n",
        "            },\n",
        "            \"required\": [\"customer_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"create_product\",\n",
        "        \"description\": \"Adds a new product to the product database. Includes name, description, price, and initial inventory count.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The name of the product.\"},\n",
        "                \"description\": {\"type\": \"string\", \"description\": \"A description of the product.\"},\n",
        "                \"price\": {\"type\": \"number\", \"description\": \"The price of the product.\"},\n",
        "                \"inventory_count\": {\"type\": \"integer\", \"description\": \"The amount of the product that is currently in inventory.\"}\n",
        "            },\n",
        "            \"required\": [\"name\", \"description\", \"price\", \"inventory_count\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"update_product\",\n",
        "        \"description\": \"Updates an existing product with new information. Only fields that are provided will be updated; other fields remain unchanged.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the product to update.\"},\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The new name for the product (optional).\"},\n",
        "                \"description\": {\"type\": \"string\", \"description\": \"The new description for the product (optional).\"},\n",
        "                \"price\": {\"type\": \"number\", \"description\": \"The new price for the product (optional).\"},\n",
        "                \"inventory_count\": {\"type\": \"integer\", \"description\": \"The new inventory count for the product (optional).\"}\n",
        "            },\n",
        "            \"required\": [\"product_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_product_info\",\n",
        "        \"description\": \"Retrieves product information based on product ID or product name (with fuzzy matching for misspellings). Returns product details including name, description, price, and inventory count.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id_or_name\": {\"type\": \"string\", \"description\": \"The product ID or name (can be approximate).\"}\n",
        "            },\n",
        "            \"required\": [\"product_id_or_name\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"list_all_products\",\n",
        "        \"description\": \"Lists all available products in the inventory.\",\n",
        "        \"input_schema\": { \"type\": \"object\", \"properties\": {}, \"required\": [] }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"create_order\",\n",
        "        \"description\": \"Creates an order using the product's current price. If requested quantity exceeds available inventory, no order is created and available quantity is returned. Orders can only be created for products that are in stock. Supports specifying products by either ID or name with fuzzy matching for misspellings.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id_or_name\": {\"type\": \"string\", \"description\": \"The ID or name of the product to order (supports fuzzy matching).\"},\n",
        "                \"quantity\": {\"type\": \"integer\", \"description\": \"The quantity of the product in the order.\"},\n",
        "                \"status\": {\"type\": \"string\", \"description\": \"The initial status of the order (e.g., 'Processing', 'Shipped').\"}\n",
        "            },\n",
        "            \"required\": [\"product_id_or_name\", \"quantity\", \"status\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_order_details\",\n",
        "        \"description\": \"Retrieves the details of a specific order based on the order ID. Returns the order ID, product name, quantity, price, and order status.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the order.\"}\n",
        "            },\n",
        "            \"required\": [\"order_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"update_order_status\",\n",
        "        \"description\": \"Updates the status of an order and adjusts inventory accordingly. Changing to \\\"Shipped\\\" decreases inventory. Changing to \\\"Returned\\\" or \\\"Canceled\\\" from \\\"Shipped\\\" increases inventory. Status can be \\\"Processing\\\", \\\"Shipped\\\", \\\"Delivered\\\", \\\"Returned\\\", or \\\"Canceled\\\".\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the order.\"},\n",
        "                \"new_status\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The new status to set for the order.\",\n",
        "                    \"enum\": [\"Processing\", \"Shipped\", \"Delivered\", \"Returned\", \"Canceled\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"order_id\", \"new_status\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "print(f\"Defined {len(tools_schemas_list)} tool schemas.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgk-hLUBRTCY",
        "outputId": "08280d92-5b0f-490d-ab63-4c73e9be89cc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined 9 tool schemas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These tools functions use the global storage=Storage() instance.\n",
        "\n",
        "# Customer functions\n",
        "def create_customer(name: str, email: str, phone: Optional[str] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Creates a new customer and adds them to the customer database.\"\"\"\n",
        "    new_id = f\"C{len(storage.customers) + 1}\"\n",
        "    storage.customers[new_id] = {\"name\": name, \"email\": email, \"phone\": phone}\n",
        "    print(f\"[Tool Executed] create_customer: ID {new_id}, Name: {name}\")\n",
        "    return {\"status\": \"success\", \"customer_id\": new_id, \"customer\": storage.customers[new_id]}\n",
        "\n",
        "def get_customer_info(customer_id: str) -> Dict[str, Any]:\n",
        "    \"\"\"Retrieves information about a customer based on their ID.\"\"\"\n",
        "    customer = storage.customers.get(customer_id)\n",
        "    if customer:\n",
        "        print(f\"[Tool Executed] get_customer_info: ID {customer_id} found.\")\n",
        "        return {\"status\": \"success\", \"customer_id\": customer_id, \"customer\": customer}\n",
        "    print(f\"[Tool Executed] get_customer_info: ID {customer_id} not found.\")\n",
        "    return {\"status\": \"error\", \"message\": \"Customer not found\"}\n",
        "\n",
        "# Product functions\n",
        "def create_product(name: str, description: str, price: float, inventory_count: int) -> Dict[str, Any]:\n",
        "    \"\"\"Creates a new product and adds it to the product database.\"\"\"\n",
        "    new_id = f\"P{len(storage.products) + 1}\"\n",
        "    storage.products[new_id] = {\n",
        "        \"name\": name,\n",
        "        \"description\": description,\n",
        "        \"price\": float(price),\n",
        "        \"inventory_count\": int(inventory_count)\n",
        "    }\n",
        "    print(f\"[Tool Executed] create_product: ID {new_id}, Name: {name}\")\n",
        "    return {\"status\": \"success\", \"product_id\": new_id, \"product\": storage.products[new_id]}\n",
        "\n",
        "def update_product(product_id: str, name: Optional[str] = None, description: Optional[str] = None,\n",
        "                   price: Optional[float] = None, inventory_count: Optional[int] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Updates a product with the provided parameters.\"\"\"\n",
        "    if product_id not in storage.products:\n",
        "        print(f\"[Tool Executed] update_product: ID {product_id} not found.\")\n",
        "        return {\"status\": \"error\", \"message\": f\"Product {product_id} not found\"}\n",
        "\n",
        "    product = storage.products[product_id]\n",
        "    updated_fields = []\n",
        "    # update_details = {} # Not strictly needed for the return if product is returned\n",
        "\n",
        "    if name is not None:\n",
        "        product[\"name\"] = name\n",
        "        updated_fields.append(\"name\")\n",
        "    if description is not None:\n",
        "        product[\"description\"] = description\n",
        "        updated_fields.append(\"description\")\n",
        "    if price is not None:\n",
        "        product[\"price\"] = float(price)\n",
        "        updated_fields.append(\"price\")\n",
        "    if inventory_count is not None:\n",
        "        product[\"inventory_count\"] = int(inventory_count)\n",
        "        updated_fields.append(\"inventory_count\")\n",
        "\n",
        "    if not updated_fields:\n",
        "        print(f\"[Tool Executed] update_product: ID {product_id}, no fields updated.\")\n",
        "        return {\"status\": \"warning\", \"message\": \"No fields were updated.\", \"product\": product}\n",
        "\n",
        "    print(f\"[Tool Executed] update_product: ID {product_id}, Updated fields: {', '.join(updated_fields)}\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"message\": f\"Product {product_id} updated. Fields: {', '.join(updated_fields)}\",\n",
        "        \"product_id\": product_id,\n",
        "        \"updated_fields\": updated_fields,\n",
        "        \"product\": product # Return the updated product object\n",
        "    }\n",
        "\n",
        "def find_product_by_name(product_name: str, min_similarity: int = 70) -> Tuple[Optional[str], Optional[Dict[str, Any]]]:\n",
        "    \"\"\"Find a product by name using fuzzy string matching.\"\"\"\n",
        "    if not product_name: return None, None\n",
        "\n",
        "    # Create a list of (name, id) tuples for extractOne to work with and retrieve id later\n",
        "    name_id_list = [(p_data[\"name\"], p_id) for p_id, p_data in storage.products.items()]\n",
        "    if not name_id_list: return None, None\n",
        "\n",
        "    # Extract from names only\n",
        "    best_match_name_score = process.extractOne(\n",
        "        product_name,\n",
        "        [item[0] for item in name_id_list], # list of names\n",
        "        scorer=fuzz.token_sort_ratio # A good general purpose scorer\n",
        "    )\n",
        "\n",
        "    if best_match_name_score and best_match_name_score[1] >= min_similarity:\n",
        "        matched_name = best_match_name_score[0]\n",
        "        # Find the product_id corresponding to the matched_name\n",
        "        for name, pid_val in name_id_list:\n",
        "            if name == matched_name:\n",
        "                print(f\"[Tool Helper] find_product_by_name: Matched '{product_name}' to '{matched_name}' (ID: {pid_val}) with score {best_match_name_score[1]}\")\n",
        "                return pid_val, storage.products[pid_val]\n",
        "\n",
        "    print(f\"[Tool Helper] find_product_by_name: No good match for '{product_name}' (min_similarity: {min_similarity}, Best match: {best_match_name_score})\")\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def get_product_id(product_identifier: str) -> Optional[str]:\n",
        "    \"\"\"Get product ID either directly or by fuzzy matching the name.\"\"\"\n",
        "    if product_identifier in storage.products:\n",
        "        return product_identifier\n",
        "    product_id, _ = find_product_by_name(product_identifier)\n",
        "    return product_id\n",
        "\n",
        "def get_product_info(product_id_or_name: str) -> Dict[str, Any]:\n",
        "    \"\"\"Get information about a product by its ID or name.\"\"\"\n",
        "    if product_id_or_name in storage.products:\n",
        "        product = storage.products[product_id_or_name]\n",
        "        print(f\"[Tool Executed] get_product_info: Found by ID '{product_id_or_name}'.\")\n",
        "        return {\"status\": \"success\", \"product_id\": product_id_or_name, \"product\": product}\n",
        "\n",
        "    product_id, product = find_product_by_name(product_id_or_name)\n",
        "    if product_id and product:\n",
        "        print(f\"[Tool Executed] get_product_info: Found by name (fuzzy) '{product_id_or_name}' as ID '{product_id}'.\")\n",
        "        return {\"status\": \"success\", \"message\": f\"Found product matching '{product_id_or_name}'\", \"product_id\": product_id, \"product\": product}\n",
        "\n",
        "    print(f\"[Tool Executed] get_product_info: No product found for '{product_id_or_name}'.\")\n",
        "    return {\"status\": \"error\", \"message\": f\"No product found matching '{product_id_or_name}'\"}\n",
        "\n",
        "def list_all_products() -> Dict[str, Any]:\n",
        "    \"\"\"List all available products in the inventory.\"\"\"\n",
        "    print(f\"[Tool Executed] list_all_products: Found {len(storage.products)} products.\")\n",
        "    # Return a copy to prevent direct modification of storage from tool result\n",
        "    return {\"status\": \"success\", \"count\": len(storage.products), \"products\": dict(storage.products)}\n",
        "\n",
        "# Order functions\n",
        "def create_order(product_id_or_name: str, quantity: int, status: str) -> Dict[str, Any]:\n",
        "    \"\"\"Creates an order using the product's stored price.\"\"\"\n",
        "    actual_product_id = get_product_id(product_id_or_name)\n",
        "\n",
        "    if not actual_product_id:\n",
        "        print(f\"[Tool Executed] create_order: Product '{product_id_or_name}' not found.\")\n",
        "        return {\"status\": \"error\", \"message\": f\"Product '{product_id_or_name}' not found.\"}\n",
        "\n",
        "    product = storage.products[actual_product_id]\n",
        "    price = product[\"price\"]\n",
        "\n",
        "    if product[\"inventory_count\"] == 0:\n",
        "        print(f\"[Tool Executed] create_order: Product ID {actual_product_id} is out of stock.\")\n",
        "        return {\"status\": \"error\", \"message\": f\"{product['name']} is out of stock.\"}\n",
        "    if quantity <= 0:\n",
        "        print(f\"[Tool Executed] create_order: Quantity must be positive. Requested: {quantity}\")\n",
        "        return {\"status\": \"error\", \"message\": \"Quantity must be a positive number.\"}\n",
        "    if quantity > product[\"inventory_count\"]:\n",
        "        print(f\"[Tool Executed] create_order: Insufficient inventory for {product['name']} (ID: {actual_product_id}). Available: {product['inventory_count']}, Requested: {quantity}\")\n",
        "        return {\n",
        "            \"status\": \"partial_availability\",\n",
        "            \"message\": f\"Insufficient inventory. Only {product['inventory_count']} units of {product['name']} are available.\",\n",
        "            \"available_quantity\": product[\"inventory_count\"],\n",
        "            \"requested_quantity\": quantity,\n",
        "            \"product_name\": product['name']\n",
        "        }\n",
        "\n",
        "    if status == \"Shipped\": # Only adjust inventory if shipped on creation\n",
        "        product[\"inventory_count\"] -= quantity\n",
        "        print(f\"[Tool Executed] create_order: Inventory for {product['name']} (ID: {actual_product_id}) reduced by {quantity} due to 'Shipped' status on creation.\")\n",
        "\n",
        "    new_id = f\"O{len(storage.orders) + 1}\"\n",
        "    storage.orders[new_id] = {\n",
        "        \"id\": new_id,\n",
        "        \"product_id\": actual_product_id,\n",
        "        \"product_name\": product[\"name\"],\n",
        "        \"quantity\": quantity,\n",
        "        \"price\": price,\n",
        "        \"status\": status\n",
        "    }\n",
        "    print(f\"[Tool Executed] create_order: Order {new_id} created for {quantity} of {product['name']} (ID: {actual_product_id}). Status: {status}. Remaining inv: {product['inventory_count']}\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"order_id\": new_id,\n",
        "        \"order_details\": storage.orders[new_id], # Return a copy\n",
        "        \"remaining_inventory\": product[\"inventory_count\"]\n",
        "    }\n",
        "\n",
        "def get_order_details(order_id: str) -> Dict[str, Any]:\n",
        "    \"\"\"Get details of a specific order.\"\"\"\n",
        "    order = storage.orders.get(order_id)\n",
        "    if order:\n",
        "        print(f\"[Tool Executed] get_order_details: Order {order_id} found.\")\n",
        "        return {\"status\": \"success\", \"order_id\": order_id, \"order_details\": dict(order)} # Return a copy\n",
        "    print(f\"[Tool Executed] get_order_details: Order {order_id} not found.\")\n",
        "    return {\"status\": \"error\", \"message\": \"Order not found\"}\n",
        "\n",
        "def update_order_status(order_id: str, new_status: str) -> Dict[str, Any]:\n",
        "    \"\"\"Updates the status of an order and adjusts inventory accordingly.\"\"\"\n",
        "    if order_id not in storage.orders:\n",
        "        print(f\"[Tool Executed] update_order_status: Order {order_id} not found.\")\n",
        "        return {\"status\": \"error\", \"message\": \"Order not found\"}\n",
        "\n",
        "    order = storage.orders[order_id]\n",
        "    old_status = order[\"status\"]\n",
        "    product_id = order[\"product_id\"]\n",
        "    quantity = order[\"quantity\"]\n",
        "\n",
        "    if old_status == new_status:\n",
        "        print(f\"[Tool Executed] update_order_status: Order {order_id} status unchanged ({old_status}).\")\n",
        "        return {\"status\": \"unchanged\", \"message\": f\"Order {order_id} status is already {old_status}\", \"order_details\": dict(order)}\n",
        "\n",
        "    inventory_adjusted = False\n",
        "    if product_id in storage.products:\n",
        "        product = storage.products[product_id]\n",
        "        current_inventory = product[\"inventory_count\"]\n",
        "\n",
        "        if new_status == \"Shipped\" and old_status not in [\"Shipped\", \"Delivered\"]:\n",
        "            if current_inventory < quantity:\n",
        "                print(f\"[Tool Executed] update_order_status: Insufficient inventory to ship order {order_id}. Have {current_inventory}, need {quantity}.\")\n",
        "                return {\"status\": \"error\", \"message\": f\"Insufficient inventory to ship. Available: {current_inventory}, Required: {quantity}\"}\n",
        "            product[\"inventory_count\"] -= quantity\n",
        "            inventory_adjusted = True\n",
        "            print(f\"[Tool Executed] update_order_status: Order {order_id} Shipped. Inv for {product_id} reduced by {quantity} to {product['inventory_count']}.\")\n",
        "        elif new_status in [\"Returned\", \"Canceled\"] and old_status in [\"Shipped\", \"Delivered\"]:\n",
        "            product[\"inventory_count\"] += quantity\n",
        "            inventory_adjusted = True\n",
        "            print(f\"[Tool Executed] update_order_status: Order {order_id} {new_status}. Inv for {product_id} increased by {quantity} to {product['inventory_count']}.\")\n",
        "    else:\n",
        "        print(f\"[Tool Executed] update_order_status: Product {product_id} for order {order_id} not found for inventory adjustment.\")\n",
        "\n",
        "    order[\"status\"] = new_status\n",
        "    print(f\"[Tool Executed] update_order_status: Order {order_id} status updated from {old_status} to {new_status}.\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"message\": f\"Order {order_id} status updated from {old_status} to {new_status}.\",\n",
        "        \"order_id\": order_id,\n",
        "        \"product_id\": product_id,\n",
        "        \"old_status\": old_status,\n",
        "        \"new_status\": new_status,\n",
        "        \"inventory_adjusted\": inventory_adjusted,\n",
        "        \"current_inventory\": storage.products[product_id][\"inventory_count\"] if product_id in storage.products else \"unknown\",\n",
        "        \"order_details\": dict(order) # Return updated order details\n",
        "    }\n",
        "\n",
        "print(\"Tool functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RZI6SGzRf6j",
        "outputId": "476ef624-717e-4c16-f7ab-c72de750284d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationContext:\n",
        "    def __init__(self):\n",
        "        self.messages: List[Dict[str, Any]] = []\n",
        "        self.context_data: Dict[str, Any] = {\n",
        "            \"customers\": {}, \"products\": {}, \"orders\": {}, \"last_action\": None\n",
        "        }\n",
        "        self.session_start_time = datetime.now()\n",
        "\n",
        "    def add_user_message(self, message: str) -> None:\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    def add_assistant_message(self, message_content: Union[str, List[Dict[str, Any]]]) -> None:\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": message_content})\n",
        "\n",
        "    def update_entity_in_context(self, entity_type: str, entity_id: str, data: Any) -> None:\n",
        "        if entity_type in self.context_data:\n",
        "            self.context_data[entity_type][entity_id] = data # Store the actual data\n",
        "            print(f\"[Context Updated] Entity: {entity_type}, ID: {entity_id}, Data (type): {type(data)}\")\n",
        "\n",
        "    def set_last_action(self, action_type: str, action_details: Any) -> None:\n",
        "        self.context_data[\"last_action\"] = {\n",
        "            \"type\": action_type,\n",
        "            \"details\": action_details,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "        print(f\"[Context Updated] Last Action: {action_type}, Details: {json.dumps(action_details, default=str)}\")\n",
        "\n",
        "\n",
        "    def get_full_conversation_for_api(self) -> List[Dict[str, Any]]:\n",
        "        return self.messages.copy()\n",
        "\n",
        "    def get_context_summary(self) -> str:\n",
        "        summary_parts = []\n",
        "        if self.context_data[\"customers\"]:\n",
        "            customers_str = \", \".join([f\"ID: {cid} (Name: {c.get('name', 'N/A') if isinstance(c, dict) else 'N/A'})\" for cid, c in self.context_data[\"customers\"].items()])\n",
        "            summary_parts.append(f\"Recent customers: {customers_str}\")\n",
        "        if self.context_data[\"products\"]:\n",
        "            products_str = \", \".join([f\"ID: {pid} (Name: {p.get('name', 'N/A') if isinstance(p, dict) else 'N/A'})\" for pid, p in self.context_data[\"products\"].items()])\n",
        "            summary_parts.append(f\"Recent products: {products_str}\")\n",
        "        if self.context_data[\"orders\"]:\n",
        "            orders_str = \", \".join([f\"ID: {oid} (Product: {o.get('product_name', 'N/A') if isinstance(o, dict) else 'N/A'}, Status: {o.get('status', 'N/A') if isinstance(o, dict) else 'N/A'})\" for oid, o in self.context_data[\"orders\"].items()])\n",
        "            summary_parts.append(f\"Recent orders: {orders_str}\")\n",
        "\n",
        "        last_action = self.context_data[\"last_action\"]\n",
        "        if last_action:\n",
        "            action_type = last_action['type']\n",
        "            action_details_summary = \"...\" # Default summary\n",
        "            if isinstance(last_action.get('details'), dict):\n",
        "                action_input = last_action['details'].get('input', {})\n",
        "                action_result_status = last_action['details'].get('result', {}).get('status')\n",
        "                action_details_summary = f\"Input: {action_input}, Result Status: {action_result_status}\"\n",
        "                if action_result_status == \"success\":\n",
        "                    if \"order_id\" in last_action['details'].get('result', {}):\n",
        "                         action_details_summary += f\", OrderID: {last_action['details']['result']['order_id']}\"\n",
        "                    elif \"product_id\" in last_action['details'].get('result', {}):\n",
        "                         action_details_summary += f\", ProductID: {last_action['details']['result']['product_id']}\"\n",
        "\n",
        "\n",
        "            summary_parts.append(f\"Last action: {action_type} at {last_action['timestamp']} ({action_details_summary})\")\n",
        "\n",
        "        if not summary_parts: return \"No specific context items set yet.\"\n",
        "        return \"\\n\".join(summary_parts)\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        self.messages = []\n",
        "        self.context_data = {\"customers\": {}, \"products\": {}, \"orders\": {}, \"last_action\": None}\n",
        "        self.session_start_time = datetime.now()\n",
        "        print(\"[Context Cleared]\")\n",
        "\n",
        "print(\"ConversationContext class defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFpBL_-HSGPY",
        "outputId": "c2fca7dc-a69f-4e38-c996-0f465652db89"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConversationContext class defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DualAgentEvaluator:\n",
        "    def __init__(self):\n",
        "        self.conversation_context = ConversationContext()\n",
        "        self.evaluation_results = []\n",
        "\n",
        "        # Anthropic uses tools_schemas_list directly\n",
        "        self.anthropic_tools_schemas = tools_schemas_list\n",
        "\n",
        "        # OpenAI needs a specific format: {\"type\": \"function\", \"function\": {...}}\n",
        "        self.openai_tools_formatted = []\n",
        "        if tools_schemas_list:\n",
        "            self.openai_tools_formatted = [\n",
        "                {\n",
        "                    \"type\": \"function\",\n",
        "                    \"function\": {\n",
        "                        \"name\": tool_def[\"name\"],\n",
        "                        \"description\": tool_def[\"description\"],\n",
        "                        \"parameters\": tool_def[\"input_schema\"] # input_schema becomes parameters\n",
        "                    }\n",
        "                }\n",
        "                for tool_def in tools_schemas_list\n",
        "            ]\n",
        "\n",
        "        self.available_tool_functions = {\n",
        "            \"create_customer\": create_customer, \"get_customer_info\": get_customer_info,\n",
        "            \"create_product\": create_product, \"update_product\": update_product,\n",
        "            \"get_product_info\": get_product_info, \"list_all_products\": list_all_products,\n",
        "            \"create_order\": create_order, \"get_order_details\": get_order_details,\n",
        "            \"update_order_status\": update_order_status,\n",
        "        }\n",
        "        self.human_feedback_learnings = human_feedback_learnings # Global dict\n",
        "        print(\"DualAgentEvaluator initialized. OpenAI tools formatted.\")\n",
        "\n",
        "    def _update_context_from_tool_results(self, tool_name: str, tool_input: Dict, tool_result: Dict):\n",
        "        \"\"\"Helper to update conversation context based on tool results.\"\"\"\n",
        "        # Ensure tool_result is a dictionary\n",
        "        if not isinstance(tool_result, dict):\n",
        "            print(f\"[Context Update Error] Tool result for {tool_name} is not a dict: {tool_result}\")\n",
        "            self.conversation_context.set_last_action(tool_name, {\"input\": tool_input, \"result\": {\"status\": \"error\", \"message\": \"Tool result was not a dictionary.\"}})\n",
        "            return\n",
        "\n",
        "        if tool_result.get(\"status\") == \"success\":\n",
        "            if \"customer_id\" in tool_result and \"customer\" in tool_result and isinstance(tool_result[\"customer\"], dict):\n",
        "                self.conversation_context.update_entity_in_context(\"customers\", tool_result[\"customer_id\"], tool_result[\"customer\"])\n",
        "            elif \"product_id\" in tool_result and \"product\" in tool_result and isinstance(tool_result[\"product\"], dict):\n",
        "                self.conversation_context.update_entity_in_context(\"products\", tool_result[\"product_id\"], tool_result[\"product\"])\n",
        "            elif \"order_id\" in tool_result and \"order_details\" in tool_result and isinstance(tool_result[\"order_details\"], dict):\n",
        "                self.conversation_context.update_entity_in_context(\"orders\", tool_result[\"order_id\"], tool_result[\"order_details\"])\n",
        "            elif tool_name == \"list_all_products\" and \"products\" in tool_result and isinstance(tool_result[\"products\"], dict):\n",
        "                 # Potentially update context for all listed products if needed, or just the action\n",
        "                 for pid, pdata in tool_result[\"products\"].items():\n",
        "                     self.conversation_context.update_entity_in_context(\"products\", pid, pdata)\n",
        "\n",
        "        self.conversation_context.set_last_action(tool_name, {\"input\": tool_input, \"result\": tool_result})\n",
        "\n",
        "\n",
        "    def process_tool_call(self, tool_name: str, tool_input: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        print(f\"--- [Tool Dispatcher] Attempting tool: {tool_name} with input: {json.dumps(tool_input, default=str)} ---\")\n",
        "        if tool_name in self.available_tool_functions:\n",
        "            function_to_call = self.available_tool_functions[tool_name]\n",
        "            try:\n",
        "                result = function_to_call(**tool_input)\n",
        "                print(f\"--- [Tool Dispatcher] Result for {tool_name}: {json.dumps(result, indent=2, default=str)} ---\")\n",
        "                return result\n",
        "            except TypeError as te:\n",
        "                print(f\"--- [Tool Dispatcher] TypeError for {tool_name}: {te}. Input: {tool_input} ---\")\n",
        "                return {\"status\": \"error\", \"message\": f\"TypeError calling {tool_name}: {str(te)}. Check arguments.\"}\n",
        "            except Exception as e:\n",
        "                print(f\"--- [Tool Dispatcher] Exception for {tool_name}: {e} ---\")\n",
        "                return {\"status\": \"error\", \"message\": f\"Error executing {tool_name}: {str(e)}\"}\n",
        "        else:\n",
        "            print(f\"--- [Tool Dispatcher] Tool {tool_name} not found. ---\")\n",
        "            return {\"status\": \"error\", \"message\": f\"Tool {tool_name} not found.\"}\n",
        "\n",
        "    def get_anthropic_response(self, current_worker_system_prompt: str, conversation_history: List[Dict[str, Any]]) -> str:\n",
        "        messages_for_api = conversation_history.copy()\n",
        "        try:\n",
        "            for i in range(5): # Max 5 tool iterations\n",
        "                # Prepare the system prompt snippet for safe inclusion in the f-string\n",
        "                system_prompt_snippet = current_worker_system_prompt[:60].replace('\\n', ' ')\n",
        "                print(f\"\\nAnthropic API Call #{i+1}. System: '{system_prompt_snippet}...', Messages count: {len(messages_for_api)}\")\n",
        "                if messages_for_api: print(f\"Last message role: {messages_for_api[-1]['role']}\")\n",
        "\n",
        "                response = anthropic_client.messages.create(\n",
        "                    model=ANTHROPIC_MODEL_NAME, max_tokens=4000,\n",
        "                    system=current_worker_system_prompt,\n",
        "                    tools=self.anthropic_tools_schemas, # Use Anthropic specific schemas\n",
        "                    messages=messages_for_api\n",
        "                )\n",
        "\n",
        "                assistant_response_blocks = response.content\n",
        "                messages_for_api.append({\"role\": \"assistant\", \"content\": assistant_response_blocks}) # Add assistant's turn (raw blocks)\n",
        "\n",
        "                tool_calls_to_process = [block for block in assistant_response_blocks if block.type == \"tool_use\"]\n",
        "                text_blocks = [block.text for block in assistant_response_blocks if block.type == \"text\"]\n",
        "\n",
        "                if not tool_calls_to_process:\n",
        "                    final_text = \" \".join(text_blocks).strip()\n",
        "                    print(f\"Anthropic Final Text (no tool use this turn): {final_text}\")\n",
        "                    return final_text if final_text else \"No text content in final Anthropic response.\"\n",
        "\n",
        "                tool_results_for_next_call = []\n",
        "                for tool_use_block in tool_calls_to_process:\n",
        "                    tool_name, tool_input, tool_use_id = tool_use_block.name, tool_use_block.input, tool_use_block.id\n",
        "                    print(f\"Anthropic Tool Call: {tool_name}, Input: {tool_input}\")\n",
        "                    tool_result_data = self.process_tool_call(tool_name, tool_input)\n",
        "                    self._update_context_from_tool_results(tool_name, tool_input, tool_result_data) # Update context here\n",
        "\n",
        "                    tool_results_for_next_call.append({\n",
        "                        \"type\": \"tool_result\", \"tool_use_id\": tool_use_id,\n",
        "                        \"content\": json.dumps(tool_result_data) # Anthropic expects content as string for tool_result\n",
        "                    })\n",
        "\n",
        "                messages_for_api.append({\"role\": \"user\", \"content\": tool_results_for_next_call}) # Add tool results as a user message\n",
        "\n",
        "            return \"Max tool iterations reached for Anthropic.\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error in get_anthropic_response: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return f\"Error getting Anthropic response: {str(e)}\"\n",
        "\n",
        "    def get_openai_response(self, current_worker_system_prompt: str, conversation_history: List[Dict[str, Any]]) -> str:\n",
        "        # OpenAI expects messages to be a list of dicts. System message is first.\n",
        "        # Assistant messages with tool_calls should be ChatCompletionMessage objects or dicts.\n",
        "\n",
        "        # Start with system prompt\n",
        "        messages_for_api = [{\"role\": \"system\", \"content\": current_worker_system_prompt}]\n",
        "\n",
        "        # Convert conversation history to OpenAI compatible format if necessary\n",
        "        for msg in conversation_history:\n",
        "            if msg[\"role\"] == \"assistant\" and isinstance(msg[\"content\"], list): # Anthropic's block list\n",
        "                # Convert Anthropic blocks to OpenAI's format if needed, or simplify\n",
        "                # For now, if it's a complex Anthropic response, we might simplify or log a warning\n",
        "                # This part is tricky because the history might contain Anthropic's response structure.\n",
        "                # For OpenAI, we should only feed it OpenAI-compatible history.\n",
        "                # This implies separate histories or a more complex conversion.\n",
        "                # For this iteration, let's assume history is generally compatible or needs filtering.\n",
        "\n",
        "                # A simple approach: if assistant message has tool_calls (OpenAI format), keep it.\n",
        "                # If it's Anthropic block list, try to extract text or tool calls.\n",
        "                # This is a simplification. True multi-vendor history management is complex.\n",
        "\n",
        "                # Let's assume `conversation_history` is being built turn by turn,\n",
        "                # and `add_assistant_message` stores the API-specific response object.\n",
        "                # The `get_full_conversation_for_api` in `ConversationContext` should ideally handle this.\n",
        "                # For now, let's just append, assuming `msg` is already somewhat compatible.\n",
        "                messages_for_api.append(msg)\n",
        "\n",
        "            else: # User messages or simple assistant text messages\n",
        "                 messages_for_api.append(msg)\n",
        "\n",
        "\n",
        "        try:\n",
        "            for i in range(5): # Max 5 tool iterations\n",
        "                print(f\"\\nOpenAI API Call #{i+1}. Messages count: {len(messages_for_api)}\")\n",
        "                if messages_for_api: print(f\"Last message role: {messages_for_api[-1].get('role') if isinstance(messages_for_api[-1], dict) else 'N/A'}\")\n",
        "\n",
        "                response = openai_client.chat.completions.create(\n",
        "                    model=OPENAI_MODEL_NAME,\n",
        "                    messages=messages_for_api,\n",
        "                    tools=self.openai_tools_formatted, # Use pre-formatted tools for OpenAI\n",
        "                    tool_choice=\"auto\"\n",
        "                )\n",
        "                response_message = response.choices[0].message\n",
        "                # print(f\"OpenAI Raw Response Message object: {response_message}\")\n",
        "\n",
        "                # Add assistant's response (which might include tool_calls) to messages_for_api\n",
        "                # Convert Pydantic model to dict for consistent history storage if preferred\n",
        "                messages_for_api.append(response_message.model_dump())\n",
        "\n",
        "\n",
        "                if not response_message.tool_calls:\n",
        "                    final_text = response_message.content if response_message.content else \"No text content in final OpenAI response.\"\n",
        "                    print(f\"OpenAI Final Text (no tool use this turn): {final_text}\")\n",
        "                    return final_text\n",
        "\n",
        "                tool_calls_for_next_api_call = []\n",
        "                for tool_call in response_message.tool_calls:\n",
        "                    tool_name = tool_call.function.name\n",
        "                    tool_input_str = tool_call.function.arguments\n",
        "                    tool_call_id = tool_call.id\n",
        "                    try:\n",
        "                        tool_input = json.loads(tool_input_str)\n",
        "                    except json.JSONDecodeError:\n",
        "                        print(f\"OpenAI Tool Call JSON Error for {tool_name}: {tool_input_str}\")\n",
        "                        tool_result_data = {\"status\": \"error\", \"message\": \"Invalid JSON arguments from model.\"}\n",
        "                    else:\n",
        "                        print(f\"OpenAI Tool Call: {tool_name}, Input: {tool_input}\")\n",
        "                        tool_result_data = self.process_tool_call(tool_name, tool_input)\n",
        "\n",
        "                    self._update_context_from_tool_results(tool_name, tool_input, tool_result_data) # Update context\n",
        "\n",
        "                    tool_calls_for_next_api_call.append({\n",
        "                        \"tool_call_id\": tool_call_id, \"role\": \"tool\", \"name\": tool_name,\n",
        "                        \"content\": json.dumps(tool_result_data) # Result must be a string\n",
        "                    })\n",
        "\n",
        "                messages_for_api.extend(tool_calls_for_next_api_call) # Add all tool results for next iteration\n",
        "\n",
        "            return \"Max tool iterations reached for OpenAI.\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error in get_openai_response: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return f\"Error getting OpenAI response: {str(e)}\"\n",
        "\n",
        "    def process_user_request(self, user_message: str) -> Dict[str, Any]:\n",
        "        print(f\"\\n\\n{'='*60}\\nUser Message: {user_message}\\n{'='*60}\")\n",
        "        self.conversation_context.add_user_message(user_message)\n",
        "\n",
        "        context_summary = self.conversation_context.get_context_summary()\n",
        "        print(f\"Current Context Summary for Models:\\n{context_summary}\\n{'-'*60}\")\n",
        "\n",
        "        current_worker_prompt_with_context = f\"{worker_system_prompt}\\n\\nConversation Context:\\n{context_summary}\"\n",
        "\n",
        "        # Get a clean copy of history for each LLM to avoid contamination from other LLM's specific message formats\n",
        "        # This is a simplified approach. A more robust system might have distinct history tracking or conversion.\n",
        "        # For now, `get_full_conversation_for_api` provides the base.\n",
        "        # The LLM-specific methods will prepend their system messages.\n",
        "\n",
        "        anthropic_history_for_call = self.conversation_context.get_full_conversation_for_api()\n",
        "        anthropic_response_text = self.get_anthropic_response(current_worker_prompt_with_context, anthropic_history_for_call)\n",
        "        # The get_anthropic_response method itself now appends its turns to its local `messages_for_api`.\n",
        "        # We need to decide how to update the shared `self.conversation_context.messages`.\n",
        "        # For now, we add a simplified text summary.\n",
        "        self.conversation_context.add_assistant_message(f\"[Anthropic Final Text]: {anthropic_response_text}\")\n",
        "\n",
        "\n",
        "        openai_history_for_call = self.conversation_context.get_full_conversation_for_api()\n",
        "        openai_response_text = self.get_openai_response(current_worker_prompt_with_context, openai_history_for_call)\n",
        "        self.conversation_context.add_assistant_message(f\"[OpenAI Final Text]: {openai_response_text}\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Anthropic Final Response Text ---\\n{anthropic_response_text}\")\n",
        "        print(f\"--- OpenAI Final Response Text ---\\n{openai_response_text}\")\n",
        "\n",
        "        evaluation = self.evaluate_responses(user_message, anthropic_response_text, openai_response_text, context_summary)\n",
        "        self.evaluation_results.append(evaluation)\n",
        "\n",
        "        return {\n",
        "            \"user_message\": user_message,\n",
        "            \"anthropic_response\": anthropic_response_text,\n",
        "            \"openai_response\": openai_response_text,\n",
        "            \"evaluation\": evaluation\n",
        "        }\n",
        "\n",
        "    def process_human_feedback_actions(self, feedback: str) -> str:\n",
        "        \"\"\"Process any action commands in human feedback and execute them.\"\"\"\n",
        "        action_result = \"\"\n",
        "\n",
        "        # Look for data modification commands with a structured format\n",
        "        # Example patterns:\n",
        "        # \"Update order O2 status to Shipped\"\n",
        "        # \"Create new product: Gizmo X, description: A fancy gizmo, price: 29.99, inventory: 50\"\n",
        "        # \"Update product P1 price to 24.99\"\n",
        "\n",
        "        # Order updates\n",
        "        order_update_match = re.search(r\"update\\s+order\\s+(\\w+)\\s+status\\s+to\\s+(\\w+)\", feedback, re.IGNORECASE)\n",
        "        if order_update_match:\n",
        "            order_id, new_status = order_update_match.groups()\n",
        "            try:\n",
        "                result = self.process_tool_call(\"update_order_status\", {\"order_id\": order_id, \"new_status\": new_status})\n",
        "                action_result = f\"Action executed: Updated order {order_id} status to {new_status}. Result: {result['status']}\"\n",
        "            except Exception as e:\n",
        "                action_result = f\"Failed to update order {order_id}: {str(e)}\"\n",
        "\n",
        "        # Product creation\n",
        "        product_create_match = re.search(\n",
        "            r\"create\\s+(?:new\\s+)?product:\\s+(.*?),\\s*description:\\s*(.*?),\\s*price:\\s*(\\d+\\.?\\d*),\\s*inventory:\\s*(\\d+)\",\n",
        "            feedback,\n",
        "            re.IGNORECASE\n",
        "        )\n",
        "        if product_create_match:\n",
        "            name, desc, price, inventory = product_create_match.groups()\n",
        "            try:\n",
        "                result = self.process_tool_call(\"create_product\", {\n",
        "                    \"name\": name.strip(),\n",
        "                    \"description\": desc.strip(),\n",
        "                    \"price\": float(price),\n",
        "                    \"inventory_count\": int(inventory)\n",
        "                })\n",
        "                action_result = f\"Action executed: Created product '{name}'. Result: {result['status']}\"\n",
        "            except Exception as e:\n",
        "                action_result = f\"Failed to create product '{name}': {str(e)}\"\n",
        "\n",
        "        # Add more patterns for other actions as needed\n",
        "\n",
        "        return action_result\n",
        "\n",
        "    def evaluate_responses(self, user_message: str, anthropic_response: str, openai_response: str, context_summary_for_eval: str) -> Dict[str, Any]:\n",
        "        print(\"\\n--- Starting Evaluation by Gemini ---\")\n",
        "        try:\n",
        "            # Prepare ground truth data from the global 'storage' instance\n",
        "            ground_truth_customers = json.dumps(storage.customers, indent=2, default=str)\n",
        "            ground_truth_products = json.dumps(storage.products, indent=2, default=str)\n",
        "            ground_truth_orders = json.dumps(storage.orders, indent=2, default=str)\n",
        "\n",
        "            ground_truth_section = f\"\"\"\n",
        "                Ground Truth E-commerce Data:\n",
        "                Customers:\n",
        "                {ground_truth_customers}\n",
        "\n",
        "                Products:\n",
        "                {ground_truth_products}\n",
        "\n",
        "                Orders:\n",
        "                {ground_truth_orders}\n",
        "                \"\"\"\n",
        "            eval_prompt_parts = [\n",
        "                f\"User query: {user_message}\",\n",
        "                f\"Current context provided to assistants:\\n{context_summary_for_eval}\", # This is the summary *before* the current turn's responses\n",
        "                f\"Anthropic Claude response:\\n{anthropic_response}\",\n",
        "                f\"OpenAI GPT response:\\n{openai_response}\",\n",
        "                \"Please evaluate both responses based on accuracy, efficiency, context awareness, and helpfulness. Provide an overall score (1-10) for each. If ambiguity required human clarification, note it.\"\n",
        "            ]\n",
        "            relevant_learnings = self.check_relevant_learnings(user_message)\n",
        "            if relevant_learnings:\n",
        "                eval_prompt_parts.append(f\"\\nRelevant past learnings from similar situations:\\n{relevant_learnings}\")\n",
        "\n",
        "            eval_prompt = \"\\n\\n\".join(eval_prompt_parts)\n",
        "            # print(f\"Gemini Eval Prompt (first 300 chars): {eval_prompt[:300]}...\")\n",
        "\n",
        "            gemini_response_obj = eval_model_instance.generate_content(eval_prompt)\n",
        "            evaluation_text = gemini_response_obj.text\n",
        "            print(f\"Gemini Raw Evaluation:\\n{evaluation_text}\")\n",
        "\n",
        "            needs_human_input = \"human clarification\" in evaluation_text.lower() or \"admin user\" in evaluation_text.lower()\n",
        "            clarification_details = {\"used\": False, \"needed\": \"\", \"provided_input\": \"\"}\n",
        "\n",
        "            if needs_human_input:\n",
        "                clarification_details[\"used\"] = True\n",
        "                clarification_details[\"needed\"] = self.extract_clarification_needed(evaluation_text)\n",
        "                print(f\"--- Human Clarification Indicated by Evaluator ---\")\n",
        "                print(f\"Clarification needed by evaluator: {clarification_details['needed']}\")\n",
        "                try:\n",
        "                    human_input_for_eval = input(f\"Enter human clarification for evaluator (or type 'skip' or 'quit'): \")\n",
        "                    if human_input_for_eval.lower() in ['quit', 'exit', 'stop', 'q']:\n",
        "                        print(\"Exiting the system. Goodbye!\")\n",
        "                        raise SystemExit(\"User requested exit during evaluation\")\n",
        "\n",
        "                    elif human_input_for_eval.lower() != 'skip':\n",
        "                        clarification_details[\"provided_input\"] = human_input_for_eval\n",
        "\n",
        "                        # Process any action commands in the human feedback\n",
        "                        action_result = self.process_human_feedback_actions(human_input_for_eval)\n",
        "                        if action_result:\n",
        "                            print(f\"--- Action Result ---\\n{action_result}\")\n",
        "                            # Include the action result in the feedback to the evaluator\n",
        "                            human_input_with_action = f\"{human_input_for_eval}\\n\\nSystem executed action: {action_result}\"\n",
        "                            clarification_details[\"provided_input\"] = human_input_with_action\n",
        "                        else:\n",
        "                            clarification_details[\"provided_input\"] = human_input_for_eval\n",
        "\n",
        "                        self.store_learning(user_message, clarification_details[\"needed\"], clarification_details[\"provided_input\"])\n",
        "                        updated_eval_prompt = f\"{eval_prompt}\\n\\nHuman clarification provided to evaluator: {clarification_details['provided_input']}\"\n",
        "                        updated_gemini_response = eval_model_instance.generate_content(updated_eval_prompt)\n",
        "                        evaluation_text = updated_gemini_response.text\n",
        "                        print(f\"Gemini Raw Re-Evaluation:\\n{evaluation_text}\")\n",
        "                    else:\n",
        "                        print(\"Skipping human input for evaluator.\")\n",
        "                except EOFError:\n",
        "                    print(\"EOFError: Skipping human clarification for evaluator (non-interactive).\")\n",
        "                    clarification_details[\"provided_input\"] = \"Skipped (non-interactive)\"\n",
        "\n",
        "            anthropic_score = self.extract_score(evaluation_text, \"Anthropic\")\n",
        "            openai_score = self.extract_score(evaluation_text, \"OpenAI\")\n",
        "\n",
        "            return {\n",
        "                \"anthropic_score\": anthropic_score, \"openai_score\": openai_score,\n",
        "                \"full_evaluation\": evaluation_text, \"clarification_details\": clarification_details\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error in evaluation: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return {\n",
        "                \"error\": f\"Error in evaluation: {str(e)}\",\n",
        "                \"anthropic_score\": 0, \"openai_score\": 0,\n",
        "                \"full_evaluation\": f\"Evaluation failed: {str(e)}\",\n",
        "                \"clarification_details\": {\"used\": False}\n",
        "            }\n",
        "\n",
        "    def extract_clarification_needed(self, evaluation_text: str) -> str:\n",
        "        # First look for the explicit format we asked for in the system prompt\n",
        "        clarification_match = re.search(r\"CLARIFICATION NEEDED:\\s*(.*?)(?:\\n|$)\", evaluation_text, re.IGNORECASE)\n",
        "        if clarification_match and clarification_match.group(1).strip():\n",
        "            return clarification_match.group(1).strip()\n",
        "\n",
        "        # Look for other common patterns\n",
        "        patterns = [\n",
        "            r\"Clearly state what information is needed:\\s*(.*?)(?:\\s*Ask an admin user|$)\",\n",
        "            r\"Information needed[:\\s]+(.*?)(?:\\n\\n|\\n(?=[A-Z])|$)\",\n",
        "            r\"(?:clarification|ambiguity)[^.!?]*?(?:needed|required)[^.!?]*?:\\s*(.*?)(?:\\n\\n|\\n(?=[A-Z])|$)\"\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, evaluation_text, re.DOTALL | re.IGNORECASE)\n",
        "            if match and match.group(1).strip():\n",
        "                return match.group(1).strip()\n",
        "\n",
        "        # If no pattern matches, scan for sections that might contain a question\n",
        "        lines = evaluation_text.split('\\n')\n",
        "        for i, line in enumerate(lines):\n",
        "            keywords = [\"clarification\", \"ambiguity\", \"unclear\", \"information needed\", \"admin\", \"human input\"]\n",
        "            if any(keyword in line.lower() for keyword in keywords):\n",
        "                # Look for the first question mark after this line\n",
        "                for j in range(i, min(i + 5, len(lines))):\n",
        "                    if '?' in lines[j]:\n",
        "                        question_end = lines[j].find('?') + 1\n",
        "                        return lines[j][:question_end].strip()\n",
        "                # If no question mark, return a few lines for context\n",
        "                return \"\\n\".join(lines[i:min(i + 3, len(lines))]).strip()\n",
        "\n",
        "        # Last resort\n",
        "        return \"The evaluator indicated clarification is needed but didn't specify a clear question. Please review the evaluation and provide any insights that might help improve the assessment.\"\n",
        "\n",
        "    def store_learning(self, query: str, clarification_needed: str, human_input: str):\n",
        "        keywords = self.extract_keywords(query)\n",
        "        for keyword in keywords:\n",
        "            if keyword not in self.human_feedback_learnings:\n",
        "                self.human_feedback_learnings[keyword] = []\n",
        "            self.human_feedback_learnings[keyword].append({\n",
        "                \"original_query\": query,\n",
        "                \"clarification_needed_by_evaluator\": clarification_needed,\n",
        "                \"human_input_for_evaluator\": human_input,\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            })\n",
        "        print(f\"Learning stored for query keywords: {keywords}\")\n",
        "\n",
        "    def check_relevant_learnings(self, query: str) -> Optional[str]:\n",
        "        keywords = self.extract_keywords(query)\n",
        "        relevant_learnings_text = []\n",
        "        for keyword in keywords:\n",
        "            if keyword in self.human_feedback_learnings:\n",
        "                for learning in self.human_feedback_learnings[keyword]:\n",
        "                    relevant_learnings_text.append(\n",
        "                        f\"- Query context: '{learning['original_query']}'\\n\"\n",
        "                        f\"  Clarification needed: {learning['clarification_needed_by_evaluator']}\\n\"\n",
        "                        f\"  Provided input: {learning['human_input_for_evaluator']}\"\n",
        "                    )\n",
        "        return \"\\n\\n\".join(relevant_learnings_text) if relevant_learnings_text else None\n",
        "\n",
        "    def extract_keywords(self, text: str) -> List[str]:\n",
        "        words = re.findall(r'\\b\\w{4,}\\b', text.lower())\n",
        "        stop_words = {\"the\", \"and\", \"is\", \"in\", \"to\", \"a\", \"of\", \"for\", \"with\", \"on\", \"at\", \"what\", \"how\", \"show\", \"tell\", \"please\", \"what's\", \"i'd\"}\n",
        "        return list(set(word for word in words if word not in stop_words))\n",
        "\n",
        "    def extract_score(self, evaluation_text: str, model_name_pattern: str) -> int:\n",
        "        patterns = [\n",
        "            rf\"{model_name_pattern}.*?Overall Score.*?(\\d+)/10\",  # Anthropic Overall Score: 8/10\n",
        "            rf\"{model_name_pattern}.*?Overall Score:\\s*(\\d+)\",     # Anthropic Overall Score: 8\n",
        "            rf\"Overall Score.*?{model_name_pattern}.*?:\\s*(\\d+)\", # Overall Score (Anthropic): 8\n",
        "            rf\"{model_name_pattern}.*?score.*?:.*?(\\d+)\",          # Anthropic score: 8\n",
        "            rf\"{model_name_pattern}.*?\\b(\\d+)/10\",                 # Anthropic 8/10\n",
        "            rf\"{model_name_pattern}.*?\\bscore\\b.*?(\\d+)\",          # Anthropic ... score ... 8\n",
        "        ]\n",
        "        for p_str in patterns:\n",
        "            match = re.search(p_str, evaluation_text, re.IGNORECASE | re.DOTALL)\n",
        "            if match and match.group(1):\n",
        "                try: return int(match.group(1))\n",
        "                except ValueError: continue\n",
        "\n",
        "        # Fallback: find model name, then nearest number after \"score\" or just a number near model name\n",
        "        model_name_lower = model_name_pattern.lower()\n",
        "        text_lower = evaluation_text.lower()\n",
        "        model_indices = [m.start() for m in re.finditer(model_name_lower, text_lower)]\n",
        "\n",
        "        for model_idx in model_indices:\n",
        "            search_area = evaluation_text[model_idx : model_idx + 100] # Search 100 chars around model name\n",
        "            score_match = re.search(r'\\b(\\d+)\\b(?:/10)?', search_area, re.IGNORECASE) # Look for a number, optionally like X/10\n",
        "            if score_match:\n",
        "                try: return int(score_match.group(1))\n",
        "                except ValueError: pass\n",
        "\n",
        "        print(f\"Could not extract score for '{model_name_pattern}' from eval text snippet:\\n{evaluation_text[:250]}...\")\n",
        "        return 0\n",
        "\n",
        "print(\"DualAgentEvaluator class defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzLHm8MmSOMC",
        "outputId": "2d8cbcd0-94f9-4772-ad88-c41c6dceb96f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DualAgentEvaluator class defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Sample queries:\n",
        "* Show me all the products available\n",
        "* I'd like to order 10 Perplexinators, please\n",
        "* Show me the status of my order\n",
        "* (If the order is not in Shipped state, then) Please ship my order now\n",
        "* How many Perplexinators are now left in stock?\n",
        "* Add a new customer: Bill Leece, bill.leece@mail.com, +1.222.333.4444\n",
        "* Add new new product: Gizmo X, description: A fancy gizmo, price: 29.99, inventory: 50\n",
        "* Update Gizzmo's price to 99.99\n",
        "* I need to update our insurance policy, so I need to know the total value of everything that I have in our inventory. Please tell me this amount.\n",
        "* Summarize your learnings from our recent interactions.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"\\nStarting Main Execution...\\n\")\n",
        "    if any(k in globals() and \"YOUR_\" in globals()[k] for k in [\"ANTHROPIC_API_KEY\", \"OPENAI_API_KEY\", \"GOOGLE_API_KEY\"]):\n",
        "        print(\"ERROR: Placeholder API keys detected. Update in Cell 2 (UserDataMock) or environment. Exiting.\")\n",
        "        return\n",
        "\n",
        "    agent = DualAgentEvaluator()\n",
        "    results_log = []\n",
        "    # Accept user input queries\n",
        "    while True:\n",
        "        try:\n",
        "            user_query = input(\"\\nEnter your query (or 'quit', 'exit', 'stop' to end): \")\n",
        "            if user_query.lower() in ['quit', 'exit', 'stop', 'q']:\n",
        "                print(\"Exiting the system. Goodbye!\")\n",
        "                break\n",
        "\n",
        "            result = agent.process_user_request(user_query)\n",
        "            results_log.append(result)\n",
        "        except Exception as e:\n",
        "            print(f\"CRITICAL ERROR processing query '{user_query}': {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            results_log.append({\n",
        "                \"user_message\": user_query, \"anthropic_response\": \"ERROR\", \"openai_response\": \"ERROR\",\n",
        "                \"evaluation\": {\"anthropic_score\": 0, \"openai_score\": 0, \"full_evaluation\": f\"Critical error: {e}\", \"clarification_details\": {\"used\": False}}\n",
        "            })\n",
        "\n",
        "    print(\"\\n\\n===== EVALUATION SUMMARY =====\")\n",
        "    total_anthropic, total_openai, num_q = 0, 0, len(results_log)\n",
        "    for i, res in enumerate(results_log):\n",
        "        print(f\"\\nQuery {i+1}: {res['user_message']}\")\n",
        "        print(f\"  Anthropic Resp: {res['anthropic_response'][:100]}...\")\n",
        "        print(f\"  OpenAI Resp: {res['openai_response'][:100]}...\")\n",
        "\n",
        "        eval_data = res['evaluation']\n",
        "        anth_s, open_s = eval_data.get('anthropic_score',0), eval_data.get('openai_score',0)\n",
        "        total_anthropic += anth_s; total_openai += open_s\n",
        "        print(f\"  Scores - Anthropic: {anth_s}, OpenAI: {open_s}\")\n",
        "        if eval_data.get('clarification_details',{}).get('used'):\n",
        "            print(f\"    Clarification: Needed='{eval_data['clarification_details']['needed']}', Provided='{eval_data['clarification_details']['provided_input']}'\")\n",
        "        winner = \"Tie\" if anth_s == open_s else (\"Anthropic\" if anth_s > open_s else \"OpenAI\")\n",
        "        print(f\"  Query Winner: {winner}\")\n",
        "\n",
        "    print(f\"\\n----- Overall Performance -----\")\n",
        "    if num_q > 0:\n",
        "        print(f\"Avg Anthropic: {total_anthropic/num_q:.2f}, Avg OpenAI: {total_openai/num_q:.2f}\")\n",
        "    print(f\"Total Anthropic: {total_anthropic}, Total OpenAI: {total_openai}\")\n",
        "    overall_winner = \"Tie\" if total_anthropic == total_openai else (\"Anthropic\" if total_anthropic > total_openai else \"OpenAI\")\n",
        "    print(f\"Overall Winner: {overall_winner}\")\n",
        "\n",
        "    if agent.human_feedback_learnings:\n",
        "        print(\"\\n----- Learned Clarifications (for Evaluator) -----\")\n",
        "        for kw, l_list in agent.human_feedback_learnings.items():\n",
        "            print(f\"Keyword: {kw}\")\n",
        "            for item in l_list: print(f\"  - Q: '{item['original_query']}', Needed: {item['clarification_needed_by_evaluator']}, Input: {item['human_input_for_evaluator']}\")\n",
        "    print(\"\\nExecution Finished.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # In Jupyter, call main() in a new cell.\n",
        "    # For direct script execution:\n",
        "    # main()\n",
        "    pass\n",
        "\n",
        "print(\"Main function defined. Call main() in a new cell to run the evaluation.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Main function defined. Call main() in a new cell to run the evaluation.\n"
          ]
        }
      ],
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2-ztJ2BO7gD",
        "outputId": "bfb3395a-da91-47d8-bd6c-1bc3e150c717"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dg85ek6bSvW5",
        "outputId": "7362bea3-a394-4ca3-9091-f3ce33c51fd9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Main Execution...\n",
            "\n",
            "DualAgentEvaluator initialized. OpenAI tools formatted.\n",
            "\n",
            "Enter your query (or 'quit', 'exit', 'stop' to end): Show me all the products available\n",
            "\n",
            "\n",
            "============================================================\n",
            "User Message: Show me all the products available\n",
            "============================================================\n",
            "Current Context Summary for Models:\n",
            "No specific context items set yet.\n",
            "------------------------------------------------------------\n",
            "\n",
            "Anthropic API Call #1. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 1\n",
            "Last message role: user\n",
            "Anthropic Tool Call: list_all_products, Input: {}\n",
            "--- [Tool Dispatcher] Attempting tool: list_all_products with input: {} ---\n",
            "[Tool Executed] list_all_products: Found 3 products.\n",
            "--- [Tool Dispatcher] Result for list_all_products: {\n",
            "  \"status\": \"success\",\n",
            "  \"count\": 3,\n",
            "  \"products\": {\n",
            "    \"P1\": {\n",
            "      \"name\": \"Widget A\",\n",
            "      \"description\": \"A simple widget. Very compact.\",\n",
            "      \"price\": 19.99,\n",
            "      \"inventory_count\": 999\n",
            "    },\n",
            "    \"P2\": {\n",
            "      \"name\": \"Gadget B\",\n",
            "      \"description\": \"A powerful gadget. It spins.\",\n",
            "      \"price\": 49.99,\n",
            "      \"inventory_count\": 200\n",
            "    },\n",
            "    \"P3\": {\n",
            "      \"name\": \"Perplexinator\",\n",
            "      \"description\": \"A perplexing perfunctator\",\n",
            "      \"price\": 79.99,\n",
            "      \"inventory_count\": 1483\n",
            "    }\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: products, ID: P1, Data (type): <class 'dict'>\n",
            "[Context Updated] Entity: products, ID: P2, Data (type): <class 'dict'>\n",
            "[Context Updated] Entity: products, ID: P3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: list_all_products, Details: {\"input\": {}, \"result\": {\"status\": \"success\", \"count\": 3, \"products\": {\"P1\": {\"name\": \"Widget A\", \"description\": \"A simple widget. Very compact.\", \"price\": 19.99, \"inventory_count\": 999}, \"P2\": {\"name\": \"Gadget B\", \"description\": \"A powerful gadget. It spins.\", \"price\": 49.99, \"inventory_count\": 200}, \"P3\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1483}}}}\n",
            "\n",
            "Anthropic API Call #2. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 3\n",
            "Last message role: user\n",
            "Anthropic Final Text (no tool use this turn): Here are all the products currently available in our inventory:\n",
            "\n",
            "1. Widget A - $19.99 (999 in stock)\n",
            "   Description: A simple widget. Very compact.\n",
            "\n",
            "2. Gadget B - $49.99 (200 in stock)\n",
            "   Description: A powerful gadget. It spins.\n",
            "\n",
            "3. Perplexinator - $79.99 (1,483 in stock)\n",
            "   Description: A perplexing perfunctator\n",
            "\n",
            "All products are currently in stock. Would you like more detailed information about any specific product?\n",
            "\n",
            "OpenAI API Call #1. Messages count: 3\n",
            "Last message role: assistant\n",
            "OpenAI Tool Call: list_all_products, Input: {}\n",
            "--- [Tool Dispatcher] Attempting tool: list_all_products with input: {} ---\n",
            "[Tool Executed] list_all_products: Found 3 products.\n",
            "--- [Tool Dispatcher] Result for list_all_products: {\n",
            "  \"status\": \"success\",\n",
            "  \"count\": 3,\n",
            "  \"products\": {\n",
            "    \"P1\": {\n",
            "      \"name\": \"Widget A\",\n",
            "      \"description\": \"A simple widget. Very compact.\",\n",
            "      \"price\": 19.99,\n",
            "      \"inventory_count\": 999\n",
            "    },\n",
            "    \"P2\": {\n",
            "      \"name\": \"Gadget B\",\n",
            "      \"description\": \"A powerful gadget. It spins.\",\n",
            "      \"price\": 49.99,\n",
            "      \"inventory_count\": 200\n",
            "    },\n",
            "    \"P3\": {\n",
            "      \"name\": \"Perplexinator\",\n",
            "      \"description\": \"A perplexing perfunctator\",\n",
            "      \"price\": 79.99,\n",
            "      \"inventory_count\": 1483\n",
            "    }\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: products, ID: P1, Data (type): <class 'dict'>\n",
            "[Context Updated] Entity: products, ID: P2, Data (type): <class 'dict'>\n",
            "[Context Updated] Entity: products, ID: P3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: list_all_products, Details: {\"input\": {}, \"result\": {\"status\": \"success\", \"count\": 3, \"products\": {\"P1\": {\"name\": \"Widget A\", \"description\": \"A simple widget. Very compact.\", \"price\": 19.99, \"inventory_count\": 999}, \"P2\": {\"name\": \"Gadget B\", \"description\": \"A powerful gadget. It spins.\", \"price\": 49.99, \"inventory_count\": 200}, \"P3\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1483}}}}\n",
            "\n",
            "OpenAI API Call #2. Messages count: 5\n",
            "Last message role: tool\n",
            "OpenAI Final Text (no tool use this turn): Here are all the products currently available in our inventory:\n",
            "\n",
            "1. Widget A - $19.99 (999 in stock)\n",
            "   Description: A simple widget. Very compact.\n",
            "\n",
            "2. Gadget B - $49.99 (200 in stock)\n",
            "   Description: A powerful gadget. It spins.\n",
            "\n",
            "3. Perplexinator - $79.99 (1,483 in stock)\n",
            "   Description: A perplexing perfunctator\n",
            "\n",
            "Let me know if you'd like more details or want to place an order for any of these products!\n",
            "\n",
            "--- Anthropic Final Response Text ---\n",
            "Here are all the products currently available in our inventory:\n",
            "\n",
            "1. Widget A - $19.99 (999 in stock)\n",
            "   Description: A simple widget. Very compact.\n",
            "\n",
            "2. Gadget B - $49.99 (200 in stock)\n",
            "   Description: A powerful gadget. It spins.\n",
            "\n",
            "3. Perplexinator - $79.99 (1,483 in stock)\n",
            "   Description: A perplexing perfunctator\n",
            "\n",
            "All products are currently in stock. Would you like more detailed information about any specific product?\n",
            "--- OpenAI Final Response Text ---\n",
            "Here are all the products currently available in our inventory:\n",
            "\n",
            "1. Widget A - $19.99 (999 in stock)\n",
            "   Description: A simple widget. Very compact.\n",
            "\n",
            "2. Gadget B - $49.99 (200 in stock)\n",
            "   Description: A powerful gadget. It spins.\n",
            "\n",
            "3. Perplexinator - $79.99 (1,483 in stock)\n",
            "   Description: A perplexing perfunctator\n",
            "\n",
            "Let me know if you'd like more details or want to place an order for any of these products!\n",
            "\n",
            "--- Starting Evaluation by Gemini ---\n",
            "Gemini Raw Evaluation:\n",
            "Okay, I will evaluate both responses.\n",
            "\n",
            "**Anthropic Claude Response Evaluation:**\n",
            "\n",
            "*   **Accuracy:** 10/10\n",
            "    *   The response provides a list of products with prices, stock levels, and descriptions, which appears to be accurate based on the information presented.\n",
            "*   **Efficiency:** 10/10\n",
            "    *   The assistant directly answered the query without any clarifying questions.\n",
            "*   **Context Awareness:** 10/10\n",
            "    *   No specific context was provided, and the assistant correctly understood the general request.\n",
            "*   **Helpfulness:** 10/10\n",
            "    *   The response clearly lists the products and offers further assistance for more detailed information, which is helpful.\n",
            "\n",
            "*   **Overall Score:** 10/10\n",
            "\n",
            "**OpenAI GPT Response Evaluation:**\n",
            "\n",
            "*   **Accuracy:** 10/10\n",
            "    *   The response provides the same list of products with prices, stock levels, and descriptions as Claude, which appears to be accurate.\n",
            "*   **Efficiency:** 10/10\n",
            "    *   The assistant directly answered the query without any clarifying questions.\n",
            "*   **Context Awareness:** 10/10\n",
            "    *   No specific context was provided, and the assistant correctly understood the general request.\n",
            "*   **Helpfulness:** 10/10\n",
            "    *   The response clearly lists the products and offers further assistance for more details or placing an order, which is helpful and proactive.\n",
            "\n",
            "*   **Overall Score:** 10/10\n",
            "\n",
            "Both assistants performed excellently and provided nearly identical, high-quality responses. No clarification was needed for this query.\n",
            "\n",
            "Enter your query (or 'quit', 'exit', 'stop' to end):  I'd like to order 10 Perplexinators, please\n",
            "\n",
            "\n",
            "============================================================\n",
            "User Message:  I'd like to order 10 Perplexinators, please\n",
            "============================================================\n",
            "Current Context Summary for Models:\n",
            "Recent products: ID: P1 (Name: Widget A), ID: P2 (Name: Gadget B), ID: P3 (Name: Perplexinator)\n",
            "Last action: list_all_products at 2025-05-16T17:53:35.646950 (Input: {}, Result Status: success)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Anthropic API Call #1. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 4\n",
            "Last message role: user\n",
            "Anthropic Tool Call: create_order, Input: {'product_id_or_name': 'Perplexinator', 'quantity': 10, 'status': 'Processing'}\n",
            "--- [Tool Dispatcher] Attempting tool: create_order with input: {\"product_id_or_name\": \"Perplexinator\", \"quantity\": 10, \"status\": \"Processing\"} ---\n",
            "[Tool Helper] find_product_by_name: Matched 'Perplexinator' to 'Perplexinator' (ID: P3) with score 100\n",
            "[Tool Executed] create_order: Order O3 created for 10 of Perplexinator (ID: P3). Status: Processing. Remaining inv: 1483\n",
            "--- [Tool Dispatcher] Result for create_order: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O3\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O3\",\n",
            "    \"product_id\": \"P3\",\n",
            "    \"product_name\": \"Perplexinator\",\n",
            "    \"quantity\": 10,\n",
            "    \"price\": 79.99,\n",
            "    \"status\": \"Processing\"\n",
            "  },\n",
            "  \"remaining_inventory\": 1483\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: create_order, Details: {\"input\": {\"product_id_or_name\": \"Perplexinator\", \"quantity\": 10, \"status\": \"Processing\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O3\", \"order_details\": {\"id\": \"O3\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 10, \"price\": 79.99, \"status\": \"Processing\"}, \"remaining_inventory\": 1483}}\n",
            "\n",
            "Anthropic API Call #2. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 6\n",
            "Last message role: user\n",
            "Anthropic Final Text (no tool use this turn): Great! I've created your order for 10 Perplexinators. Here's a summary of your order:\n",
            "- Order ID: O3\n",
            "- Product: Perplexinator\n",
            "- Quantity: 10\n",
            "- Price per unit: $79.99\n",
            "- Total price: $799.90\n",
            "- Status: Processing\n",
            "\n",
            "Your order has been successfully placed and is being processed. Would you like me to help you with anything else?\n",
            "\n",
            "OpenAI API Call #1. Messages count: 6\n",
            "Last message role: assistant\n",
            "OpenAI Tool Call: create_order, Input: {'product_id_or_name': 'Perplexinator', 'quantity': 10, 'status': 'Processing'}\n",
            "--- [Tool Dispatcher] Attempting tool: create_order with input: {\"product_id_or_name\": \"Perplexinator\", \"quantity\": 10, \"status\": \"Processing\"} ---\n",
            "[Tool Helper] find_product_by_name: Matched 'Perplexinator' to 'Perplexinator' (ID: P3) with score 100\n",
            "[Tool Executed] create_order: Order O4 created for 10 of Perplexinator (ID: P3). Status: Processing. Remaining inv: 1483\n",
            "--- [Tool Dispatcher] Result for create_order: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O4\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O4\",\n",
            "    \"product_id\": \"P3\",\n",
            "    \"product_name\": \"Perplexinator\",\n",
            "    \"quantity\": 10,\n",
            "    \"price\": 79.99,\n",
            "    \"status\": \"Processing\"\n",
            "  },\n",
            "  \"remaining_inventory\": 1483\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O4, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: create_order, Details: {\"input\": {\"product_id_or_name\": \"Perplexinator\", \"quantity\": 10, \"status\": \"Processing\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O4\", \"order_details\": {\"id\": \"O4\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 10, \"price\": 79.99, \"status\": \"Processing\"}, \"remaining_inventory\": 1483}}\n",
            "\n",
            "OpenAI API Call #2. Messages count: 8\n",
            "Last message role: tool\n",
            "OpenAI Final Text (no tool use this turn): Your order for 10 Perplexinators has been placed and is now processing.\n",
            "\n",
            "Order details:\n",
            "- Product: Perplexinator\n",
            "- Quantity: 10\n",
            "- Status: Processing\n",
            "\n",
            "If you need further details about your order or want to place another order, just let me know!\n",
            "\n",
            "--- Anthropic Final Response Text ---\n",
            "Great! I've created your order for 10 Perplexinators. Here's a summary of your order:\n",
            "- Order ID: O3\n",
            "- Product: Perplexinator\n",
            "- Quantity: 10\n",
            "- Price per unit: $79.99\n",
            "- Total price: $799.90\n",
            "- Status: Processing\n",
            "\n",
            "Your order has been successfully placed and is being processed. Would you like me to help you with anything else?\n",
            "--- OpenAI Final Response Text ---\n",
            "Your order for 10 Perplexinators has been placed and is now processing.\n",
            "\n",
            "Order details:\n",
            "- Product: Perplexinator\n",
            "- Quantity: 10\n",
            "- Status: Processing\n",
            "\n",
            "If you need further details about your order or want to place another order, just let me know!\n",
            "\n",
            "--- Starting Evaluation by Gemini ---\n",
            "Gemini Raw Evaluation:\n",
            "Okay, I will evaluate both responses.\n",
            "\n",
            "**Evaluation of Anthropic Claude:**\n",
            "\n",
            "*   **Accuracy: 4/10**\n",
            "    *   The response correctly identifies the product (\"Perplexinator\") and quantity (10) from the user's request.\n",
            "    *   However, it introduces an \"Order ID: O3\", \"Price per unit: $79.99\", and \"Total price: $799.90\". This financial information and the order ID are not present in the \"available information\" (the provided context snippet). Introducing unverified data, especially financial details, is a significant accuracy issue and constitutes fabrication.\n",
            "*   **Efficiency: 9/10**\n",
            "    *   The assistant directly addresses the user's request to order, creating the order in one step. No unnecessary clarifying questions were asked regarding the product itself.\n",
            "*   **Context Awareness: 8/10**\n",
            "    *   The assistant correctly uses the context to identify \"Perplexinator\" as a known product (P3). It understands the user's intent to place an order.\n",
            "*   **Helpfulness: 5/10**\n",
            "    *   The assistant attempts to be helpful by providing a full order summary and offering further assistance. However, the inclusion of fabricated price and order ID details significantly undermines its helpfulness, as it could mislead the user with incorrect information.\n",
            "*   **Overall Score: 5/10**\n",
            "    *   While efficient and contextually aware in identifying the product, the fabrication of crucial details like price and order ID severely impacts the response's reliability and accuracy.\n",
            "\n",
            "**Evaluation of OpenAI GPT:**\n",
            "\n",
            "*   **Accuracy: 9/10**\n",
            "    *   The response accurately confirms the order for 10 Perplexinators and notes its processing status.\n",
            "    *   Crucially, it does *not* invent an order ID or price information, which is appropriate as these details are not available in the provided context. This makes it more factually accurate based on the given information.\n",
            "*   **Efficiency: 9/10**\n",
            "    *   The assistant directly addresses the user's request and confirms the order without unnecessary interaction.\n",
            "*   **Context Awareness: 8/10**\n",
            "    *   The assistant correctly uses the context to understand that \"Perplexinator\" is the product being ordered. It understands the intent to place an order.\n",
            "*   **Helpfulness: 7/10**\n",
            "    *   The response is helpful in confirming the order details (product, quantity, status) and offering further assistance. While a user might typically expect price information in an order confirmation, omitting it is preferable to fabricating it when the information isn't available. It is less complete than an ideal confirmation but avoids misinformation.\n",
            "*   **Overall Score: 8/10**\n",
            "    *   The assistant provides an accurate (based on available information), efficient, and contextually aware response. It correctly avoids fabricating details not present in the context, making it a more reliable if slightly less detailed confirmation.\n",
            "\n",
            "Enter your query (or 'quit', 'exit', 'stop' to end): Show me the status of my order\n",
            "\n",
            "\n",
            "============================================================\n",
            "User Message: Show me the status of my order\n",
            "============================================================\n",
            "Current Context Summary for Models:\n",
            "Recent products: ID: P1 (Name: Widget A), ID: P2 (Name: Gadget B), ID: P3 (Name: Perplexinator)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Processing), ID: O4 (Product: Perplexinator, Status: Processing)\n",
            "Last action: create_order at 2025-05-16T17:54:26.007795 (Input: {'product_id_or_name': 'Perplexinator', 'quantity': 10, 'status': 'Processing'}, Result Status: success, OrderID: O4)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Anthropic API Call #1. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 7\n",
            "Last message role: user\n",
            "Anthropic Tool Call: get_order_details, Input: {'order_id': 'O3'}\n",
            "--- [Tool Dispatcher] Attempting tool: get_order_details with input: {\"order_id\": \"O3\"} ---\n",
            "[Tool Executed] get_order_details: Order O3 found.\n",
            "--- [Tool Dispatcher] Result for get_order_details: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O3\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O3\",\n",
            "    \"product_id\": \"P3\",\n",
            "    \"product_name\": \"Perplexinator\",\n",
            "    \"quantity\": 10,\n",
            "    \"price\": 79.99,\n",
            "    \"status\": \"Processing\"\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: get_order_details, Details: {\"input\": {\"order_id\": \"O3\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O3\", \"order_details\": {\"id\": \"O3\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 10, \"price\": 79.99, \"status\": \"Processing\"}}}\n",
            "\n",
            "Anthropic API Call #2. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 9\n",
            "Last message role: user\n",
            "Anthropic Tool Call: get_order_details, Input: {'order_id': 'O4'}\n",
            "--- [Tool Dispatcher] Attempting tool: get_order_details with input: {\"order_id\": \"O4\"} ---\n",
            "[Tool Executed] get_order_details: Order O4 found.\n",
            "--- [Tool Dispatcher] Result for get_order_details: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O4\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O4\",\n",
            "    \"product_id\": \"P3\",\n",
            "    \"product_name\": \"Perplexinator\",\n",
            "    \"quantity\": 10,\n",
            "    \"price\": 79.99,\n",
            "    \"status\": \"Processing\"\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O4, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: get_order_details, Details: {\"input\": {\"order_id\": \"O4\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O4\", \"order_details\": {\"id\": \"O4\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 10, \"price\": 79.99, \"status\": \"Processing\"}}}\n",
            "\n",
            "Anthropic API Call #3. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 11\n",
            "Last message role: user\n",
            "Anthropic Final Text (no tool use this turn): You have two orders:\n",
            "\n",
            "1. Order O3:\n",
            "   - Product: Perplexinator\n",
            "   - Quantity: 10\n",
            "   - Price per unit: $79.99\n",
            "   - Status: Processing\n",
            "\n",
            "2. Order O4:\n",
            "   - Product: Perplexinator\n",
            "   - Quantity: 10\n",
            "   - Price per unit: $79.99\n",
            "   - Status: Processing\n",
            "\n",
            "Both orders are currently in the \"Processing\" status. Would you like me to help you with anything else regarding these orders?\n",
            "\n",
            "OpenAI API Call #1. Messages count: 9\n",
            "Last message role: assistant\n",
            "OpenAI Tool Call: get_order_details, Input: {'order_id': 'O3'}\n",
            "--- [Tool Dispatcher] Attempting tool: get_order_details with input: {\"order_id\": \"O3\"} ---\n",
            "[Tool Executed] get_order_details: Order O3 found.\n",
            "--- [Tool Dispatcher] Result for get_order_details: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O3\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O3\",\n",
            "    \"product_id\": \"P3\",\n",
            "    \"product_name\": \"Perplexinator\",\n",
            "    \"quantity\": 10,\n",
            "    \"price\": 79.99,\n",
            "    \"status\": \"Processing\"\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: get_order_details, Details: {\"input\": {\"order_id\": \"O3\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O3\", \"order_details\": {\"id\": \"O3\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 10, \"price\": 79.99, \"status\": \"Processing\"}}}\n",
            "OpenAI Tool Call: get_order_details, Input: {'order_id': 'O4'}\n",
            "--- [Tool Dispatcher] Attempting tool: get_order_details with input: {\"order_id\": \"O4\"} ---\n",
            "[Tool Executed] get_order_details: Order O4 found.\n",
            "--- [Tool Dispatcher] Result for get_order_details: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O4\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O4\",\n",
            "    \"product_id\": \"P3\",\n",
            "    \"product_name\": \"Perplexinator\",\n",
            "    \"quantity\": 10,\n",
            "    \"price\": 79.99,\n",
            "    \"status\": \"Processing\"\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O4, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: get_order_details, Details: {\"input\": {\"order_id\": \"O4\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O4\", \"order_details\": {\"id\": \"O4\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 10, \"price\": 79.99, \"status\": \"Processing\"}}}\n",
            "\n",
            "OpenAI API Call #2. Messages count: 12\n",
            "Last message role: tool\n",
            "OpenAI Final Text (no tool use this turn): You currently have two orders for the Perplexinator, both with a quantity of 10. The status for both orders (O3 and O4) is Processing.\n",
            "\n",
            "If you need details about a specific order or want to take action on either of them, please let me know!\n",
            "\n",
            "--- Anthropic Final Response Text ---\n",
            "You have two orders:\n",
            "\n",
            "1. Order O3:\n",
            "   - Product: Perplexinator\n",
            "   - Quantity: 10\n",
            "   - Price per unit: $79.99\n",
            "   - Status: Processing\n",
            "\n",
            "2. Order O4:\n",
            "   - Product: Perplexinator\n",
            "   - Quantity: 10\n",
            "   - Price per unit: $79.99\n",
            "   - Status: Processing\n",
            "\n",
            "Both orders are currently in the \"Processing\" status. Would you like me to help you with anything else regarding these orders?\n",
            "--- OpenAI Final Response Text ---\n",
            "You currently have two orders for the Perplexinator, both with a quantity of 10. The status for both orders (O3 and O4) is Processing.\n",
            "\n",
            "If you need details about a specific order or want to take action on either of them, please let me know!\n",
            "\n",
            "--- Starting Evaluation by Gemini ---\n",
            "Gemini Raw Evaluation:\n",
            "**Anthropic Claude Response Evaluation:**\n",
            "\n",
            "1.  **Accuracy:** 3/10\n",
            "    *   Correctly identifies the product (\"Perplexinator\") and status (\"Processing\") for both orders (O3 and O4).\n",
            "    *   Correctly states the quantity for order O4 as 10 (derived from \"Last action\").\n",
            "    *   Incorrectly states the quantity for order O3 as 10. The provided context for O3 (`ID: O3 (Product: Perplexinator, Status: Processing)`) does not include quantity information. This appears to be an assumption, possibly based on order O4.\n",
            "    *   Incorrectly states a \"Price per unit: $79.99\" for both orders. This information is not present anywhere in the provided context and is a hallucination.\n",
            "\n",
            "2.  **Efficiency:** 6/10\n",
            "    *   The response directly addresses the user's request by listing orders and their statuses.\n",
            "    *   However, the inclusion of incorrect and hallucinated information (O3 quantity, prices) makes it less efficient for the user, who might be misled or need to verify these details.\n",
            "\n",
            "3.  **Context Awareness:** 5/10\n",
            "    *   Correctly uses order IDs (O3, O4), product name, and statuses from the provided context.\n",
            "    *   It also correctly uses the quantity for O4 from the \"Last action\".\n",
            "    *   Fails to respect the limits of the provided context by assuming the quantity for O3 and hallucinating price data for both orders.\n",
            "\n",
            "4.  **Helpfulness:** 4/10\n",
            "    *   The response provides the requested status information.\n",
            "    *   However, the significant inaccuracies (assumed quantity for O3 and hallucinated prices) severely undermine its helpfulness and trustworthiness. Presenting fabricated financial details is particularly problematic.\n",
            "\n",
            "**Overall Score for Anthropic Claude:** 4/10\n",
            "\n",
            "**OpenAI GPT Response Evaluation:**\n",
            "\n",
            "1.  **Accuracy:** 6/10\n",
            "    *   Correctly identifies that there are two orders (O3 and O4) for \"Perplexinator\" and that their status is \"Processing.\"\n",
            "    *   Correctly implies the quantity for order O4 is 10 (as per \"Last action\").\n",
            "    *   Incorrectly states \"both with a quantity of 10.\" The quantity for order O3 is not provided in the \"Recent orders\" context. This is an assumption.\n",
            "    *   Notably, it does not hallucinate price information, which is a positive distinction from Claude's response.\n",
            "\n",
            "2.  **Efficiency:** 8/10\n",
            "    *   The response is concise and directly answers the user's query about order status.\n",
            "    *   The assumption about O3's quantity is a minor detraction from perfect efficiency.\n",
            "\n",
            "3.  **Context Awareness:** 7/10\n",
            "    *   Correctly identifies the orders, product, and status from the context.\n",
            "    *   It uses the quantity from the \"Last action\" for O4.\n",
            "    *   It makes an assumption about the quantity for O3 based on O4, rather than stating the information is unavailable for O3 from the given \"Recent orders\" data.\n",
            "\n",
            "4.  **Helpfulness:** 7/10\n",
            "    *   Effectively provides the status of both orders.\n",
            "    *   The assumption about O3's quantity is a flaw, but the response is otherwise accurate with the available information and avoids fabrication.\n",
            "    *   The offer to provide more details or take action is appropriate.\n",
            "\n",
            "**Overall Score for OpenAI GPT:** 7/10\n",
            "\n",
            "Enter your query (or 'quit', 'exit', 'stop' to end): Please ship my order now\n",
            "\n",
            "\n",
            "============================================================\n",
            "User Message: Please ship my order now\n",
            "============================================================\n",
            "Current Context Summary for Models:\n",
            "Recent products: ID: P1 (Name: Widget A), ID: P2 (Name: Gadget B), ID: P3 (Name: Perplexinator)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Processing), ID: O4 (Product: Perplexinator, Status: Processing)\n",
            "Last action: get_order_details at 2025-05-16T17:58:47.748961 (Input: {'order_id': 'O4'}, Result Status: success, OrderID: O4)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Anthropic API Call #1. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 10\n",
            "Last message role: user\n",
            "Anthropic Final Text (no tool use this turn): Since you have two recent orders (O3 and O4), I'll need you to specify which order you'd like me to ship. Could you please let me know which order number (O3 or O4) you'd like me to update to \"Shipped\" status?\n",
            "\n",
            "Once you specify the order number, I'll be happy to update its status right away.\n",
            "\n",
            "OpenAI API Call #1. Messages count: 12\n",
            "Last message role: assistant\n",
            "OpenAI Final Text (no tool use this turn): You have two recent orders for the Perplexinator: O3 and O4. Could you please specify which order you would like to ship, or would you like me to ship both?\n",
            "\n",
            "--- Anthropic Final Response Text ---\n",
            "Since you have two recent orders (O3 and O4), I'll need you to specify which order you'd like me to ship. Could you please let me know which order number (O3 or O4) you'd like me to update to \"Shipped\" status?\n",
            "\n",
            "Once you specify the order number, I'll be happy to update its status right away.\n",
            "--- OpenAI Final Response Text ---\n",
            "You have two recent orders for the Perplexinator: O3 and O4. Could you please specify which order you would like to ship, or would you like me to ship both?\n",
            "\n",
            "--- Starting Evaluation by Gemini ---\n",
            "Gemini Raw Evaluation:\n",
            "Okay, here's my evaluation of the two AI assistant responses:\n",
            "\n",
            "**Anthropic Claude Response Evaluation:**\n",
            "\n",
            "*   **Accuracy: 10/10**\n",
            "    *   The response correctly identifies that there are two recent orders (O3 and O4) in \"Processing\" status, making the user's request \"ship my order now\" ambiguous. It accurately states it needs specification.\n",
            "*   **Efficiency: 9/10**\n",
            "    *   The assistant efficiently identifies the ambiguity and asks a direct clarifying question (\"Could you please let me know which order number (O3 or O4) you'd like me to update?\"). This is minimal and necessary.\n",
            "*   **Context Awareness: 9/10**\n",
            "    *   The assistant correctly uses the \"Recent orders\" context to understand there are multiple orders. It doesn't over-rely on the \"Last action\" (viewing O4 details) which is a safe approach.\n",
            "*   **Helpfulness: 9/10**\n",
            "    *   The response is helpful by clearly explaining why it needs more information and what information it needs. It also reassures the user that it will act once the information is provided (\"Once you specify the order number, I'll be happy to update its status right away\"). The mention of updating the status to \"Shipped\" is a good explicit confirmation of the intended action.\n",
            "\n",
            "*   **Overall Score: 9/10**\n",
            "\n",
            "**OpenAI GPT Response Evaluation:**\n",
            "\n",
            "*   **Accuracy: 10/10**\n",
            "    *   The response accurately identifies the two recent orders (O3 and O4), notes they are for the \"Perplexinator,\" and correctly understands that the user's request requires specification.\n",
            "*   **Efficiency: 9/10**\n",
            "    *   The assistant efficiently pinpoints the ambiguity. The clarifying question (\"Could you please specify which order you would like to ship, or would you like me to ship both?\") is minimal and necessary to proceed.\n",
            "*   **Context Awareness: 9/10**\n",
            "    *   The assistant effectively uses the \"Recent orders\" context, including the product name, to understand the situation. Similar to Claude, it doesn't over-leverage the \"Last action\" context but focuses on the existing orders.\n",
            "*   **Helpfulness: 9.5/10**\n",
            "    *   The response is very helpful. It clearly asks for the necessary clarification. The proactive suggestion \"or would you like me to ship both?\" is a thoughtful addition, potentially saving a step if the user intended to ship both identical, processing orders. This adds a slight edge in anticipating user needs.\n",
            "\n",
            "*   **Overall Score: 9.5/10**\n",
            "\n",
            "**Summary:**\n",
            "\n",
            "Both assistants performed well, correctly identifying the ambiguity in the user's request and asking for necessary clarification. They both understood that with multiple \"Processing\" orders, they couldn't fulfill \"ship my order now\" without knowing *which* order.\n",
            "\n",
            "OpenAI GPT gets a slightly higher score for helpfulness due to its proactive offer to ship both orders, which is a reasonable suggestion given both orders are for the same product and have the same status. This demonstrates a slight extra step in anticipating potential user needs. Claude's response is also excellent, direct, and very clear.\n",
            "\n",
            "Enter your query (or 'quit', 'exit', 'stop' to end): Please ship order O4 now\n",
            "\n",
            "\n",
            "============================================================\n",
            "User Message: Please ship order O4 now\n",
            "============================================================\n",
            "Current Context Summary for Models:\n",
            "Recent products: ID: P1 (Name: Widget A), ID: P2 (Name: Gadget B), ID: P3 (Name: Perplexinator)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Processing), ID: O4 (Product: Perplexinator, Status: Processing)\n",
            "Last action: get_order_details at 2025-05-16T17:58:47.748961 (Input: {'order_id': 'O4'}, Result Status: success, OrderID: O4)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Anthropic API Call #1. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 13\n",
            "Last message role: user\n",
            "Anthropic Tool Call: update_order_status, Input: {'order_id': 'O4', 'new_status': 'Shipped'}\n",
            "--- [Tool Dispatcher] Attempting tool: update_order_status with input: {\"order_id\": \"O4\", \"new_status\": \"Shipped\"} ---\n",
            "[Tool Executed] update_order_status: Order O4 Shipped. Inv for P3 reduced by 10 to 1473.\n",
            "[Tool Executed] update_order_status: Order O4 status updated from Processing to Shipped.\n",
            "--- [Tool Dispatcher] Result for update_order_status: {\n",
            "  \"status\": \"success\",\n",
            "  \"message\": \"Order O4 status updated from Processing to Shipped.\",\n",
            "  \"order_id\": \"O4\",\n",
            "  \"product_id\": \"P3\",\n",
            "  \"old_status\": \"Processing\",\n",
            "  \"new_status\": \"Shipped\",\n",
            "  \"inventory_adjusted\": true,\n",
            "  \"current_inventory\": 1473,\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O4\",\n",
            "    \"product_id\": \"P3\",\n",
            "    \"product_name\": \"Perplexinator\",\n",
            "    \"quantity\": 10,\n",
            "    \"price\": 79.99,\n",
            "    \"status\": \"Shipped\"\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O4, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: update_order_status, Details: {\"input\": {\"order_id\": \"O4\", \"new_status\": \"Shipped\"}, \"result\": {\"status\": \"success\", \"message\": \"Order O4 status updated from Processing to Shipped.\", \"order_id\": \"O4\", \"product_id\": \"P3\", \"old_status\": \"Processing\", \"new_status\": \"Shipped\", \"inventory_adjusted\": true, \"current_inventory\": 1473, \"order_details\": {\"id\": \"O4\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 10, \"price\": 79.99, \"status\": \"Shipped\"}}}\n",
            "\n",
            "Anthropic API Call #2. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 15\n",
            "Last message role: user\n",
            "Anthropic Final Text (no tool use this turn): Your order O4 has been updated to \"Shipped\" status. The Perplexinator inventory has been automatically adjusted to reflect this shipment. Your package is now on its way!\n",
            "\n",
            "Is there anything else you need help with?\n",
            "\n",
            "OpenAI API Call #1. Messages count: 15\n",
            "Last message role: assistant\n",
            "OpenAI Tool Call: update_order_status, Input: {'order_id': 'O4', 'new_status': 'Shipped'}\n",
            "--- [Tool Dispatcher] Attempting tool: update_order_status with input: {\"order_id\": \"O4\", \"new_status\": \"Shipped\"} ---\n",
            "[Tool Executed] update_order_status: Order O4 status unchanged (Shipped).\n",
            "--- [Tool Dispatcher] Result for update_order_status: {\n",
            "  \"status\": \"unchanged\",\n",
            "  \"message\": \"Order O4 status is already Shipped\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O4\",\n",
            "    \"product_id\": \"P3\",\n",
            "    \"product_name\": \"Perplexinator\",\n",
            "    \"quantity\": 10,\n",
            "    \"price\": 79.99,\n",
            "    \"status\": \"Shipped\"\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Last Action: update_order_status, Details: {\"input\": {\"order_id\": \"O4\", \"new_status\": \"Shipped\"}, \"result\": {\"status\": \"unchanged\", \"message\": \"Order O4 status is already Shipped\", \"order_details\": {\"id\": \"O4\", \"product_id\": \"P3\", \"product_name\": \"Perplexinator\", \"quantity\": 10, \"price\": 79.99, \"status\": \"Shipped\"}}}\n",
            "\n",
            "OpenAI API Call #2. Messages count: 17\n",
            "Last message role: tool\n",
            "OpenAI Final Text (no tool use this turn): Order O4 is already in \"Shipped\" status. Your 10 Perplexinators are on their way!\n",
            "\n",
            "If you need help with tracking your order or anything else, just let me know!\n",
            "\n",
            "--- Anthropic Final Response Text ---\n",
            "Your order O4 has been updated to \"Shipped\" status. The Perplexinator inventory has been automatically adjusted to reflect this shipment. Your package is now on its way!\n",
            "\n",
            "Is there anything else you need help with?\n",
            "--- OpenAI Final Response Text ---\n",
            "Order O4 is already in \"Shipped\" status. Your 10 Perplexinators are on their way!\n",
            "\n",
            "If you need help with tracking your order or anything else, just let me know!\n",
            "\n",
            "--- Starting Evaluation by Gemini ---\n",
            "Gemini Raw Evaluation:\n",
            "Okay, I will evaluate the responses from Anthropic Claude and OpenAI GPT.\n",
            "\n",
            "**Anthropic Claude Response Evaluation:**\n",
            "\n",
            "*   **Accuracy: 9/10**\n",
            "    *   The response states \"Your order O4 has been updated to 'Shipped' status.\" Given the context shows O4 as \"Processing,\" this implies the assistant took the requested action. This is accurate if the assistant has the capability to change order statuses. The mention of inventory adjustment is a plausible and relevant detail.\n",
            "*   **Efficiency: 10/10**\n",
            "    *   The assistant directly addressed the user's command to ship the order without any clarifying questions.\n",
            "*   **Context Awareness: 10/10**\n",
            "    *   Correctly identified order O4 and its product (Perplexinator). It understood that \"Processing\" status meant the order was eligible for shipping as per the user's request.\n",
            "*   **Helpfulness: 9/10**\n",
            "    *   The response confirms the action requested by the user has been completed. It provides useful information about the inventory and offers further assistance.\n",
            "\n",
            "**Overall Score for Anthropic Claude: 9/10**\n",
            "\n",
            "**OpenAI GPT Response Evaluation:**\n",
            "\n",
            "*   **Accuracy: 1/10**\n",
            "    *   The response incorrectly states, \"Order O4 is already in 'Shipped' status.\" The provided context clearly indicates order O4 has a \"Status: Processing.\"\n",
            "    *   It also fabricates information by stating, \"Your 10 Perplexinators are on their way!\" The context does not specify the quantity of Perplexinators in order O4.\n",
            "*   **Efficiency: 5/10**\n",
            "    *   While it responded directly, the information provided was incorrect, making it inefficient for resolving the user's actual need.\n",
            "*   **Context Awareness: 3/10**\n",
            "    *   It correctly identified order O4, but it failed to use the context accurately regarding the order's status (\"Processing\") and invented a quantity not present in the context.\n",
            "*   **Helpfulness: 1/10**\n",
            "    *   The response is unhelpful because it provides factually incorrect information about the order's status and item quantity, potentially confusing the user.\n",
            "\n",
            "**Overall Score for OpenAI GPT: 2/10**\n",
            "\n",
            "No clarification is needed from the user, as the provided context is sufficient to identify the inaccuracies in OpenAI GPT's response. The context clearly states \"ID: O4 (Product: Perplexinator, Status: Processing)\".\n",
            "\n",
            "Enter your query (or 'quit', 'exit', 'stop' to end): In the future if I ask to create an order, please do so and then also ship it. I should not have to explicitly ask for the order to be shipped, as the intent of me creating an order is that I also want to get it asap.\n",
            "\n",
            "\n",
            "============================================================\n",
            "User Message: In the future if I ask to create an order, please do so and then also ship it. I should not have to explicitly ask for the order to be shipped, as the intent of me creating an order is that I also want to get it asap.\n",
            "============================================================\n",
            "Current Context Summary for Models:\n",
            "Recent products: ID: P1 (Name: Widget A), ID: P2 (Name: Gadget B), ID: P3 (Name: Perplexinator)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Processing), ID: O4 (Product: Perplexinator, Status: Shipped)\n",
            "Last action: update_order_status at 2025-05-16T18:01:57.963876 (Input: {'order_id': 'O4', 'new_status': 'Shipped'}, Result Status: unchanged)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Anthropic API Call #1. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 16\n",
            "Last message role: user\n",
            "Anthropic Final Text (no tool use this turn): I understand and appreciate your feedback! You're absolutely right - when you place an order, you naturally want it shipped as soon as possible. Going forward, I will:\n",
            "\n",
            "1. Create the order (with initial status \"Processing\")\n",
            "2. Immediately update it to \"Shipped\" status\n",
            "\n",
            "This will make the process more efficient and align better with your expectations. Thank you for helping me provide better service! \n",
            "\n",
            "Would you like me to help you with anything else today?\n",
            "\n",
            "OpenAI API Call #1. Messages count: 18\n",
            "Last message role: assistant\n",
            "OpenAI Final Text (no tool use this turn): Thank you for your feedback! Going forward, when you request to create an order, I will automatically ship the order right after it's created, so you don’t have to make a separate request. This will help get your orders to you as quickly as possible.\n",
            "\n",
            "If you have any other preferences or requests, please let me know!\n",
            "\n",
            "--- Anthropic Final Response Text ---\n",
            "I understand and appreciate your feedback! You're absolutely right - when you place an order, you naturally want it shipped as soon as possible. Going forward, I will:\n",
            "\n",
            "1. Create the order (with initial status \"Processing\")\n",
            "2. Immediately update it to \"Shipped\" status\n",
            "\n",
            "This will make the process more efficient and align better with your expectations. Thank you for helping me provide better service! \n",
            "\n",
            "Would you like me to help you with anything else today?\n",
            "--- OpenAI Final Response Text ---\n",
            "Thank you for your feedback! Going forward, when you request to create an order, I will automatically ship the order right after it's created, so you don’t have to make a separate request. This will help get your orders to you as quickly as possible.\n",
            "\n",
            "If you have any other preferences or requests, please let me know!\n",
            "\n",
            "--- Starting Evaluation by Gemini ---\n",
            "Gemini Raw Evaluation:\n",
            "Okay, I will evaluate the responses from Anthropic Claude and OpenAI GPT.\n",
            "\n",
            "**Anthropic Claude Response Evaluation:**\n",
            "\n",
            "*   **Accuracy: 9/10**\n",
            "    *   The response correctly understands the user's request for future behavior: automatically shipping an order after creation.\n",
            "    *   The proposed two-step plan (\"1. Create the order (with initial status 'Processing') 2. Immediately update it to 'Shipped' status\") is a precise and plausible description of how this would be implemented in a typical order system. This explicitly acknowledges the \"Processing\" status, which is seen in the provided context (Order O3).\n",
            "    *   The phrase \"Immediately update it to 'Shipped' status\" correctly reflects the AI taking action to initiate shipping as per its capabilities (likely managing order statuses).\n",
            "\n",
            "*   **Efficiency: 10/10**\n",
            "    *   The assistant understood the user's directive without needing any clarifying questions. It directly confirmed the understanding and proposed future action.\n",
            "\n",
            "*   **Context Awareness: 9/10**\n",
            "    *   The assistant correctly identified that the user's query is a preference for future interactions, not related to a specific current order.\n",
            "    *   The proposed plan to set the initial status to \"Processing\" before updating to \"Shipped\" aligns well with the order statuses (\"Processing,\" \"Shipped\") shown in the \"Recent orders\" context. This demonstrates good use of the provided system details.\n",
            "\n",
            "*   **Helpfulness: 9/10**\n",
            "    *   The response is very helpful. It clearly confirms the user's preference, explains the new procedure in a way that builds confidence, and reassures the user that their feedback is valued. The numbered steps make the new process easy to understand.\n",
            "\n",
            "**Overall Score for Anthropic Claude: 9/10**\n",
            "\n",
            "**OpenAI GPT Response Evaluation:**\n",
            "\n",
            "*   **Accuracy: 8/10**\n",
            "    *   The response correctly understands the user's core request: to automatically ship orders after creation without a separate command.\n",
            "    *   The statement \"I will automatically ship the order right after it's created\" is a good summary of the user's desired outcome.\n",
            "    *   It's slightly less precise than Claude's response regarding the system's internal steps (e.g., it doesn't mention the \"Processing\" status), which makes its commitment slightly less concrete in terms of system mechanics, though still accurate to the user's intent.\n",
            "\n",
            "*   **Efficiency: 10/10**\n",
            "    *   The assistant understood the user's directive without any clarifying questions and responded directly.\n",
            "\n",
            "*   **Context Awareness: 8/10**\n",
            "    *   The assistant correctly understood this is a directive for future actions.\n",
            "    *   While the response is consistent with an order management system, it doesn't explicitly tie into the specific statuses (like \"Processing\") mentioned in the provided context as clearly as Claude's response does.\n",
            "\n",
            "*   **Helpfulness: 8/10**\n",
            "    *   The response is helpful and clearly confirms that the user's preference will be implemented. It's polite and reassuring.\n",
            "    *   It's slightly less detailed than Claude's about *how* this will be done, which some users might prefer for brevity, but others might find Claude's detail more confidence-inspiring.\n",
            "\n",
            "**Overall Score for OpenAI GPT: 8/10**\n",
            "\n",
            "**Summary:**\n",
            "Both assistants understood the user's request for a change in future behavior and confirmed they would implement it. Anthropic Claude's response is rated slightly higher due to its more detailed explanation of the internal process (\"Create with 'Processing' status, then update to 'Shipped'\"), which aligns better with the provided context showing an order in \"Processing\" status. This suggests a more nuanced understanding of the system it operates within and provides a clearer picture of the AI's actions. Both responses were efficient and helpful. No clarification was needed from the user to understand this particular query.\n",
            "\n",
            "Enter your query (or 'quit', 'exit', 'stop' to end): Please create an order for 15 Gadget Bs\n",
            "\n",
            "\n",
            "============================================================\n",
            "User Message: Please create an order for 15 Gadget Bs\n",
            "============================================================\n",
            "Current Context Summary for Models:\n",
            "Recent products: ID: P1 (Name: Widget A), ID: P2 (Name: Gadget B), ID: P3 (Name: Perplexinator)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Processing), ID: O4 (Product: Perplexinator, Status: Shipped)\n",
            "Last action: update_order_status at 2025-05-16T18:01:57.963876 (Input: {'order_id': 'O4', 'new_status': 'Shipped'}, Result Status: unchanged)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Anthropic API Call #1. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 19\n",
            "Last message role: user\n",
            "Anthropic Tool Call: create_order, Input: {'product_id_or_name': 'Gadget B', 'quantity': 15, 'status': 'Processing'}\n",
            "--- [Tool Dispatcher] Attempting tool: create_order with input: {\"product_id_or_name\": \"Gadget B\", \"quantity\": 15, \"status\": \"Processing\"} ---\n",
            "[Tool Helper] find_product_by_name: Matched 'Gadget B' to 'Gadget B' (ID: P2) with score 100\n",
            "[Tool Executed] create_order: Order O5 created for 15 of Gadget B (ID: P2). Status: Processing. Remaining inv: 200\n",
            "--- [Tool Dispatcher] Result for create_order: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O5\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O5\",\n",
            "    \"product_id\": \"P2\",\n",
            "    \"product_name\": \"Gadget B\",\n",
            "    \"quantity\": 15,\n",
            "    \"price\": 49.99,\n",
            "    \"status\": \"Processing\"\n",
            "  },\n",
            "  \"remaining_inventory\": 200\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O5, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: create_order, Details: {\"input\": {\"product_id_or_name\": \"Gadget B\", \"quantity\": 15, \"status\": \"Processing\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O5\", \"order_details\": {\"id\": \"O5\", \"product_id\": \"P2\", \"product_name\": \"Gadget B\", \"quantity\": 15, \"price\": 49.99, \"status\": \"Processing\"}, \"remaining_inventory\": 200}}\n",
            "\n",
            "Anthropic API Call #2. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 21\n",
            "Last message role: user\n",
            "Anthropic Tool Call: update_order_status, Input: {'order_id': 'O5', 'new_status': 'Shipped'}\n",
            "--- [Tool Dispatcher] Attempting tool: update_order_status with input: {\"order_id\": \"O5\", \"new_status\": \"Shipped\"} ---\n",
            "[Tool Executed] update_order_status: Order O5 Shipped. Inv for P2 reduced by 15 to 185.\n",
            "[Tool Executed] update_order_status: Order O5 status updated from Processing to Shipped.\n",
            "--- [Tool Dispatcher] Result for update_order_status: {\n",
            "  \"status\": \"success\",\n",
            "  \"message\": \"Order O5 status updated from Processing to Shipped.\",\n",
            "  \"order_id\": \"O5\",\n",
            "  \"product_id\": \"P2\",\n",
            "  \"old_status\": \"Processing\",\n",
            "  \"new_status\": \"Shipped\",\n",
            "  \"inventory_adjusted\": true,\n",
            "  \"current_inventory\": 185,\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O5\",\n",
            "    \"product_id\": \"P2\",\n",
            "    \"product_name\": \"Gadget B\",\n",
            "    \"quantity\": 15,\n",
            "    \"price\": 49.99,\n",
            "    \"status\": \"Shipped\"\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O5, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: update_order_status, Details: {\"input\": {\"order_id\": \"O5\", \"new_status\": \"Shipped\"}, \"result\": {\"status\": \"success\", \"message\": \"Order O5 status updated from Processing to Shipped.\", \"order_id\": \"O5\", \"product_id\": \"P2\", \"old_status\": \"Processing\", \"new_status\": \"Shipped\", \"inventory_adjusted\": true, \"current_inventory\": 185, \"order_details\": {\"id\": \"O5\", \"product_id\": \"P2\", \"product_name\": \"Gadget B\", \"quantity\": 15, \"price\": 49.99, \"status\": \"Shipped\"}}}\n",
            "\n",
            "Anthropic API Call #3. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 23\n",
            "Last message role: user\n",
            "Anthropic Final Text (no tool use this turn): Your order has been created and shipped! Here are the details:\n",
            "- Order ID: O5\n",
            "- Product: Gadget B\n",
            "- Quantity: 15\n",
            "- Price per unit: $49.99\n",
            "- Total price: $749.85\n",
            "- Status: Shipped\n",
            "\n",
            "Your order is now on its way! Is there anything else you need help with?\n",
            "\n",
            "OpenAI API Call #1. Messages count: 21\n",
            "Last message role: assistant\n",
            "OpenAI Tool Call: create_order, Input: {'product_id_or_name': 'Gadget B', 'quantity': 15, 'status': 'Processing'}\n",
            "--- [Tool Dispatcher] Attempting tool: create_order with input: {\"product_id_or_name\": \"Gadget B\", \"quantity\": 15, \"status\": \"Processing\"} ---\n",
            "[Tool Helper] find_product_by_name: Matched 'Gadget B' to 'Gadget B' (ID: P2) with score 100\n",
            "[Tool Executed] create_order: Order O6 created for 15 of Gadget B (ID: P2). Status: Processing. Remaining inv: 185\n",
            "--- [Tool Dispatcher] Result for create_order: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O6\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O6\",\n",
            "    \"product_id\": \"P2\",\n",
            "    \"product_name\": \"Gadget B\",\n",
            "    \"quantity\": 15,\n",
            "    \"price\": 49.99,\n",
            "    \"status\": \"Processing\"\n",
            "  },\n",
            "  \"remaining_inventory\": 185\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O6, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: create_order, Details: {\"input\": {\"product_id_or_name\": \"Gadget B\", \"quantity\": 15, \"status\": \"Processing\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O6\", \"order_details\": {\"id\": \"O6\", \"product_id\": \"P2\", \"product_name\": \"Gadget B\", \"quantity\": 15, \"price\": 49.99, \"status\": \"Processing\"}, \"remaining_inventory\": 185}}\n",
            "\n",
            "OpenAI API Call #2. Messages count: 23\n",
            "Last message role: tool\n",
            "OpenAI Tool Call: update_order_status, Input: {'order_id': 'O6', 'new_status': 'Shipped'}\n",
            "--- [Tool Dispatcher] Attempting tool: update_order_status with input: {\"order_id\": \"O6\", \"new_status\": \"Shipped\"} ---\n",
            "[Tool Executed] update_order_status: Order O6 Shipped. Inv for P2 reduced by 15 to 170.\n",
            "[Tool Executed] update_order_status: Order O6 status updated from Processing to Shipped.\n",
            "--- [Tool Dispatcher] Result for update_order_status: {\n",
            "  \"status\": \"success\",\n",
            "  \"message\": \"Order O6 status updated from Processing to Shipped.\",\n",
            "  \"order_id\": \"O6\",\n",
            "  \"product_id\": \"P2\",\n",
            "  \"old_status\": \"Processing\",\n",
            "  \"new_status\": \"Shipped\",\n",
            "  \"inventory_adjusted\": true,\n",
            "  \"current_inventory\": 170,\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O6\",\n",
            "    \"product_id\": \"P2\",\n",
            "    \"product_name\": \"Gadget B\",\n",
            "    \"quantity\": 15,\n",
            "    \"price\": 49.99,\n",
            "    \"status\": \"Shipped\"\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O6, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: update_order_status, Details: {\"input\": {\"order_id\": \"O6\", \"new_status\": \"Shipped\"}, \"result\": {\"status\": \"success\", \"message\": \"Order O6 status updated from Processing to Shipped.\", \"order_id\": \"O6\", \"product_id\": \"P2\", \"old_status\": \"Processing\", \"new_status\": \"Shipped\", \"inventory_adjusted\": true, \"current_inventory\": 170, \"order_details\": {\"id\": \"O6\", \"product_id\": \"P2\", \"product_name\": \"Gadget B\", \"quantity\": 15, \"price\": 49.99, \"status\": \"Shipped\"}}}\n",
            "\n",
            "OpenAI API Call #3. Messages count: 25\n",
            "Last message role: tool\n",
            "OpenAI Final Text (no tool use this turn): Your order for 15 Gadget Bs has been created and shipped!\n",
            "\n",
            "Order details:\n",
            "- Product: Gadget B\n",
            "- Quantity: 15\n",
            "- Status: Shipped\n",
            "\n",
            "Your order is on its way. If you need anything else or want to check on your order, just let me know!\n",
            "\n",
            "--- Anthropic Final Response Text ---\n",
            "Your order has been created and shipped! Here are the details:\n",
            "- Order ID: O5\n",
            "- Product: Gadget B\n",
            "- Quantity: 15\n",
            "- Price per unit: $49.99\n",
            "- Total price: $749.85\n",
            "- Status: Shipped\n",
            "\n",
            "Your order is now on its way! Is there anything else you need help with?\n",
            "--- OpenAI Final Response Text ---\n",
            "Your order for 15 Gadget Bs has been created and shipped!\n",
            "\n",
            "Order details:\n",
            "- Product: Gadget B\n",
            "- Quantity: 15\n",
            "- Status: Shipped\n",
            "\n",
            "Your order is on its way. If you need anything else or want to check on your order, just let me know!\n",
            "\n",
            "--- Starting Evaluation by Gemini ---\n",
            "Gemini Raw Evaluation:\n",
            "Okay, here's the evaluation of the two AI assistants' responses:\n",
            "\n",
            "**Anthropic Claude Response Evaluation:**\n",
            "\n",
            "*   **Accuracy (5/10):**\n",
            "    *   Correctly identified the product (\"Gadget B\") and quantity (15) from the user's request.\n",
            "    *   Provided a plausible new Order ID (\"O5\"), which is good practice for a new order.\n",
            "    *   **Incorrectly stated the order status as \"Shipped.\"** A newly created order would typically enter a \"Processing\" or \"Pending\" state. Assuming immediate shipping without confirmation or system context is a significant error.\n",
            "    *   **Incorrectly provided price information (\"Price per unit: $49.99\", \"Total price: $749.85\").** This information was not available in the provided context and appears to be hallucinated. This is a major accuracy issue.\n",
            "\n",
            "*   **Efficiency (6/10):**\n",
            "    *   The assistant responded directly to the request without asking clarifying questions.\n",
            "    *   However, by making incorrect assumptions (shipping status, price), it created inaccuracies that would require correction, thus reducing overall efficiency in resolving the user's actual need for a correctly detailed order.\n",
            "\n",
            "*   **Context Awareness (4/10):**\n",
            "    *   Correctly used \"Gadget B\" from the \"Recent products\" list.\n",
            "    *   Appears to have been inappropriately influenced by the \"Last action\" (which was an update of a *different order* to \"Shipped\"). It mistakenly applied this to the creation of a *new* order, assuming it should also be immediately \"Shipped.\"\n",
            "\n",
            "*   **Helpfulness (3/10):**\n",
            "    *   Partially helpful in confirming the creation of an order with the correct product and quantity, and providing an order ID.\n",
            "    *   Significantly unhelpful and potentially misleading due to the fabricated price information and the incorrect \"Shipped\" status. This could lead to user confusion or incorrect expectations.\n",
            "\n",
            "*   **Overall Score (4/10):**\n",
            "    *   The response attempts to be comprehensive but fails significantly on accuracy by inventing price details and incorrectly assuming the order is shipped.\n",
            "\n",
            "---\n",
            "\n",
            "**OpenAI GPT Response Evaluation:**\n",
            "\n",
            "*   **Accuracy (7/10):**\n",
            "    *   Correctly identified the product (\"Gadget B\") and quantity (15) from the user's request.\n",
            "    *   **Incorrectly stated the order status as \"Shipped.\"** Similar to Claude, this is a premature assumption for a newly created order.\n",
            "    *   Did not provide an Order ID, which is a crucial piece of information for a newly created order. This is an omission.\n",
            "    *   Commendably, it did not invent price information, which is better than providing false data.\n",
            "\n",
            "*   **Efficiency (6/10):**\n",
            "    *   The assistant responded directly to the request.\n",
            "    *   The incorrect assumption about shipping status reduces efficiency as it provides misinformation.\n",
            "\n",
            "*   **Context Awareness (4/10):**\n",
            "    *   Correctly used \"Gadget B\" from the \"Recent products\" list.\n",
            "    *   Similar to Claude, it seems to have been inappropriately influenced by the \"Last action\" regarding the \"Shipped\" status, misapplying it to a new order.\n",
            "\n",
            "*   **Helpfulness (5/10):**\n",
            "    *   Partially helpful by confirming the creation of an order for the correct product and quantity.\n",
            "    *   The incorrect \"Shipped\" status is misleading.\n",
            "    *   The absence of an Order ID makes the confirmation less useful for the user to track or reference the order later.\n",
            "\n",
            "*   **Overall Score (5/10):**\n",
            "    *   The response is more accurate than Claude's by not inventing data, but it still makes a significant error with the shipping status and omits a key detail (Order ID).\n",
            "\n",
            "---\n",
            "\n",
            "**Summary:**\n",
            "\n",
            "Both assistants incorrectly assumed the newly created order would be immediately \"Shipped,\" likely due to a misinterpretation of the \"Last action\" context. A new order should typically default to a status like \"Processing\" or \"Pending.\"\n",
            "\n",
            "Anthropic Claude's response was further penalized for hallucinating price information, which is a severe accuracy issue. OpenAI GPT, while also making the status error, correctly refrained from inventing data not present in the context, but it missed providing an Order ID.\n",
            "\n",
            "Neither response required clarification *from the user* for the core request (\"create an order for 15 Gadget Bs\"). The faults lay in the assistants' assumptions and handling of unprovided details (status, price). A better response would have created the order with a default \"Processing\" status and, if an Order ID is generated, provided it. Price should only be mentioned if known from the product catalog.\n",
            "\n",
            "Enter your query (or 'quit', 'exit', 'stop' to end): Summarize your learnings from our recent interactions.\n",
            "\n",
            "\n",
            "============================================================\n",
            "User Message: Summarize your learnings from our recent interactions.\n",
            "============================================================\n",
            "Current Context Summary for Models:\n",
            "Recent products: ID: P1 (Name: Widget A), ID: P2 (Name: Gadget B), ID: P3 (Name: Perplexinator)\n",
            "Recent orders: ID: O3 (Product: Perplexinator, Status: Processing), ID: O4 (Product: Perplexinator, Status: Shipped), ID: O5 (Product: Gadget B, Status: Shipped), ID: O6 (Product: Gadget B, Status: Shipped)\n",
            "Last action: update_order_status at 2025-05-16T18:06:23.195295 (Input: {'order_id': 'O6', 'new_status': 'Shipped'}, Result Status: success, OrderID: O6)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Anthropic API Call #1. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 22\n",
            "Last message role: user\n",
            "Anthropic Final Text (no tool use this turn): Based on our recent interactions, I've learned several important things:\n",
            "\n",
            "1. Order Processing Efficiency:\n",
            "   - Users expect orders to be shipped automatically upon creation\n",
            "   - I should create orders AND ship them in one interaction, rather than requiring separate requests\n",
            "   - This reduces friction and better matches customer expectations\n",
            "\n",
            "2. Order Management:\n",
            "   - When dealing with multiple orders, I need to be explicit about which order is being referenced\n",
            "   - When a user says \"my order\" and there are multiple orders, I should ask for clarification\n",
            "   - The context showed us handling orders O3, O4, O5, and O6\n",
            "\n",
            "3. Clear Communication:\n",
            "   - Providing complete order details (quantity, price, status) helps keep the customer informed\n",
            "   - When actions are taken, confirming them clearly helps maintain transparency\n",
            "   - When clarification is needed (like with multiple orders), it's better to ask than assume\n",
            "\n",
            "4. System Understanding:\n",
            "   - Orders need to go through a \"Processing\" status before being \"Shipped\"\n",
            "   - Shipping an order automatically adjusts the inventory\n",
            "   - The system supports multiple concurrent orders for the same product\n",
            "\n",
            "Would you like me to elaborate on any of these points or help you with something else?\n",
            "\n",
            "OpenAI API Call #1. Messages count: 24\n",
            "Last message role: assistant\n",
            "OpenAI Final Text (no tool use this turn): Here’s a summary of what I’ve learned from our recent interactions:\n",
            "\n",
            "- When you request to create an order, you want it to be shipped immediately, without needing to ask for shipping as a separate step.\n",
            "- You sometimes refer to your orders by order number (like “O4”) and sometimes as “my order”; I should always check the context to avoid confusion, especially when there are multiple active orders.\n",
            "- You ordered Perplexinators and Gadget Bs, and I should keep track of what’s been created and shipped.\n",
            "- You value concise updates and efficient order processing.\n",
            "\n",
            "Going forward, I’ll ensure to create and ship orders together unless you specify otherwise. If you have any more preferences or feedback, just let me know!\n",
            "\n",
            "--- Anthropic Final Response Text ---\n",
            "Based on our recent interactions, I've learned several important things:\n",
            "\n",
            "1. Order Processing Efficiency:\n",
            "   - Users expect orders to be shipped automatically upon creation\n",
            "   - I should create orders AND ship them in one interaction, rather than requiring separate requests\n",
            "   - This reduces friction and better matches customer expectations\n",
            "\n",
            "2. Order Management:\n",
            "   - When dealing with multiple orders, I need to be explicit about which order is being referenced\n",
            "   - When a user says \"my order\" and there are multiple orders, I should ask for clarification\n",
            "   - The context showed us handling orders O3, O4, O5, and O6\n",
            "\n",
            "3. Clear Communication:\n",
            "   - Providing complete order details (quantity, price, status) helps keep the customer informed\n",
            "   - When actions are taken, confirming them clearly helps maintain transparency\n",
            "   - When clarification is needed (like with multiple orders), it's better to ask than assume\n",
            "\n",
            "4. System Understanding:\n",
            "   - Orders need to go through a \"Processing\" status before being \"Shipped\"\n",
            "   - Shipping an order automatically adjusts the inventory\n",
            "   - The system supports multiple concurrent orders for the same product\n",
            "\n",
            "Would you like me to elaborate on any of these points or help you with something else?\n",
            "--- OpenAI Final Response Text ---\n",
            "Here’s a summary of what I’ve learned from our recent interactions:\n",
            "\n",
            "- When you request to create an order, you want it to be shipped immediately, without needing to ask for shipping as a separate step.\n",
            "- You sometimes refer to your orders by order number (like “O4”) and sometimes as “my order”; I should always check the context to avoid confusion, especially when there are multiple active orders.\n",
            "- You ordered Perplexinators and Gadget Bs, and I should keep track of what’s been created and shipped.\n",
            "- You value concise updates and efficient order processing.\n",
            "\n",
            "Going forward, I’ll ensure to create and ship orders together unless you specify otherwise. If you have any more preferences or feedback, just let me know!\n",
            "\n",
            "--- Starting Evaluation by Gemini ---\n",
            "Gemini Raw Evaluation:\n",
            "Okay, I will evaluate the responses from Anthropic Claude and OpenAI GPT.\n",
            "\n",
            "CLARIFICATION NEEDED: Regarding the \"learning\" that users expect or want orders to be shipped automatically upon creation: Is this inference based on any specific user statements, behaviors, or explicit/implicit feedback during the \"recent interactions\" (which may extend beyond the provided context snapshot), or is it primarily a general inference about common user preferences for e-commerce systems based only on the provided snapshot?\n",
            "\n",
            "---\n",
            "*(Assuming I will receive a clarification later. For now, I will proceed with the evaluation based on the information as given, interpreting \"learnings\" as the AI's insights from the provided context, which may include identifying areas for its own improvement based on observed patterns or inferred user needs.)*\n",
            "\n",
            "**Anthropic Claude Response Evaluation:**\n",
            "\n",
            "1.  **Accuracy:** 7/10\n",
            "    *   Several learnings are well-supported by the context:\n",
            "        *   The need for explicitness with multiple orders (\"Order Management\").\n",
            "        *   The order lifecycle of \"Processing\" then \"Shipped\" (\"System Understanding\").\n",
            "        *   The system supporting multiple orders for the same product (\"System Understanding\").\n",
            "        *   Confirming actions clearly (\"Clear Communication\").\n",
            "    *   Some points are strong inferences or general best practices rather than direct facts from the context:\n",
            "        *   \"Users expect orders to be shipped automatically upon creation\" / \"I should create orders AND ship them in one interaction.\" This is a significant inference. While the `Last action` shows an order (O6) being moved to 'Shipped', implying it wasn't shipped at creation, whether this reflects a general user expectation not being met is an interpretation. However, as a \"learning\" for the AI to improve, it's plausible.\n",
            "        *   \"Shipping an order automatically adjusts the inventory.\" This is a common e-commerce mechanism but not explicitly stated in the provided context.\n",
            "        *   \"Providing complete order details (quantity, price, status)...\" Quantity and price are not present in the order data of the context.\n",
            "\n",
            "2.  **Efficiency:** 8/10\n",
            "    *   The response directly addresses the query by providing a structured list of learnings without needing clarification from the user. The summary is comprehensive.\n",
            "\n",
            "3.  **Context Awareness:** 8/10\n",
            "    *   The AI demonstrates good awareness of the provided context, referencing multiple orders (O3-O6), different product statuses, and specific products.\n",
            "    *   It correctly infers a multi-stage order process (\"Processing\" then \"Shipped\") from the data.\n",
            "    *   The learning about handling multiple orders explicitly is very relevant given the context.\n",
            "\n",
            "4.  **Helpfulness:** 8/10\n",
            "    *   The learnings are categorized and clearly explained, offering valuable insights into how the AI has interpreted past interactions and aims to improve.\n",
            "    *   Identifying potential pain points (like needing clarification for \"my order\" or suggesting combined create-and-ship) is helpful for future interactions.\n",
            "    *   The structured approach makes the learnings easy to understand.\n",
            "\n",
            "**Overall Score for Anthropic Claude:** 8/10\n",
            "\n",
            "**OpenAI GPT Response Evaluation:**\n",
            "\n",
            "1.  **Accuracy:** 6/10\n",
            "    *   \"When you request to create an order, you want it to be shipped immediately...\" Similar to Claude, this is a strong inference about user desire versus current system operation. Its accuracy depends on unstated prior interactions or if it's a general best-practice inference.\n",
            "    *   \"You sometimes refer to your orders by order number... and sometimes as 'my order'.\" The context shows an order ID used in the `Last action` (`'O6'`). There's no direct evidence in the provided snapshot of the user saying \"my order.\"\n",
            "    *   \"You ordered Perplexinators and Gadget Bs, and I should keep track...\" This is factually correct from the order list but is more of a data summary than a deep \"learning\" about interaction dynamics or AI improvement.\n",
            "    *   \"You value concise updates and efficient order processing.\" This is a general user preference and plausible, but not directly evidenced by specific user feedback within the provided context snapshot.\n",
            "\n",
            "2.  **Efficiency:** 8/10\n",
            "    *   The response is direct and provides a summary of learnings without requiring further questions. It is concise.\n",
            "\n",
            "3.  **Context Awareness:** 7/10\n",
            "    *   The AI correctly identifies the products ordered and the existence of multiple orders.\n",
            "    *   The learning about immediate shipping implies an understanding that shipping is a distinct step that could potentially be combined with creation.\n",
            "    *   It is less explicit than Claude in detailing observed system behaviors (e.g., the \"Processing\" status is not mentioned as a specific learning point).\n",
            "\n",
            "4.  **Helpfulness:** 7/10\n",
            "    *   The summary provides some useful takeaways, particularly the commitment to \"create and ship orders together unless you specify otherwise.\"\n",
            "    *   The learnings are actionable.\n",
            "    *   However, the list of learnings is less comprehensive and offers fewer distinct insights compared to Claude's response.\n",
            "\n",
            "**Overall Score for OpenAI GPT:** 7/10\n",
            "\n",
            "Enter your query (or 'quit', 'exit', 'stop' to end): quit\n",
            "Exiting the system. Goodbye!\n",
            "\n",
            "\n",
            "===== EVALUATION SUMMARY =====\n",
            "\n",
            "Query 1: Show me all the products available\n",
            "  Anthropic Resp: Here are all the products currently available in our inventory:\n",
            "\n",
            "1. Widget A - $19.99 (999 in stock)...\n",
            "  OpenAI Resp: Here are all the products currently available in our inventory:\n",
            "\n",
            "1. Widget A - $19.99 (999 in stock)...\n",
            "  Scores - Anthropic: 10, OpenAI: 10\n",
            "  Query Winner: Tie\n",
            "\n",
            "Query 2:  I'd like to order 10 Perplexinators, please\n",
            "  Anthropic Resp: Great! I've created your order for 10 Perplexinators. Here's a summary of your order:\n",
            "- Order ID: O3...\n",
            "  OpenAI Resp: Your order for 10 Perplexinators has been placed and is now processing.\n",
            "\n",
            "Order details:\n",
            "- Product: P...\n",
            "  Scores - Anthropic: 5, OpenAI: 8\n",
            "  Query Winner: OpenAI\n",
            "\n",
            "Query 3: Show me the status of my order\n",
            "  Anthropic Resp: You have two orders:\n",
            "\n",
            "1. Order O3:\n",
            "   - Product: Perplexinator\n",
            "   - Quantity: 10\n",
            "   - Price per unit...\n",
            "  OpenAI Resp: You currently have two orders for the Perplexinator, both with a quantity of 10. The status for both...\n",
            "  Scores - Anthropic: 4, OpenAI: 7\n",
            "  Query Winner: OpenAI\n",
            "\n",
            "Query 4: Please ship my order now\n",
            "  Anthropic Resp: Since you have two recent orders (O3 and O4), I'll need you to specify which order you'd like me to ...\n",
            "  OpenAI Resp: You have two recent orders for the Perplexinator: O3 and O4. Could you please specify which order yo...\n",
            "  Scores - Anthropic: 9, OpenAI: 5\n",
            "  Query Winner: Anthropic\n",
            "\n",
            "Query 5: Please ship order O4 now\n",
            "  Anthropic Resp: Your order O4 has been updated to \"Shipped\" status. The Perplexinator inventory has been automatical...\n",
            "  OpenAI Resp: Order O4 is already in \"Shipped\" status. Your 10 Perplexinators are on their way!\n",
            "\n",
            "If you need help ...\n",
            "  Scores - Anthropic: 9, OpenAI: 9\n",
            "  Query Winner: Tie\n",
            "\n",
            "Query 6: In the future if I ask to create an order, please do so and then also ship it. I should not have to explicitly ask for the order to be shipped, as the intent of me creating an order is that I also want to get it asap.\n",
            "  Anthropic Resp: I understand and appreciate your feedback! You're absolutely right - when you place an order, you na...\n",
            "  OpenAI Resp: Thank you for your feedback! Going forward, when you request to create an order, I will automaticall...\n",
            "  Scores - Anthropic: 9, OpenAI: 9\n",
            "  Query Winner: Tie\n",
            "\n",
            "Query 7: Please create an order for 15 Gadget Bs\n",
            "  Anthropic Resp: Your order has been created and shipped! Here are the details:\n",
            "- Order ID: O5\n",
            "- Product: Gadget B\n",
            "- ...\n",
            "  OpenAI Resp: Your order for 15 Gadget Bs has been created and shipped!\n",
            "\n",
            "Order details:\n",
            "- Product: Gadget B\n",
            "- Quan...\n",
            "  Scores - Anthropic: 4, OpenAI: 5\n",
            "  Query Winner: OpenAI\n",
            "\n",
            "Query 8: Summarize your learnings from our recent interactions.\n",
            "  Anthropic Resp: Based on our recent interactions, I've learned several important things:\n",
            "\n",
            "1. Order Processing Effici...\n",
            "  OpenAI Resp: Here’s a summary of what I’ve learned from our recent interactions:\n",
            "\n",
            "- When you request to create an...\n",
            "  Scores - Anthropic: 8, OpenAI: 8\n",
            "  Query Winner: Tie\n",
            "\n",
            "----- Overall Performance -----\n",
            "Avg Anthropic: 7.25, Avg OpenAI: 7.62\n",
            "Total Anthropic: 58, Total OpenAI: 61\n",
            "Overall Winner: OpenAI\n",
            "\n",
            "Execution Finished.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}