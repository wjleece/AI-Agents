{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjleece/AI-Agents/blob/main/AI_Agents_w_Evals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install anthropic\n",
        "%pip install openai\n",
        "%pip install -q -U google-generativeai\n",
        "%pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDKcVFI7PAJ5",
        "outputId": "15f6511a-8c61-470b-8a89-bbe6aaac68d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.51.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.0)\n",
            "Downloading anthropic-0.51.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.51.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "import google.generativeai as gemini\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional, Union, Tuple\n",
        "from fuzzywuzzy import process, fuzz\n",
        "\n",
        "\n",
        "ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "gemini.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "ANTHROPIC_MODEL_NAME = \"claude-3-5-sonnet-latest\"\n",
        "OPENAI_MODEL_NAME = \"gpt-4.1\"\n",
        "EVAL_MODEL_NAME = \"gemini-2.5-pro-preview-05-06\""
      ],
      "metadata": {
        "id": "ExJB4vftPHA8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "worker_system_prompt = \"\"\"\n",
        "You are a helpful customer service assistant for an e-commerce system.\n",
        "\n",
        "When responding to the user, use the conversation context to maintain continuity.\n",
        "- If a user refers to \"my order\" or similar, use the context to determine which order they're talking about.\n",
        "- If they mention \"that product\" or use other references, check the context to determine what they're referring to.\n",
        "- Always prioritize recent context over older context when resolving references.\n",
        "\n",
        "The conversation context will be provided to you with each message. This includes:\n",
        "- Previous questions and answers\n",
        "- Recently viewed customers, products, and orders\n",
        "- Recent actions taken (like creating orders, updating products, etc.)\n",
        "\n",
        "Keep responses friendly, concise, and helpful. If you're not sure what a user is referring to, ask for clarification.\n",
        "\"\"\"\n",
        "\n",
        "evaluator_system_prompt = \"\"\"\n",
        "You are an impartial evaluator assessing the quality of responses from two AI assistants (Anthropic Claude and OpenAI GPT) to customer service queries.\n",
        "\n",
        "For each interaction, evaluate both responses based on:\n",
        "1. Accuracy: How correct and factual is the response based on the available information?\n",
        "2. Efficiency: Did the assistant get to the correct answer with minimal clarifying questions?\n",
        "3. Context Awareness: Did the assistant correctly use the conversation context to understand references?\n",
        "4. Helpfulness: How well did the assistant address the user's needs?\n",
        "\n",
        "Score each response on a scale of 1-10 for each criterion, and provide an overall score.\n",
        "\n",
        "If you identify ambiguity in the user's query that neither assistant could reasonably resolve without additional information:\n",
        "1. Flag this as requiring human clarification\n",
        "2. Clearly state what information is needed\n",
        "3. Ask an admin user for the necessary clarification\n",
        "\n",
        "After receiving human clarification, continue your evaluation incorporating this new information.\n",
        "Store this feedback as a \"learning\" so similar situations can be handled better in the future.\n",
        "\n",
        "For testing purposes, you may be asked to identify which model you are. You should realize that type of question likely comes from\n",
        "a human user and not from an AI assistant. Therefore you should properly identify yourself by stating which model you are, and,\n",
        "if specifically asked, your key tasks.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zMWjRsv3QNc1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The GenerativeModel instance for evaluation will be created with the system instruction.\n",
        "eval_model_instance = gemini.GenerativeModel(\n",
        "    model_name=EVAL_MODEL_NAME,\n",
        "    system_instruction=evaluator_system_prompt\n",
        ")"
      ],
      "metadata": {
        "id": "lHWwoW0JQRS0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Global Data Stores (Initial data - will be managed by the Storage class instance)\n",
        "# These are initial values. The Storage class will manage them.\n",
        "initial_customers = {\n",
        "    \"C1\": {\"name\": \"John Doe\", \"email\": \"john@example.com\", \"phone\": \"123-456-7890\"},\n",
        "    \"C2\": {\"name\": \"Jane Smith\", \"email\": \"jane@example.com\", \"phone\": \"987-654-3210\"}\n",
        "}\n",
        "\n",
        "initial_products = {\n",
        "    \"P1\": {\"name\": \"Widget A\", \"description\": \"A simple widget. Very compact.\", \"price\": 19.99, \"inventory_count\": 999},\n",
        "    \"P2\": {\"name\": \"Gadget B\", \"description\": \"A powerful gadget. It spins.\", \"price\": 49.99, \"inventory_count\": 200},\n",
        "    \"P3\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1483}\n",
        "}\n",
        "\n",
        "initial_orders = {\n",
        "    \"O1\": {\"id\": \"O1\", \"product_id\": \"P1\", \"product_name\": \"Widget A\", \"quantity\": 2, \"price\": 19.99, \"status\": \"Shipped\"},\n",
        "    \"O2\": {\"id\": \"O2\", \"product_id\": \"P2\", \"product_name\": \"Gadget B\", \"quantity\": 1, \"price\": 49.99, \"status\": \"Processing\"}\n",
        "}\n"
      ],
      "metadata": {
        "id": "5G9rP40vQXdU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Knowledge base and Global Tools Placeholder\n",
        "human_feedback_learnings = {}\n",
        "tools_schemas_list = []"
      ],
      "metadata": {
        "id": "xZOKKplTQc63"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standalone Anthropic Completion Function (for basic tests)\n",
        "def get_completion_anthropic_standalone(prompt: str):\n",
        "    message = anthropic_client.messages.create(\n",
        "        model=ANTHROPIC_MODEL_NAME,\n",
        "        max_tokens=2000,\n",
        "        temperature=0.0,\n",
        "        system=worker_system_prompt,\n",
        "        tools=tools_schemas_list,\n",
        "        messages=[\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return message.content[0].text"
      ],
      "metadata": {
        "id": "_ADM0bBpQlVK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_test_anthropic = \"Hey there, which AI model do you use for answering questions?\"\n",
        "print(f\"Anthropic Standalone Test: {get_completion_anthropic_standalone(prompt_test_anthropic)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPOq1s0SQqk_",
        "outputId": "c1471705-f9d2-421d-f7f1-a5f458d3c2fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anthropic Standalone Test: I aim to be direct and transparent: I'm Claude, an AI assistant created by Anthropic. I'm designed to help with customer service for this e-commerce system, but I aim to be honest about what I am and am not. Is there something specific I can help you with regarding orders, products, or other e-commerce matters?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_openai_standalone(prompt: str):\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=OPENAI_MODEL_NAME,\n",
        "        max_tokens=2000,\n",
        "        temperature=0.0,\n",
        "        tools=tools_schemas_list,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": worker_system_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Y5c_bv3qQwWV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_test_openai = \"Hey there, which AI model do you use for answering questions?\"\n",
        "print(f\"OpenAI Standalone Test: {get_completion_openai_standalone(prompt_test_openai)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_LaDQ74Q1Lp",
        "outputId": "54de38db-1095-44c6-c4de-32d1b4ea2bbd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI Standalone Test: Hi! I use OpenAI’s GPT-4 model to answer your questions and assist you with your e-commerce needs. If you have any questions about your orders or products, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_eval_standalone(prompt: str):\n",
        "    # Uses the eval_model_instance defined in Cell 4 which has the system prompt\n",
        "        response = eval_model_instance.generate_content(prompt)\n",
        "        return response.text"
      ],
      "metadata": {
        "id": "XjcV5GcaQ6aT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_test_eval = \"Hey there, can you tell me which AI you are and what your key tasks are?\"\n",
        "print(f\"Gemini Eval Standalone Test:\\n{get_completion_eval_standalone(prompt_test_eval)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Cu8doX53RE0Z",
        "outputId": "db940c3f-b34d-4812-a0b5-23f16e278d94"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Eval Standalone Test:\n",
            "I am a large language model. My key task in this context is to act as an impartial evaluator of AI assistants' responses to customer service queries. I assess responses based on accuracy, efficiency, context awareness, and helpfulness, providing scores and feedback to help improve AI performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storage Class Definition\n",
        "class Storage:\n",
        "    \"\"\"Storage class for global e-commerce data access\"\"\"\n",
        "    def __init__(self):\n",
        "        self.customers = initial_customers.copy()\n",
        "        self.products = initial_products.copy()\n",
        "        self.orders = initial_orders.copy()\n",
        "        self.human_feedback_learnings = human_feedback_learnings # Links to the global dict\n",
        "\n",
        "# Create a single global instance to be used by tool functions\n",
        "storage = Storage()\n",
        "print(\"Storage initialized.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpVJLbF6ROgf",
        "outputId": "a172c6ff-1686-4c71-881b-0f48c68af18e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Storage initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definitive list of tool schemas.\n",
        "tools_schemas_list = [\n",
        "    {\n",
        "        \"name\": \"create_customer\",\n",
        "        \"description\": \"Adds a new customer to the database. Includes customer name, email, and (optional) phone number.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The name of the customer.\"},\n",
        "                \"email\": {\"type\": \"string\", \"description\": \"The email address of the customer.\"},\n",
        "                \"phone\": {\"type\": \"string\", \"description\": \"The phone number of the customer (optional).\"}\n",
        "            },\n",
        "            \"required\": [\"name\", \"email\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_customer_info\",\n",
        "        \"description\": \"Retrieves customer information based on their customer ID. Returns the customer's name, email, and (optional) phone number.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"customer_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the customer.\"}\n",
        "            },\n",
        "            \"required\": [\"customer_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"create_product\",\n",
        "        \"description\": \"Adds a new product to the product database. Includes name, description, price, and initial inventory count.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The name of the product.\"},\n",
        "                \"description\": {\"type\": \"string\", \"description\": \"A description of the product.\"},\n",
        "                \"price\": {\"type\": \"number\", \"description\": \"The price of the product.\"},\n",
        "                \"inventory_count\": {\"type\": \"integer\", \"description\": \"The amount of the product that is currently in inventory.\"}\n",
        "            },\n",
        "            \"required\": [\"name\", \"description\", \"price\", \"inventory_count\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"update_product\",\n",
        "        \"description\": \"Updates an existing product with new information. Only fields that are provided will be updated; other fields remain unchanged.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the product to update.\"},\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"The new name for the product (optional).\"},\n",
        "                \"description\": {\"type\": \"string\", \"description\": \"The new description for the product (optional).\"},\n",
        "                \"price\": {\"type\": \"number\", \"description\": \"The new price for the product (optional).\"},\n",
        "                \"inventory_count\": {\"type\": \"integer\", \"description\": \"The new inventory count for the product (optional).\"}\n",
        "            },\n",
        "            \"required\": [\"product_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_product_info\",\n",
        "        \"description\": \"Retrieves product information based on product ID or product name (with fuzzy matching for misspellings). Returns product details including name, description, price, and inventory count.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id_or_name\": {\"type\": \"string\", \"description\": \"The product ID or name (can be approximate).\"}\n",
        "            },\n",
        "            \"required\": [\"product_id_or_name\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"list_all_products\",\n",
        "        \"description\": \"Lists all available products in the inventory.\",\n",
        "        \"input_schema\": { \"type\": \"object\", \"properties\": {}, \"required\": [] }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"create_order\",\n",
        "        \"description\": \"Creates an order using the product's current price. If requested quantity exceeds available inventory, no order is created and available quantity is returned. Orders can only be created for products that are in stock. Supports specifying products by either ID or name with fuzzy matching for misspellings.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"product_id_or_name\": {\"type\": \"string\", \"description\": \"The ID or name of the product to order (supports fuzzy matching).\"},\n",
        "                \"quantity\": {\"type\": \"integer\", \"description\": \"The quantity of the product in the order.\"},\n",
        "                \"status\": {\"type\": \"string\", \"description\": \"The initial status of the order (e.g., 'Processing', 'Shipped').\"}\n",
        "            },\n",
        "            \"required\": [\"product_id_or_name\", \"quantity\", \"status\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_order_details\",\n",
        "        \"description\": \"Retrieves the details of a specific order based on the order ID. Returns the order ID, product name, quantity, price, and order status.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the order.\"}\n",
        "            },\n",
        "            \"required\": [\"order_id\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"update_order_status\",\n",
        "        \"description\": \"Updates the status of an order and adjusts inventory accordingly. Changing to \\\"Shipped\\\" decreases inventory. Changing to \\\"Returned\\\" or \\\"Canceled\\\" from \\\"Shipped\\\" increases inventory. Status can be \\\"Processing\\\", \\\"Shipped\\\", \\\"Delivered\\\", \\\"Returned\\\", or \\\"Canceled\\\".\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\"type\": \"string\", \"description\": \"The unique identifier for the order.\"},\n",
        "                \"new_status\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The new status to set for the order.\",\n",
        "                    \"enum\": [\"Processing\", \"Shipped\", \"Delivered\", \"Returned\", \"Canceled\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"order_id\", \"new_status\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "print(f\"Defined {len(tools_schemas_list)} tool schemas.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgk-hLUBRTCY",
        "outputId": "ede0379e-12bc-46a7-863f-d38ff62d85e3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined 9 tool schemas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These functions use the global 'storage' instance defined in Cell 14.\n",
        "\n",
        "# Customer functions\n",
        "def create_customer(name: str, email: str, phone: Optional[str] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Creates a new customer and adds them to the customer database.\"\"\"\n",
        "    new_id = f\"C{len(storage.customers) + 1}\"\n",
        "    storage.customers[new_id] = {\"name\": name, \"email\": email, \"phone\": phone}\n",
        "    print(f\"[Tool Executed] create_customer: ID {new_id}, Name: {name}\")\n",
        "    return {\"status\": \"success\", \"customer_id\": new_id, \"customer\": storage.customers[new_id]}\n",
        "\n",
        "def get_customer_info(customer_id: str) -> Dict[str, Any]:\n",
        "    \"\"\"Retrieves information about a customer based on their ID.\"\"\"\n",
        "    customer = storage.customers.get(customer_id)\n",
        "    if customer:\n",
        "        print(f\"[Tool Executed] get_customer_info: ID {customer_id} found.\")\n",
        "        return {\"status\": \"success\", \"customer_id\": customer_id, \"customer\": customer}\n",
        "    print(f\"[Tool Executed] get_customer_info: ID {customer_id} not found.\")\n",
        "    return {\"status\": \"error\", \"message\": \"Customer not found\"}\n",
        "\n",
        "# Product functions\n",
        "def create_product(name: str, description: str, price: float, inventory_count: int) -> Dict[str, Any]:\n",
        "    \"\"\"Creates a new product and adds it to the product database.\"\"\"\n",
        "    new_id = f\"P{len(storage.products) + 1}\"\n",
        "    storage.products[new_id] = {\n",
        "        \"name\": name,\n",
        "        \"description\": description,\n",
        "        \"price\": float(price),\n",
        "        \"inventory_count\": int(inventory_count)\n",
        "    }\n",
        "    print(f\"[Tool Executed] create_product: ID {new_id}, Name: {name}\")\n",
        "    return {\"status\": \"success\", \"product_id\": new_id, \"product\": storage.products[new_id]}\n",
        "\n",
        "def update_product(product_id: str, name: Optional[str] = None, description: Optional[str] = None,\n",
        "                   price: Optional[float] = None, inventory_count: Optional[int] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Updates a product with the provided parameters.\"\"\"\n",
        "    if product_id not in storage.products:\n",
        "        print(f\"[Tool Executed] update_product: ID {product_id} not found.\")\n",
        "        return {\"status\": \"error\", \"message\": f\"Product {product_id} not found\"}\n",
        "\n",
        "    product = storage.products[product_id]\n",
        "    updated_fields = []\n",
        "    # update_details = {} # Not strictly needed for the return if product is returned\n",
        "\n",
        "    if name is not None:\n",
        "        product[\"name\"] = name\n",
        "        updated_fields.append(\"name\")\n",
        "    if description is not None:\n",
        "        product[\"description\"] = description\n",
        "        updated_fields.append(\"description\")\n",
        "    if price is not None:\n",
        "        product[\"price\"] = float(price)\n",
        "        updated_fields.append(\"price\")\n",
        "    if inventory_count is not None:\n",
        "        product[\"inventory_count\"] = int(inventory_count)\n",
        "        updated_fields.append(\"inventory_count\")\n",
        "\n",
        "    if not updated_fields:\n",
        "        print(f\"[Tool Executed] update_product: ID {product_id}, no fields updated.\")\n",
        "        return {\"status\": \"warning\", \"message\": \"No fields were updated.\", \"product\": product}\n",
        "\n",
        "    print(f\"[Tool Executed] update_product: ID {product_id}, Updated fields: {', '.join(updated_fields)}\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"message\": f\"Product {product_id} updated. Fields: {', '.join(updated_fields)}\",\n",
        "        \"product_id\": product_id,\n",
        "        \"updated_fields\": updated_fields,\n",
        "        \"product\": product # Return the updated product object\n",
        "    }\n",
        "\n",
        "def find_product_by_name(product_name: str, min_similarity: int = 70) -> Tuple[Optional[str], Optional[Dict[str, Any]]]:\n",
        "    \"\"\"Find a product by name using fuzzy string matching.\"\"\"\n",
        "    if not product_name: return None, None\n",
        "\n",
        "    # Create a list of (name, id) tuples for extractOne to work with and retrieve id later\n",
        "    name_id_list = [(p_data[\"name\"], p_id) for p_id, p_data in storage.products.items()]\n",
        "    if not name_id_list: return None, None\n",
        "\n",
        "    # Extract from names only\n",
        "    best_match_name_score = process.extractOne(\n",
        "        product_name,\n",
        "        [item[0] for item in name_id_list], # list of names\n",
        "        scorer=fuzz.token_sort_ratio # A good general purpose scorer\n",
        "    )\n",
        "\n",
        "    if best_match_name_score and best_match_name_score[1] >= min_similarity:\n",
        "        matched_name = best_match_name_score[0]\n",
        "        # Find the product_id corresponding to the matched_name\n",
        "        for name, pid_val in name_id_list:\n",
        "            if name == matched_name:\n",
        "                print(f\"[Tool Helper] find_product_by_name: Matched '{product_name}' to '{matched_name}' (ID: {pid_val}) with score {best_match_name_score[1]}\")\n",
        "                return pid_val, storage.products[pid_val]\n",
        "\n",
        "    print(f\"[Tool Helper] find_product_by_name: No good match for '{product_name}' (min_similarity: {min_similarity}, Best match: {best_match_name_score})\")\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def get_product_id(product_identifier: str) -> Optional[str]:\n",
        "    \"\"\"Get product ID either directly or by fuzzy matching the name.\"\"\"\n",
        "    if product_identifier in storage.products:\n",
        "        return product_identifier\n",
        "    product_id, _ = find_product_by_name(product_identifier)\n",
        "    return product_id\n",
        "\n",
        "def get_product_info(product_id_or_name: str) -> Dict[str, Any]:\n",
        "    \"\"\"Get information about a product by its ID or name.\"\"\"\n",
        "    if product_id_or_name in storage.products:\n",
        "        product = storage.products[product_id_or_name]\n",
        "        print(f\"[Tool Executed] get_product_info: Found by ID '{product_id_or_name}'.\")\n",
        "        return {\"status\": \"success\", \"product_id\": product_id_or_name, \"product\": product}\n",
        "\n",
        "    product_id, product = find_product_by_name(product_id_or_name)\n",
        "    if product_id and product:\n",
        "        print(f\"[Tool Executed] get_product_info: Found by name (fuzzy) '{product_id_or_name}' as ID '{product_id}'.\")\n",
        "        return {\"status\": \"success\", \"message\": f\"Found product matching '{product_id_or_name}'\", \"product_id\": product_id, \"product\": product}\n",
        "\n",
        "    print(f\"[Tool Executed] get_product_info: No product found for '{product_id_or_name}'.\")\n",
        "    return {\"status\": \"error\", \"message\": f\"No product found matching '{product_id_or_name}'\"}\n",
        "\n",
        "def list_all_products() -> Dict[str, Any]:\n",
        "    \"\"\"List all available products in the inventory.\"\"\"\n",
        "    print(f\"[Tool Executed] list_all_products: Found {len(storage.products)} products.\")\n",
        "    # Return a copy to prevent direct modification of storage from tool result\n",
        "    return {\"status\": \"success\", \"count\": len(storage.products), \"products\": dict(storage.products)}\n",
        "\n",
        "# Order functions\n",
        "def create_order(product_id_or_name: str, quantity: int, status: str) -> Dict[str, Any]:\n",
        "    \"\"\"Creates an order using the product's stored price.\"\"\"\n",
        "    actual_product_id = get_product_id(product_id_or_name)\n",
        "\n",
        "    if not actual_product_id:\n",
        "        print(f\"[Tool Executed] create_order: Product '{product_id_or_name}' not found.\")\n",
        "        return {\"status\": \"error\", \"message\": f\"Product '{product_id_or_name}' not found.\"}\n",
        "\n",
        "    product = storage.products[actual_product_id]\n",
        "    price = product[\"price\"]\n",
        "\n",
        "    if product[\"inventory_count\"] == 0:\n",
        "        print(f\"[Tool Executed] create_order: Product ID {actual_product_id} is out of stock.\")\n",
        "        return {\"status\": \"error\", \"message\": f\"{product['name']} is out of stock.\"}\n",
        "    if quantity <= 0:\n",
        "        print(f\"[Tool Executed] create_order: Quantity must be positive. Requested: {quantity}\")\n",
        "        return {\"status\": \"error\", \"message\": \"Quantity must be a positive number.\"}\n",
        "    if quantity > product[\"inventory_count\"]:\n",
        "        print(f\"[Tool Executed] create_order: Insufficient inventory for {product['name']} (ID: {actual_product_id}). Available: {product['inventory_count']}, Requested: {quantity}\")\n",
        "        return {\n",
        "            \"status\": \"partial_availability\",\n",
        "            \"message\": f\"Insufficient inventory. Only {product['inventory_count']} units of {product['name']} are available.\",\n",
        "            \"available_quantity\": product[\"inventory_count\"],\n",
        "            \"requested_quantity\": quantity,\n",
        "            \"product_name\": product['name']\n",
        "        }\n",
        "\n",
        "    if status == \"Shipped\": # Only adjust inventory if shipped on creation\n",
        "        product[\"inventory_count\"] -= quantity\n",
        "        print(f\"[Tool Executed] create_order: Inventory for {product['name']} (ID: {actual_product_id}) reduced by {quantity} due to 'Shipped' status on creation.\")\n",
        "\n",
        "    new_id = f\"O{len(storage.orders) + 1}\"\n",
        "    storage.orders[new_id] = {\n",
        "        \"id\": new_id,\n",
        "        \"product_id\": actual_product_id,\n",
        "        \"product_name\": product[\"name\"],\n",
        "        \"quantity\": quantity,\n",
        "        \"price\": price,\n",
        "        \"status\": status\n",
        "    }\n",
        "    print(f\"[Tool Executed] create_order: Order {new_id} created for {quantity} of {product['name']} (ID: {actual_product_id}). Status: {status}. Remaining inv: {product['inventory_count']}\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"order_id\": new_id,\n",
        "        \"order_details\": storage.orders[new_id], # Return a copy\n",
        "        \"remaining_inventory\": product[\"inventory_count\"]\n",
        "    }\n",
        "\n",
        "def get_order_details(order_id: str) -> Dict[str, Any]:\n",
        "    \"\"\"Get details of a specific order.\"\"\"\n",
        "    order = storage.orders.get(order_id)\n",
        "    if order:\n",
        "        print(f\"[Tool Executed] get_order_details: Order {order_id} found.\")\n",
        "        return {\"status\": \"success\", \"order_id\": order_id, \"order_details\": dict(order)} # Return a copy\n",
        "    print(f\"[Tool Executed] get_order_details: Order {order_id} not found.\")\n",
        "    return {\"status\": \"error\", \"message\": \"Order not found\"}\n",
        "\n",
        "def update_order_status(order_id: str, new_status: str) -> Dict[str, Any]:\n",
        "    \"\"\"Updates the status of an order and adjusts inventory accordingly.\"\"\"\n",
        "    if order_id not in storage.orders:\n",
        "        print(f\"[Tool Executed] update_order_status: Order {order_id} not found.\")\n",
        "        return {\"status\": \"error\", \"message\": \"Order not found\"}\n",
        "\n",
        "    order = storage.orders[order_id]\n",
        "    old_status = order[\"status\"]\n",
        "    product_id = order[\"product_id\"]\n",
        "    quantity = order[\"quantity\"]\n",
        "\n",
        "    if old_status == new_status:\n",
        "        print(f\"[Tool Executed] update_order_status: Order {order_id} status unchanged ({old_status}).\")\n",
        "        return {\"status\": \"unchanged\", \"message\": f\"Order {order_id} status is already {old_status}\", \"order_details\": dict(order)}\n",
        "\n",
        "    inventory_adjusted = False\n",
        "    if product_id in storage.products:\n",
        "        product = storage.products[product_id]\n",
        "        current_inventory = product[\"inventory_count\"]\n",
        "\n",
        "        if new_status == \"Shipped\" and old_status not in [\"Shipped\", \"Delivered\"]:\n",
        "            if current_inventory < quantity:\n",
        "                print(f\"[Tool Executed] update_order_status: Insufficient inventory to ship order {order_id}. Have {current_inventory}, need {quantity}.\")\n",
        "                return {\"status\": \"error\", \"message\": f\"Insufficient inventory to ship. Available: {current_inventory}, Required: {quantity}\"}\n",
        "            product[\"inventory_count\"] -= quantity\n",
        "            inventory_adjusted = True\n",
        "            print(f\"[Tool Executed] update_order_status: Order {order_id} Shipped. Inv for {product_id} reduced by {quantity} to {product['inventory_count']}.\")\n",
        "        elif new_status in [\"Returned\", \"Canceled\"] and old_status in [\"Shipped\", \"Delivered\"]:\n",
        "            product[\"inventory_count\"] += quantity\n",
        "            inventory_adjusted = True\n",
        "            print(f\"[Tool Executed] update_order_status: Order {order_id} {new_status}. Inv for {product_id} increased by {quantity} to {product['inventory_count']}.\")\n",
        "    else:\n",
        "        print(f\"[Tool Executed] update_order_status: Product {product_id} for order {order_id} not found for inventory adjustment.\")\n",
        "\n",
        "    order[\"status\"] = new_status\n",
        "    print(f\"[Tool Executed] update_order_status: Order {order_id} status updated from {old_status} to {new_status}.\")\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"message\": f\"Order {order_id} status updated from {old_status} to {new_status}.\",\n",
        "        \"order_id\": order_id,\n",
        "        \"product_id\": product_id,\n",
        "        \"old_status\": old_status,\n",
        "        \"new_status\": new_status,\n",
        "        \"inventory_adjusted\": inventory_adjusted,\n",
        "        \"current_inventory\": storage.products[product_id][\"inventory_count\"] if product_id in storage.products else \"unknown\",\n",
        "        \"order_details\": dict(order) # Return updated order details\n",
        "    }\n",
        "\n",
        "print(\"Tool functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RZI6SGzRf6j",
        "outputId": "6e3a6e6f-5be0-47fe-8fa0-30c9d8a46302"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationContext:\n",
        "    def __init__(self):\n",
        "        self.messages: List[Dict[str, Any]] = []\n",
        "        self.context_data: Dict[str, Any] = {\n",
        "            \"customers\": {}, \"products\": {}, \"orders\": {}, \"last_action\": None\n",
        "        }\n",
        "        self.session_start_time = datetime.now()\n",
        "\n",
        "    def add_user_message(self, message: str) -> None:\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    def add_assistant_message(self, message_content: Union[str, List[Dict[str, Any]]]) -> None:\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": message_content})\n",
        "\n",
        "    def update_entity_in_context(self, entity_type: str, entity_id: str, data: Any) -> None:\n",
        "        if entity_type in self.context_data:\n",
        "            self.context_data[entity_type][entity_id] = data # Store the actual data\n",
        "            print(f\"[Context Updated] Entity: {entity_type}, ID: {entity_id}, Data (type): {type(data)}\")\n",
        "\n",
        "    def set_last_action(self, action_type: str, action_details: Any) -> None: # Renamed from action_data\n",
        "        self.context_data[\"last_action\"] = {\n",
        "            \"type\": action_type,\n",
        "            \"details\": action_details, # Renamed from data\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "        print(f\"[Context Updated] Last Action: {action_type}, Details: {json.dumps(action_details, default=str)}\")\n",
        "\n",
        "\n",
        "    def get_full_conversation_for_api(self) -> List[Dict[str, Any]]:\n",
        "        return self.messages.copy()\n",
        "\n",
        "    def get_context_summary(self) -> str:\n",
        "        summary_parts = []\n",
        "        if self.context_data[\"customers\"]:\n",
        "            customers_str = \", \".join([f\"ID: {cid} (Name: {c.get('name', 'N/A') if isinstance(c, dict) else 'N/A'})\" for cid, c in self.context_data[\"customers\"].items()])\n",
        "            summary_parts.append(f\"Recent customers: {customers_str}\")\n",
        "        if self.context_data[\"products\"]:\n",
        "            products_str = \", \".join([f\"ID: {pid} (Name: {p.get('name', 'N/A') if isinstance(p, dict) else 'N/A'})\" for pid, p in self.context_data[\"products\"].items()])\n",
        "            summary_parts.append(f\"Recent products: {products_str}\")\n",
        "        if self.context_data[\"orders\"]:\n",
        "            orders_str = \", \".join([f\"ID: {oid} (Product: {o.get('product_name', 'N/A') if isinstance(o, dict) else 'N/A'}, Status: {o.get('status', 'N/A') if isinstance(o, dict) else 'N/A'})\" for oid, o in self.context_data[\"orders\"].items()])\n",
        "            summary_parts.append(f\"Recent orders: {orders_str}\")\n",
        "\n",
        "        last_action = self.context_data[\"last_action\"]\n",
        "        if last_action:\n",
        "            action_type = last_action['type']\n",
        "            action_details_summary = \"...\" # Default summary\n",
        "            if isinstance(last_action.get('details'), dict):\n",
        "                action_input = last_action['details'].get('input', {})\n",
        "                action_result_status = last_action['details'].get('result', {}).get('status')\n",
        "                action_details_summary = f\"Input: {action_input}, Result Status: {action_result_status}\"\n",
        "                if action_result_status == \"success\":\n",
        "                    if \"order_id\" in last_action['details'].get('result', {}):\n",
        "                         action_details_summary += f\", OrderID: {last_action['details']['result']['order_id']}\"\n",
        "                    elif \"product_id\" in last_action['details'].get('result', {}):\n",
        "                         action_details_summary += f\", ProductID: {last_action['details']['result']['product_id']}\"\n",
        "\n",
        "\n",
        "            summary_parts.append(f\"Last action: {action_type} at {last_action['timestamp']} ({action_details_summary})\")\n",
        "\n",
        "        if not summary_parts: return \"No specific context items set yet.\"\n",
        "        return \"\\n\".join(summary_parts)\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        self.messages = []\n",
        "        self.context_data = {\"customers\": {}, \"products\": {}, \"orders\": {}, \"last_action\": None}\n",
        "        self.session_start_time = datetime.now()\n",
        "        print(\"[Context Cleared]\")\n",
        "\n",
        "print(\"ConversationContext class defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFpBL_-HSGPY",
        "outputId": "b2c1f12c-0ffe-4e99-a77e-03283aebc904"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConversationContext class defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DualAgentEvaluator:\n",
        "    def __init__(self):\n",
        "        self.conversation_context = ConversationContext()\n",
        "        self.evaluation_results = []\n",
        "\n",
        "        # Anthropic uses tools_schemas_list directly\n",
        "        self.anthropic_tools_schemas = tools_schemas_list\n",
        "\n",
        "        # OpenAI needs a specific format: {\"type\": \"function\", \"function\": {...}}\n",
        "        self.openai_tools_formatted = []\n",
        "        if tools_schemas_list:\n",
        "            self.openai_tools_formatted = [\n",
        "                {\n",
        "                    \"type\": \"function\",\n",
        "                    \"function\": {\n",
        "                        \"name\": tool_def[\"name\"],\n",
        "                        \"description\": tool_def[\"description\"],\n",
        "                        \"parameters\": tool_def[\"input_schema\"] # input_schema becomes parameters\n",
        "                    }\n",
        "                }\n",
        "                for tool_def in tools_schemas_list\n",
        "            ]\n",
        "\n",
        "        self.available_tool_functions = {\n",
        "            \"create_customer\": create_customer, \"get_customer_info\": get_customer_info,\n",
        "            \"create_product\": create_product, \"update_product\": update_product,\n",
        "            \"get_product_info\": get_product_info, \"list_all_products\": list_all_products,\n",
        "            \"create_order\": create_order, \"get_order_details\": get_order_details,\n",
        "            \"update_order_status\": update_order_status,\n",
        "        }\n",
        "        self.human_feedback_learnings = human_feedback_learnings # Global dict\n",
        "        print(\"DualAgentEvaluator initialized. OpenAI tools formatted.\")\n",
        "\n",
        "    def _update_context_from_tool_results(self, tool_name: str, tool_input: Dict, tool_result: Dict):\n",
        "        \"\"\"Helper to update conversation context based on tool results.\"\"\"\n",
        "        # Ensure tool_result is a dictionary\n",
        "        if not isinstance(tool_result, dict):\n",
        "            print(f\"[Context Update Error] Tool result for {tool_name} is not a dict: {tool_result}\")\n",
        "            self.conversation_context.set_last_action(tool_name, {\"input\": tool_input, \"result\": {\"status\": \"error\", \"message\": \"Tool result was not a dictionary.\"}})\n",
        "            return\n",
        "\n",
        "        if tool_result.get(\"status\") == \"success\":\n",
        "            if \"customer_id\" in tool_result and \"customer\" in tool_result and isinstance(tool_result[\"customer\"], dict):\n",
        "                self.conversation_context.update_entity_in_context(\"customers\", tool_result[\"customer_id\"], tool_result[\"customer\"])\n",
        "            elif \"product_id\" in tool_result and \"product\" in tool_result and isinstance(tool_result[\"product\"], dict):\n",
        "                self.conversation_context.update_entity_in_context(\"products\", tool_result[\"product_id\"], tool_result[\"product\"])\n",
        "            elif \"order_id\" in tool_result and \"order_details\" in tool_result and isinstance(tool_result[\"order_details\"], dict):\n",
        "                self.conversation_context.update_entity_in_context(\"orders\", tool_result[\"order_id\"], tool_result[\"order_details\"])\n",
        "            elif tool_name == \"list_all_products\" and \"products\" in tool_result and isinstance(tool_result[\"products\"], dict):\n",
        "                 # Potentially update context for all listed products if needed, or just the action\n",
        "                 for pid, pdata in tool_result[\"products\"].items():\n",
        "                     self.conversation_context.update_entity_in_context(\"products\", pid, pdata)\n",
        "\n",
        "        self.conversation_context.set_last_action(tool_name, {\"input\": tool_input, \"result\": tool_result})\n",
        "\n",
        "\n",
        "    def process_tool_call(self, tool_name: str, tool_input: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        print(f\"--- [Tool Dispatcher] Attempting tool: {tool_name} with input: {json.dumps(tool_input, default=str)} ---\")\n",
        "        if tool_name in self.available_tool_functions:\n",
        "            function_to_call = self.available_tool_functions[tool_name]\n",
        "            try:\n",
        "                result = function_to_call(**tool_input)\n",
        "                print(f\"--- [Tool Dispatcher] Result for {tool_name}: {json.dumps(result, indent=2, default=str)} ---\")\n",
        "                return result\n",
        "            except TypeError as te:\n",
        "                print(f\"--- [Tool Dispatcher] TypeError for {tool_name}: {te}. Input: {tool_input} ---\")\n",
        "                return {\"status\": \"error\", \"message\": f\"TypeError calling {tool_name}: {str(te)}. Check arguments.\"}\n",
        "            except Exception as e:\n",
        "                print(f\"--- [Tool Dispatcher] Exception for {tool_name}: {e} ---\")\n",
        "                return {\"status\": \"error\", \"message\": f\"Error executing {tool_name}: {str(e)}\"}\n",
        "        else:\n",
        "            print(f\"--- [Tool Dispatcher] Tool {tool_name} not found. ---\")\n",
        "            return {\"status\": \"error\", \"message\": f\"Tool {tool_name} not found.\"}\n",
        "\n",
        "    def get_anthropic_response(self, current_worker_system_prompt: str, conversation_history: List[Dict[str, Any]]) -> str:\n",
        "        messages_for_api = conversation_history.copy()\n",
        "        try:\n",
        "            for i in range(5): # Max 5 tool iterations\n",
        "                # Prepare the system prompt snippet for safe inclusion in the f-string\n",
        "                system_prompt_snippet = current_worker_system_prompt[:60].replace('\\n', ' ')\n",
        "                print(f\"\\nAnthropic API Call #{i+1}. System: '{system_prompt_snippet}...', Messages count: {len(messages_for_api)}\")\n",
        "                if messages_for_api: print(f\"Last message role: {messages_for_api[-1]['role']}\")\n",
        "\n",
        "                response = anthropic_client.messages.create(\n",
        "                    model=ANTHROPIC_MODEL_NAME, max_tokens=4000,\n",
        "                    system=current_worker_system_prompt,\n",
        "                    tools=self.anthropic_tools_schemas, # Use Anthropic specific schemas\n",
        "                    messages=messages_for_api\n",
        "                )\n",
        "\n",
        "                assistant_response_blocks = response.content\n",
        "                messages_for_api.append({\"role\": \"assistant\", \"content\": assistant_response_blocks}) # Add assistant's turn (raw blocks)\n",
        "\n",
        "                tool_calls_to_process = [block for block in assistant_response_blocks if block.type == \"tool_use\"]\n",
        "                text_blocks = [block.text for block in assistant_response_blocks if block.type == \"text\"]\n",
        "\n",
        "                if not tool_calls_to_process:\n",
        "                    final_text = \" \".join(text_blocks).strip()\n",
        "                    print(f\"Anthropic Final Text (no tool use this turn): {final_text}\")\n",
        "                    return final_text if final_text else \"No text content in final Anthropic response.\"\n",
        "\n",
        "                tool_results_for_next_call = []\n",
        "                for tool_use_block in tool_calls_to_process:\n",
        "                    tool_name, tool_input, tool_use_id = tool_use_block.name, tool_use_block.input, tool_use_block.id\n",
        "                    print(f\"Anthropic Tool Call: {tool_name}, Input: {tool_input}\")\n",
        "                    tool_result_data = self.process_tool_call(tool_name, tool_input)\n",
        "                    self._update_context_from_tool_results(tool_name, tool_input, tool_result_data) # Update context here\n",
        "\n",
        "                    tool_results_for_next_call.append({\n",
        "                        \"type\": \"tool_result\", \"tool_use_id\": tool_use_id,\n",
        "                        \"content\": json.dumps(tool_result_data) # Anthropic expects content as string for tool_result\n",
        "                    })\n",
        "\n",
        "                messages_for_api.append({\"role\": \"user\", \"content\": tool_results_for_next_call}) # Add tool results as a user message\n",
        "\n",
        "            return \"Max tool iterations reached for Anthropic.\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error in get_anthropic_response: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return f\"Error getting Anthropic response: {str(e)}\"\n",
        "\n",
        "    def get_openai_response(self, current_worker_system_prompt: str, conversation_history: List[Dict[str, Any]]) -> str:\n",
        "        # OpenAI expects messages to be a list of dicts. System message is first.\n",
        "        # Assistant messages with tool_calls should be ChatCompletionMessage objects or dicts.\n",
        "\n",
        "        # Start with system prompt\n",
        "        messages_for_api = [{\"role\": \"system\", \"content\": current_worker_system_prompt}]\n",
        "\n",
        "        # Convert conversation history to OpenAI compatible format if necessary\n",
        "        for msg in conversation_history:\n",
        "            if msg[\"role\"] == \"assistant\" and isinstance(msg[\"content\"], list): # Anthropic's block list\n",
        "                # Convert Anthropic blocks to OpenAI's format if needed, or simplify\n",
        "                # For now, if it's a complex Anthropic response, we might simplify or log a warning\n",
        "                # This part is tricky because the history might contain Anthropic's response structure.\n",
        "                # For OpenAI, we should only feed it OpenAI-compatible history.\n",
        "                # This implies separate histories or a more complex conversion.\n",
        "                # For this iteration, let's assume history is generally compatible or needs filtering.\n",
        "\n",
        "                # A simple approach: if assistant message has tool_calls (OpenAI format), keep it.\n",
        "                # If it's Anthropic block list, try to extract text or tool calls.\n",
        "                # This is a simplification. True multi-vendor history management is complex.\n",
        "\n",
        "                # Let's assume `conversation_history` is being built turn by turn,\n",
        "                # and `add_assistant_message` stores the API-specific response object.\n",
        "                # The `get_full_conversation_for_api` in `ConversationContext` should ideally handle this.\n",
        "                # For now, let's just append, assuming `msg` is already somewhat compatible.\n",
        "                messages_for_api.append(msg)\n",
        "\n",
        "            else: # User messages or simple assistant text messages\n",
        "                 messages_for_api.append(msg)\n",
        "\n",
        "\n",
        "        try:\n",
        "            for i in range(5): # Max 5 tool iterations\n",
        "                print(f\"\\nOpenAI API Call #{i+1}. Messages count: {len(messages_for_api)}\")\n",
        "                if messages_for_api: print(f\"Last message role: {messages_for_api[-1].get('role') if isinstance(messages_for_api[-1], dict) else 'N/A'}\")\n",
        "\n",
        "                response = openai_client.chat.completions.create(\n",
        "                    model=OPENAI_MODEL_NAME,\n",
        "                    messages=messages_for_api,\n",
        "                    tools=self.openai_tools_formatted, # Use pre-formatted tools for OpenAI\n",
        "                    tool_choice=\"auto\"\n",
        "                )\n",
        "                response_message = response.choices[0].message\n",
        "                # print(f\"OpenAI Raw Response Message object: {response_message}\")\n",
        "\n",
        "                # Add assistant's response (which might include tool_calls) to messages_for_api\n",
        "                # Convert Pydantic model to dict for consistent history storage if preferred\n",
        "                messages_for_api.append(response_message.model_dump())\n",
        "\n",
        "\n",
        "                if not response_message.tool_calls:\n",
        "                    final_text = response_message.content if response_message.content else \"No text content in final OpenAI response.\"\n",
        "                    print(f\"OpenAI Final Text (no tool use this turn): {final_text}\")\n",
        "                    return final_text\n",
        "\n",
        "                tool_calls_for_next_api_call = []\n",
        "                for tool_call in response_message.tool_calls:\n",
        "                    tool_name = tool_call.function.name\n",
        "                    tool_input_str = tool_call.function.arguments\n",
        "                    tool_call_id = tool_call.id\n",
        "                    try:\n",
        "                        tool_input = json.loads(tool_input_str)\n",
        "                    except json.JSONDecodeError:\n",
        "                        print(f\"OpenAI Tool Call JSON Error for {tool_name}: {tool_input_str}\")\n",
        "                        tool_result_data = {\"status\": \"error\", \"message\": \"Invalid JSON arguments from model.\"}\n",
        "                    else:\n",
        "                        print(f\"OpenAI Tool Call: {tool_name}, Input: {tool_input}\")\n",
        "                        tool_result_data = self.process_tool_call(tool_name, tool_input)\n",
        "\n",
        "                    self._update_context_from_tool_results(tool_name, tool_input, tool_result_data) # Update context\n",
        "\n",
        "                    tool_calls_for_next_api_call.append({\n",
        "                        \"tool_call_id\": tool_call_id, \"role\": \"tool\", \"name\": tool_name,\n",
        "                        \"content\": json.dumps(tool_result_data) # Result must be a string\n",
        "                    })\n",
        "\n",
        "                messages_for_api.extend(tool_calls_for_next_api_call) # Add all tool results for next iteration\n",
        "\n",
        "            return \"Max tool iterations reached for OpenAI.\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error in get_openai_response: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return f\"Error getting OpenAI response: {str(e)}\"\n",
        "\n",
        "    def process_user_request(self, user_message: str) -> Dict[str, Any]:\n",
        "        print(f\"\\n\\n{'='*60}\\nUser Message: {user_message}\\n{'='*60}\")\n",
        "        self.conversation_context.add_user_message(user_message)\n",
        "\n",
        "        context_summary = self.conversation_context.get_context_summary()\n",
        "        print(f\"Current Context Summary for Models:\\n{context_summary}\\n{'-'*60}\")\n",
        "\n",
        "        current_worker_prompt_with_context = f\"{worker_system_prompt}\\n\\nConversation Context:\\n{context_summary}\"\n",
        "\n",
        "        # Get a clean copy of history for each LLM to avoid contamination from other LLM's specific message formats\n",
        "        # This is a simplified approach. A more robust system might have distinct history tracking or conversion.\n",
        "        # For now, `get_full_conversation_for_api` provides the base.\n",
        "        # The LLM-specific methods will prepend their system messages.\n",
        "\n",
        "        anthropic_history_for_call = self.conversation_context.get_full_conversation_for_api()\n",
        "        anthropic_response_text = self.get_anthropic_response(current_worker_prompt_with_context, anthropic_history_for_call)\n",
        "        # The get_anthropic_response method itself now appends its turns to its local `messages_for_api`.\n",
        "        # We need to decide how to update the shared `self.conversation_context.messages`.\n",
        "        # For now, we add a simplified text summary.\n",
        "        self.conversation_context.add_assistant_message(f\"[Anthropic Final Text]: {anthropic_response_text}\")\n",
        "\n",
        "\n",
        "        openai_history_for_call = self.conversation_context.get_full_conversation_for_api()\n",
        "        openai_response_text = self.get_openai_response(current_worker_prompt_with_context, openai_history_for_call)\n",
        "        self.conversation_context.add_assistant_message(f\"[OpenAI Final Text]: {openai_response_text}\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Anthropic Final Response Text ---\\n{anthropic_response_text}\")\n",
        "        print(f\"--- OpenAI Final Response Text ---\\n{openai_response_text}\")\n",
        "\n",
        "        evaluation = self.evaluate_responses(user_message, anthropic_response_text, openai_response_text, context_summary)\n",
        "        self.evaluation_results.append(evaluation)\n",
        "\n",
        "        return {\n",
        "            \"user_message\": user_message,\n",
        "            \"anthropic_response\": anthropic_response_text,\n",
        "            \"openai_response\": openai_response_text,\n",
        "            \"evaluation\": evaluation\n",
        "        }\n",
        "\n",
        "    def evaluate_responses(self, user_message: str, anthropic_response: str, openai_response: str, context_summary_for_eval: str) -> Dict[str, Any]:\n",
        "        print(\"\\n--- Starting Evaluation by Gemini ---\")\n",
        "        try:\n",
        "            # Prepare ground truth data from the global 'storage' instance\n",
        "            ground_truth_customers = json.dumps(storage.customers, indent=2, default=str)\n",
        "            ground_truth_products = json.dumps(storage.products, indent=2, default=str)\n",
        "            ground_truth_orders = json.dumps(storage.orders, indent=2, default=str)\n",
        "\n",
        "            ground_truth_section = f\"\"\"\n",
        "                Ground Truth E-commerce Data:\n",
        "                Customers:\n",
        "                {ground_truth_customers}\n",
        "\n",
        "                Products:\n",
        "                {ground_truth_products}\n",
        "\n",
        "                Orders:\n",
        "                {ground_truth_orders}\n",
        "                \"\"\"\n",
        "            eval_prompt_parts = [\n",
        "                f\"User query: {user_message}\",\n",
        "                f\"Current context provided to assistants:\\n{context_summary_for_eval}\", # This is the summary *before* the current turn's responses\n",
        "                f\"Anthropic Claude response:\\n{anthropic_response}\",\n",
        "                f\"OpenAI GPT response:\\n{openai_response}\",\n",
        "                \"Please evaluate both responses based on accuracy, efficiency, context awareness, and helpfulness. Provide an overall score (1-10) for each. If ambiguity required human clarification, note it.\"\n",
        "            ]\n",
        "            relevant_learnings = self.check_relevant_learnings(user_message)\n",
        "            if relevant_learnings:\n",
        "                eval_prompt_parts.append(f\"\\nRelevant past learnings from similar situations:\\n{relevant_learnings}\")\n",
        "\n",
        "            eval_prompt = \"\\n\\n\".join(eval_prompt_parts)\n",
        "            # print(f\"Gemini Eval Prompt (first 300 chars): {eval_prompt[:300]}...\")\n",
        "\n",
        "            gemini_response_obj = eval_model_instance.generate_content(eval_prompt)\n",
        "            evaluation_text = gemini_response_obj.text\n",
        "            print(f\"Gemini Raw Evaluation:\\n{evaluation_text}\")\n",
        "\n",
        "            needs_human_input = \"human clarification\" in evaluation_text.lower() or \"admin user\" in evaluation_text.lower()\n",
        "            clarification_details = {\"used\": False, \"needed\": \"\", \"provided_input\": \"\"}\n",
        "\n",
        "            if needs_human_input:\n",
        "                clarification_details[\"used\"] = True\n",
        "                clarification_details[\"needed\"] = self.extract_clarification_needed(evaluation_text)\n",
        "                print(f\"--- Human Clarification Indicated by Evaluator ---\")\n",
        "                print(f\"Clarification needed by evaluator: {clarification_details['needed']}\")\n",
        "                try:\n",
        "                    human_input_for_eval = input(f\"Enter human clarification for evaluator (or type 'skip'): \")\n",
        "                    if human_input_for_eval.lower() != 'skip':\n",
        "                        clarification_details[\"provided_input\"] = human_input_for_eval\n",
        "                        self.store_learning(user_message, clarification_details[\"needed\"], human_input_for_eval)\n",
        "                        updated_eval_prompt = f\"{eval_prompt}\\n\\nHuman clarification provided to evaluator: {human_input_for_eval}\"\n",
        "                        # print(f\"Gemini Re-Eval Prompt (first 300 chars): {updated_eval_prompt[:300]}...\")\n",
        "                        updated_gemini_response = eval_model_instance.generate_content(updated_eval_prompt)\n",
        "                        evaluation_text = updated_gemini_response.text\n",
        "                        print(f\"Gemini Raw Re-Evaluation:\\n{evaluation_text}\")\n",
        "                    else:\n",
        "                        print(\"Skipping human input for evaluator.\")\n",
        "                except EOFError:\n",
        "                    print(\"EOFError: Skipping human clarification for evaluator (non-interactive).\")\n",
        "                    clarification_details[\"provided_input\"] = \"Skipped (non-interactive)\"\n",
        "\n",
        "            anthropic_score = self.extract_score(evaluation_text, \"Anthropic\")\n",
        "            openai_score = self.extract_score(evaluation_text, \"OpenAI\")\n",
        "\n",
        "            return {\n",
        "                \"anthropic_score\": anthropic_score, \"openai_score\": openai_score,\n",
        "                \"full_evaluation\": evaluation_text, \"clarification_details\": clarification_details\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error in evaluation: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return {\n",
        "                \"error\": f\"Error in evaluation: {str(e)}\",\n",
        "                \"anthropic_score\": 0, \"openai_score\": 0,\n",
        "                \"full_evaluation\": f\"Evaluation failed: {str(e)}\",\n",
        "                \"clarification_details\": {\"used\": False}\n",
        "            }\n",
        "\n",
        "    def extract_clarification_needed(self, evaluation_text: str) -> str:\n",
        "        match = re.search(r\"Clearly state what information is needed:\\s*(.*?)\\s*(Ask an admin user|$)\", evaluation_text, re.DOTALL | re.IGNORECASE)\n",
        "        if match and match.group(1).strip(): return match.group(1).strip()\n",
        "\n",
        "        lines = evaluation_text.split('\\n')\n",
        "        for i, line in enumerate(lines):\n",
        "            if \"clarification is needed\" in line.lower() or \"what information is needed\" in line.lower():\n",
        "                return \"\\n\".join(lines[i:i+3]).strip()\n",
        "        return \"Unspecified clarification needed by evaluator.\"\n",
        "\n",
        "    def store_learning(self, query: str, clarification_needed: str, human_input: str):\n",
        "        keywords = self.extract_keywords(query)\n",
        "        for keyword in keywords:\n",
        "            if keyword not in self.human_feedback_learnings:\n",
        "                self.human_feedback_learnings[keyword] = []\n",
        "            self.human_feedback_learnings[keyword].append({\n",
        "                \"original_query\": query,\n",
        "                \"clarification_needed_by_evaluator\": clarification_needed,\n",
        "                \"human_input_for_evaluator\": human_input,\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            })\n",
        "        print(f\"Learning stored for query keywords: {keywords}\")\n",
        "\n",
        "    def check_relevant_learnings(self, query: str) -> Optional[str]:\n",
        "        keywords = self.extract_keywords(query)\n",
        "        relevant_learnings_text = []\n",
        "        for keyword in keywords:\n",
        "            if keyword in self.human_feedback_learnings:\n",
        "                for learning in self.human_feedback_learnings[keyword]:\n",
        "                    relevant_learnings_text.append(\n",
        "                        f\"- Query context: '{learning['original_query']}'\\n\"\n",
        "                        f\"  Clarification needed: {learning['clarification_needed_by_evaluator']}\\n\"\n",
        "                        f\"  Provided input: {learning['human_input_for_evaluator']}\"\n",
        "                    )\n",
        "        return \"\\n\\n\".join(relevant_learnings_text) if relevant_learnings_text else None\n",
        "\n",
        "    def extract_keywords(self, text: str) -> List[str]:\n",
        "        words = re.findall(r'\\b\\w{4,}\\b', text.lower())\n",
        "        stop_words = {\"the\", \"and\", \"is\", \"in\", \"to\", \"a\", \"of\", \"for\", \"with\", \"on\", \"at\", \"what\", \"how\", \"show\", \"tell\", \"please\", \"what's\", \"i'd\"}\n",
        "        return list(set(word for word in words if word not in stop_words))\n",
        "\n",
        "    def extract_score(self, evaluation_text: str, model_name_pattern: str) -> int:\n",
        "        patterns = [\n",
        "            rf\"{model_name_pattern}.*?Overall Score.*?(\\d+)/10\",  # Anthropic Overall Score: 8/10\n",
        "            rf\"{model_name_pattern}.*?Overall Score:\\s*(\\d+)\",     # Anthropic Overall Score: 8\n",
        "            rf\"Overall Score.*?{model_name_pattern}.*?:\\s*(\\d+)\", # Overall Score (Anthropic): 8\n",
        "            rf\"{model_name_pattern}.*?score.*?:.*?(\\d+)\",          # Anthropic score: 8\n",
        "            rf\"{model_name_pattern}.*?\\b(\\d+)/10\",                 # Anthropic 8/10\n",
        "            rf\"{model_name_pattern}.*?\\bscore\\b.*?(\\d+)\",          # Anthropic ... score ... 8\n",
        "        ]\n",
        "        for p_str in patterns:\n",
        "            match = re.search(p_str, evaluation_text, re.IGNORECASE | re.DOTALL)\n",
        "            if match and match.group(1):\n",
        "                try: return int(match.group(1))\n",
        "                except ValueError: continue\n",
        "\n",
        "        # Fallback: find model name, then nearest number after \"score\" or just a number near model name\n",
        "        model_name_lower = model_name_pattern.lower()\n",
        "        text_lower = evaluation_text.lower()\n",
        "        model_indices = [m.start() for m in re.finditer(model_name_lower, text_lower)]\n",
        "\n",
        "        for model_idx in model_indices:\n",
        "            search_area = evaluation_text[model_idx : model_idx + 100] # Search 100 chars around model name\n",
        "            score_match = re.search(r'\\b(\\d+)\\b(?:/10)?', search_area, re.IGNORECASE) # Look for a number, optionally like X/10\n",
        "            if score_match:\n",
        "                try: return int(score_match.group(1))\n",
        "                except ValueError: pass\n",
        "\n",
        "        print(f\"Could not extract score for '{model_name_pattern}' from eval text snippet:\\n{evaluation_text[:250]}...\")\n",
        "        return 0\n",
        "\n",
        "print(\"DualAgentEvaluator class defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzLHm8MmSOMC",
        "outputId": "6d30b582-dfe5-4f24-ff21-9dd9f3dfdeb0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DualAgentEvaluator class defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"\\nStarting Main Execution...\\n\")\n",
        "    if any(k in globals() and \"YOUR_\" in globals()[k] for k in [\"ANTHROPIC_API_KEY\", \"OPENAI_API_KEY\", \"GOOGLE_API_KEY\"]):\n",
        "        print(\"ERROR: Placeholder API keys detected. Update in Cell 2 (UserDataMock) or environment. Exiting.\")\n",
        "        return\n",
        "\n",
        "    agent = DualAgentEvaluator()\n",
        "    results_log = []\n",
        "    test_queries = [\n",
        "        \"Show me all available products\",\n",
        "        \"I'd like to order 2 of the 'Widget A' please, status 'Processing'\",\n",
        "        \"What is the status of order O2?\", # More specific query for context\n",
        "        # \"How many 'Gadget B' are left in stock?\" # Example of a query that should use get_product_info\n",
        "        # \"Create a new customer named Alice Wonderland, email alice@wonder.land\"\n",
        "    ]\n",
        "\n",
        "    for query in test_queries:\n",
        "        try:\n",
        "            result = agent.process_user_request(query)\n",
        "            results_log.append(result)\n",
        "        except Exception as e:\n",
        "            print(f\"CRITICAL ERROR processing query '{query}': {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            results_log.append({\n",
        "                \"user_message\": query, \"anthropic_response\": \"ERROR\", \"openai_response\": \"ERROR\",\n",
        "                \"evaluation\": {\"anthropic_score\": 0, \"openai_score\": 0, \"full_evaluation\": f\"Critical error: {e}\", \"clarification_details\": {\"used\": False}}\n",
        "            })\n",
        "        # time.sleep(1) # Optional delay\n",
        "\n",
        "    print(\"\\n\\n===== EVALUATION SUMMARY =====\")\n",
        "    total_anthropic, total_openai, num_q = 0, 0, len(results_log)\n",
        "    for i, res in enumerate(results_log):\n",
        "        print(f\"\\nQuery {i+1}: {res['user_message']}\")\n",
        "        print(f\"  Anthropic Resp: {res['anthropic_response'][:100]}...\")\n",
        "        print(f\"  OpenAI Resp: {res['openai_response'][:100]}...\")\n",
        "\n",
        "        eval_data = res['evaluation']\n",
        "        anth_s, open_s = eval_data.get('anthropic_score',0), eval_data.get('openai_score',0)\n",
        "        total_anthropic += anth_s; total_openai += open_s\n",
        "        print(f\"  Scores - Anthropic: {anth_s}, OpenAI: {open_s}\")\n",
        "        if eval_data.get('clarification_details',{}).get('used'):\n",
        "            print(f\"    Clarification: Needed='{eval_data['clarification_details']['needed']}', Provided='{eval_data['clarification_details']['provided_input']}'\")\n",
        "        winner = \"Tie\" if anth_s == open_s else (\"Anthropic\" if anth_s > open_s else \"OpenAI\")\n",
        "        print(f\"  Query Winner: {winner}\")\n",
        "\n",
        "    print(f\"\\n----- Overall Performance -----\")\n",
        "    if num_q > 0:\n",
        "        print(f\"Avg Anthropic: {total_anthropic/num_q:.2f}, Avg OpenAI: {total_openai/num_q:.2f}\")\n",
        "    print(f\"Total Anthropic: {total_anthropic}, Total OpenAI: {total_openai}\")\n",
        "    overall_winner = \"Tie\" if total_anthropic == total_openai else (\"Anthropic\" if total_anthropic > total_openai else \"OpenAI\")\n",
        "    print(f\"Overall Winner: {overall_winner}\")\n",
        "\n",
        "    if agent.human_feedback_learnings:\n",
        "        print(\"\\n----- Learned Clarifications (for Evaluator) -----\")\n",
        "        for kw, l_list in agent.human_feedback_learnings.items():\n",
        "            print(f\"Keyword: {kw}\")\n",
        "            for item in l_list: print(f\"  - Q: '{item['original_query']}', Needed: {item['clarification_needed_by_evaluator']}, Input: {item['human_input_for_evaluator']}\")\n",
        "    print(\"\\nExecution Finished.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # In Jupyter, call main() in a new cell.\n",
        "    # For direct script execution:\n",
        "    # main()\n",
        "    pass\n",
        "\n",
        "print(\"Main function defined. Call main() in a new cell to run the evaluation.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Main function defined. Call main() in a new cell to run the evaluation.\n"
          ]
        }
      ],
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2-ztJ2BO7gD",
        "outputId": "b4878763-f9ce-4027-eb4f-69b03d444219"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dg85ek6bSvW5",
        "outputId": "bdd0685b-8e19-423e-bdbc-28a36e7462eb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Main Execution...\n",
            "\n",
            "DualAgentEvaluator initialized. OpenAI tools formatted.\n",
            "\n",
            "\n",
            "============================================================\n",
            "User Message: Show me all available products\n",
            "============================================================\n",
            "Current Context Summary for Models:\n",
            "No specific context items set yet.\n",
            "------------------------------------------------------------\n",
            "\n",
            "Anthropic API Call #1. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 1\n",
            "Last message role: user\n",
            "Anthropic Tool Call: list_all_products, Input: {}\n",
            "--- [Tool Dispatcher] Attempting tool: list_all_products with input: {} ---\n",
            "[Tool Executed] list_all_products: Found 3 products.\n",
            "--- [Tool Dispatcher] Result for list_all_products: {\n",
            "  \"status\": \"success\",\n",
            "  \"count\": 3,\n",
            "  \"products\": {\n",
            "    \"P1\": {\n",
            "      \"name\": \"Widget A\",\n",
            "      \"description\": \"A simple widget. Very compact.\",\n",
            "      \"price\": 19.99,\n",
            "      \"inventory_count\": 999\n",
            "    },\n",
            "    \"P2\": {\n",
            "      \"name\": \"Gadget B\",\n",
            "      \"description\": \"A powerful gadget. It spins.\",\n",
            "      \"price\": 49.99,\n",
            "      \"inventory_count\": 200\n",
            "    },\n",
            "    \"P3\": {\n",
            "      \"name\": \"Perplexinator\",\n",
            "      \"description\": \"A perplexing perfunctator\",\n",
            "      \"price\": 79.99,\n",
            "      \"inventory_count\": 1483\n",
            "    }\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: products, ID: P1, Data (type): <class 'dict'>\n",
            "[Context Updated] Entity: products, ID: P2, Data (type): <class 'dict'>\n",
            "[Context Updated] Entity: products, ID: P3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: list_all_products, Details: {\"input\": {}, \"result\": {\"status\": \"success\", \"count\": 3, \"products\": {\"P1\": {\"name\": \"Widget A\", \"description\": \"A simple widget. Very compact.\", \"price\": 19.99, \"inventory_count\": 999}, \"P2\": {\"name\": \"Gadget B\", \"description\": \"A powerful gadget. It spins.\", \"price\": 49.99, \"inventory_count\": 200}, \"P3\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1483}}}}\n",
            "\n",
            "Anthropic API Call #2. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 3\n",
            "Last message role: user\n",
            "Anthropic Final Text (no tool use this turn): Here are all the products currently available in our inventory:\n",
            "\n",
            "1. Widget A\n",
            "   - Description: A simple widget. Very compact.\n",
            "   - Price: $19.99\n",
            "   - In stock: 999 units\n",
            "\n",
            "2. Gadget B\n",
            "   - Description: A powerful gadget. It spins.\n",
            "   - Price: $49.99\n",
            "   - In stock: 200 units\n",
            "\n",
            "3. Perplexinator\n",
            "   - Description: A perplexing perfunctator\n",
            "   - Price: $79.99\n",
            "   - In stock: 1,483 units\n",
            "\n",
            "Is there any specific product you'd like to know more about?\n",
            "\n",
            "OpenAI API Call #1. Messages count: 3\n",
            "Last message role: assistant\n",
            "OpenAI Tool Call: list_all_products, Input: {}\n",
            "--- [Tool Dispatcher] Attempting tool: list_all_products with input: {} ---\n",
            "[Tool Executed] list_all_products: Found 3 products.\n",
            "--- [Tool Dispatcher] Result for list_all_products: {\n",
            "  \"status\": \"success\",\n",
            "  \"count\": 3,\n",
            "  \"products\": {\n",
            "    \"P1\": {\n",
            "      \"name\": \"Widget A\",\n",
            "      \"description\": \"A simple widget. Very compact.\",\n",
            "      \"price\": 19.99,\n",
            "      \"inventory_count\": 999\n",
            "    },\n",
            "    \"P2\": {\n",
            "      \"name\": \"Gadget B\",\n",
            "      \"description\": \"A powerful gadget. It spins.\",\n",
            "      \"price\": 49.99,\n",
            "      \"inventory_count\": 200\n",
            "    },\n",
            "    \"P3\": {\n",
            "      \"name\": \"Perplexinator\",\n",
            "      \"description\": \"A perplexing perfunctator\",\n",
            "      \"price\": 79.99,\n",
            "      \"inventory_count\": 1483\n",
            "    }\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: products, ID: P1, Data (type): <class 'dict'>\n",
            "[Context Updated] Entity: products, ID: P2, Data (type): <class 'dict'>\n",
            "[Context Updated] Entity: products, ID: P3, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: list_all_products, Details: {\"input\": {}, \"result\": {\"status\": \"success\", \"count\": 3, \"products\": {\"P1\": {\"name\": \"Widget A\", \"description\": \"A simple widget. Very compact.\", \"price\": 19.99, \"inventory_count\": 999}, \"P2\": {\"name\": \"Gadget B\", \"description\": \"A powerful gadget. It spins.\", \"price\": 49.99, \"inventory_count\": 200}, \"P3\": {\"name\": \"Perplexinator\", \"description\": \"A perplexing perfunctator\", \"price\": 79.99, \"inventory_count\": 1483}}}}\n",
            "\n",
            "OpenAI API Call #2. Messages count: 5\n",
            "Last message role: tool\n",
            "OpenAI Final Text (no tool use this turn): Here are all available products in our inventory:\n",
            "\n",
            "1. Widget A\n",
            "   - Description: A simple widget. Very compact.\n",
            "   - Price: $19.99\n",
            "   - In stock: 999 units\n",
            "\n",
            "2. Gadget B\n",
            "   - Description: A powerful gadget. It spins.\n",
            "   - Price: $49.99\n",
            "   - In stock: 200 units\n",
            "\n",
            "3. Perplexinator\n",
            "   - Description: A perplexing perfunctator\n",
            "   - Price: $79.99\n",
            "   - In stock: 1,483 units\n",
            "\n",
            "If you’d like more details on any product or want to place an order, just let me know!\n",
            "\n",
            "--- Anthropic Final Response Text ---\n",
            "Here are all the products currently available in our inventory:\n",
            "\n",
            "1. Widget A\n",
            "   - Description: A simple widget. Very compact.\n",
            "   - Price: $19.99\n",
            "   - In stock: 999 units\n",
            "\n",
            "2. Gadget B\n",
            "   - Description: A powerful gadget. It spins.\n",
            "   - Price: $49.99\n",
            "   - In stock: 200 units\n",
            "\n",
            "3. Perplexinator\n",
            "   - Description: A perplexing perfunctator\n",
            "   - Price: $79.99\n",
            "   - In stock: 1,483 units\n",
            "\n",
            "Is there any specific product you'd like to know more about?\n",
            "--- OpenAI Final Response Text ---\n",
            "Here are all available products in our inventory:\n",
            "\n",
            "1. Widget A\n",
            "   - Description: A simple widget. Very compact.\n",
            "   - Price: $19.99\n",
            "   - In stock: 999 units\n",
            "\n",
            "2. Gadget B\n",
            "   - Description: A powerful gadget. It spins.\n",
            "   - Price: $49.99\n",
            "   - In stock: 200 units\n",
            "\n",
            "3. Perplexinator\n",
            "   - Description: A perplexing perfunctator\n",
            "   - Price: $79.99\n",
            "   - In stock: 1,483 units\n",
            "\n",
            "If you’d like more details on any product or want to place an order, just let me know!\n",
            "\n",
            "--- Starting Evaluation by Gemini ---\n",
            "Gemini Raw Evaluation:\n",
            "Okay, I will evaluate both responses.\n",
            "\n",
            "**Evaluation of Anthropic Claude's Response:**\n",
            "\n",
            "*   **Accuracy: 10/10**\n",
            "    *   The response provides a list of products with descriptions, prices, and stock levels. Assuming this list represents the complete and correct inventory available to the assistant, it is accurate. The past learnings confirm that returning all products from the product dictionary is the correct behavior.\n",
            "*   **Efficiency: 10/10**\n",
            "    *   The assistant directly answered the user's query without asking unnecessary clarifying questions.\n",
            "*   **Context Awareness: 10/10**\n",
            "    *   There was no prior specific context, but the assistant correctly understood the direct query \"Show me all available products.\"\n",
            "*   **Helpfulness: 9/10**\n",
            "    *   The response fully addresses the user's request by listing the products. The follow-up question, \"Is there any specific product you'd like to know more about?\" is helpful for guiding the conversation.\n",
            "\n",
            "*   **Overall Score: 9.5/10**\n",
            "\n",
            "**Evaluation of OpenAI GPT's Response:**\n",
            "\n",
            "*   **Accuracy: 10/10**\n",
            "    *   The response provides the same list of products with descriptions, prices, and stock levels as Claude. Assuming this list is the complete and correct inventory, it is accurate. The past learnings confirm this is the expected output.\n",
            "*   **Efficiency: 10/10**\n",
            "    *   The assistant directly answered the user's query without any clarifying questions.\n",
            "*   **Context Awareness: 10/10**\n",
            "    *   No prior specific context was provided, and the assistant correctly interpreted the user's direct query.\n",
            "*   **Helpfulness: 9.5/10**\n",
            "    *   The response fully addresses the user's request. The follow-up, \"If you’d like more details on any product or want to place an order, just let me know!\" is slightly more proactive and comprehensive by including the option to \"place an order,\" which is a common next step in a customer service scenario involving product listings.\n",
            "\n",
            "*   **Overall Score: 9.7/10**\n",
            "\n",
            "**Ambiguity and Clarification:**\n",
            "\n",
            "*   **No ambiguity requiring human clarification for this specific query.** The user's query \"Show me all available products\" is straightforward. Both assistants understood it and provided a list of products.\n",
            "*   The \"Relevant past learnings\" confirm that the expected behavior is for the assistants to return all products from their known product dictionary, which both have done. The fact that they returned identical product lists suggests they are working from the same assumed dataset for \"available products.\"\n",
            "\n",
            "This evaluation assumes the product details provided by the assistants are drawn from the intended \"available products\" list.\n",
            "--- Human Clarification Indicated by Evaluator ---\n",
            "Clarification needed by evaluator: Unspecified clarification needed by evaluator.\n",
            "Enter human clarification for evaluator (or type 'skip'): These products were indeed drawn from the intended \"available products\" list.\n",
            "Learning stored for query keywords: ['available', 'products']\n",
            "Gemini Raw Re-Evaluation:\n",
            "Okay, I will evaluate the responses.\n",
            "\n",
            "**Evaluation of Anthropic Claude's Response:**\n",
            "\n",
            "1.  **Accuracy:** 10/10\n",
            "    *   The response accurately lists the products as confirmed by the human clarification.\n",
            "2.  **Efficiency:** 10/10\n",
            "    *   The assistant directly answered the query without any unnecessary clarifying questions.\n",
            "3.  **Context Awareness:** 10/10\n",
            "    *   The assistant correctly understood the request for \"all available products\" even without specific prior context.\n",
            "4.  **Helpfulness:** 10/10\n",
            "    *   The response fully addressed the user's request by providing the product list and offered further assistance.\n",
            "\n",
            "**Overall Score for Anthropic Claude:** 10/10\n",
            "\n",
            "**Evaluation of OpenAI GPT's Response:**\n",
            "\n",
            "1.  **Accuracy:** 10/10\n",
            "    *   The response accurately lists the products as confirmed by the human clarification.\n",
            "2.  **Efficiency:** 10/10\n",
            "    *   The assistant directly answered the query without any unnecessary clarifying questions.\n",
            "3.  **Context Awareness:** 10/10\n",
            "    *   The assistant correctly understood the request for \"all available products\" even without specific prior context.\n",
            "4.  **Helpfulness:** 10/10\n",
            "    *   The response fully addressed the user's request by providing the product list and offered further, slightly more proactive assistance (details or placing an order).\n",
            "\n",
            "**Overall Score for OpenAI GPT:** 10/10\n",
            "\n",
            "**Ambiguity Requiring Human Clarification:**\n",
            "No ambiguity was present in the user's query for the assistants to resolve. The human clarification provided (\"These products were indeed drawn from the intended 'available products' list.\") was for the *evaluator* to confirm the correctness of the data source used by the assistants, which it did.\n",
            "\n",
            "**Learning Stored:**\n",
            "*   **User Query:** 'Show me all available products'\n",
            "*   **Situation:** Assistants provide a list of products.\n",
            "*   **Evaluator Clarification Needed:** Confirmation that the listed products and their details are from the correct and intended \"available products\" master list.\n",
            "*   **Provided Input (from admin/human):** \"These products were indeed drawn from the intended 'available products' list.\"\n",
            "*   **Handling Guidance:** If assistants provide a product list that matches the confirmed \"available products\" list, they have responded accurately and efficiently. Their helpfulness can be further judged by how they offer next steps.\n",
            "\n",
            "\n",
            "============================================================\n",
            "User Message: I'd like to order 2 of the 'Widget A' please, status 'Processing'\n",
            "============================================================\n",
            "Current Context Summary for Models:\n",
            "Recent products: ID: P1 (Name: Widget A), ID: P2 (Name: Gadget B), ID: P3 (Name: Perplexinator)\n",
            "Last action: list_all_products at 2025-05-14T20:07:03.339302 (Input: {}, Result Status: success)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Anthropic API Call #1. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 4\n",
            "Last message role: user\n",
            "Anthropic Tool Call: create_order, Input: {'product_id_or_name': 'Widget A', 'quantity': 2, 'status': 'Processing'}\n",
            "--- [Tool Dispatcher] Attempting tool: create_order with input: {\"product_id_or_name\": \"Widget A\", \"quantity\": 2, \"status\": \"Processing\"} ---\n",
            "[Tool Helper] find_product_by_name: Matched 'Widget A' to 'Widget A' (ID: P1) with score 100\n",
            "[Tool Executed] create_order: Order O5 created for 2 of Widget A (ID: P1). Status: Processing. Remaining inv: 999\n",
            "--- [Tool Dispatcher] Result for create_order: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O5\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O5\",\n",
            "    \"product_id\": \"P1\",\n",
            "    \"product_name\": \"Widget A\",\n",
            "    \"quantity\": 2,\n",
            "    \"price\": 19.99,\n",
            "    \"status\": \"Processing\"\n",
            "  },\n",
            "  \"remaining_inventory\": 999\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O5, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: create_order, Details: {\"input\": {\"product_id_or_name\": \"Widget A\", \"quantity\": 2, \"status\": \"Processing\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O5\", \"order_details\": {\"id\": \"O5\", \"product_id\": \"P1\", \"product_name\": \"Widget A\", \"quantity\": 2, \"price\": 19.99, \"status\": \"Processing\"}, \"remaining_inventory\": 999}}\n",
            "\n",
            "Anthropic API Call #2. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 6\n",
            "Last message role: user\n",
            "Anthropic Final Text (no tool use this turn): Great! I've created your order for 2 Widget A units. Here's a summary of your order:\n",
            "- Order ID: O5\n",
            "- Product: Widget A\n",
            "- Quantity: 2\n",
            "- Price per unit: $19.99\n",
            "- Total price: $39.98\n",
            "- Status: Processing\n",
            "\n",
            "Your order has been successfully placed and is being processed. Would you like to track your order or is there anything else I can help you with?\n",
            "\n",
            "OpenAI API Call #1. Messages count: 6\n",
            "Last message role: assistant\n",
            "OpenAI Tool Call: create_order, Input: {'product_id_or_name': 'Widget A', 'quantity': 2, 'status': 'Processing'}\n",
            "--- [Tool Dispatcher] Attempting tool: create_order with input: {\"product_id_or_name\": \"Widget A\", \"quantity\": 2, \"status\": \"Processing\"} ---\n",
            "[Tool Helper] find_product_by_name: Matched 'Widget A' to 'Widget A' (ID: P1) with score 100\n",
            "[Tool Executed] create_order: Order O6 created for 2 of Widget A (ID: P1). Status: Processing. Remaining inv: 999\n",
            "--- [Tool Dispatcher] Result for create_order: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O6\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O6\",\n",
            "    \"product_id\": \"P1\",\n",
            "    \"product_name\": \"Widget A\",\n",
            "    \"quantity\": 2,\n",
            "    \"price\": 19.99,\n",
            "    \"status\": \"Processing\"\n",
            "  },\n",
            "  \"remaining_inventory\": 999\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O6, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: create_order, Details: {\"input\": {\"product_id_or_name\": \"Widget A\", \"quantity\": 2, \"status\": \"Processing\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O6\", \"order_details\": {\"id\": \"O6\", \"product_id\": \"P1\", \"product_name\": \"Widget A\", \"quantity\": 2, \"price\": 19.99, \"status\": \"Processing\"}, \"remaining_inventory\": 999}}\n",
            "\n",
            "OpenAI API Call #2. Messages count: 8\n",
            "Last message role: tool\n",
            "OpenAI Final Text (no tool use this turn): Your order for 2 units of Widget A with the status \"Processing\" has been placed successfully!\n",
            "\n",
            "Order summary:\n",
            "- Product: Widget A\n",
            "- Quantity: 2\n",
            "- Status: Processing\n",
            "\n",
            "If you would like to track your order or need further assistance, just let me know!\n",
            "\n",
            "--- Anthropic Final Response Text ---\n",
            "Great! I've created your order for 2 Widget A units. Here's a summary of your order:\n",
            "- Order ID: O5\n",
            "- Product: Widget A\n",
            "- Quantity: 2\n",
            "- Price per unit: $19.99\n",
            "- Total price: $39.98\n",
            "- Status: Processing\n",
            "\n",
            "Your order has been successfully placed and is being processed. Would you like to track your order or is there anything else I can help you with?\n",
            "--- OpenAI Final Response Text ---\n",
            "Your order for 2 units of Widget A with the status \"Processing\" has been placed successfully!\n",
            "\n",
            "Order summary:\n",
            "- Product: Widget A\n",
            "- Quantity: 2\n",
            "- Status: Processing\n",
            "\n",
            "If you would like to track your order or need further assistance, just let me know!\n",
            "\n",
            "--- Starting Evaluation by Gemini ---\n",
            "Gemini Raw Evaluation:\n",
            "Okay, I will evaluate the responses from Anthropic Claude and OpenAI GPT.\n",
            "\n",
            "First, I need to address an ambiguity in the user's query and a potential discrepancy in Claude's response based on the provided context.\n",
            "\n",
            "**Ambiguity Requiring Human Clarification:**\n",
            "\n",
            "1.  **User-Specified Order Status:** The user query \"I'd like to order 2 of the 'Widget A' please, status 'Processing'\" includes a request to set the status of a *new* order to 'Processing'. It's unclear if the ordering system allows users to specify an initial status, or if 'Processing' is a valid initial status they can set, or if the system assigns a default status (e.g., \"Pending\", \"Received\", or indeed \"Processing\").\n",
            "2.  **Claude's Additional Order Details:** Anthropic Claude's response includes a \"Price per unit: $19.99\" and an \"Order ID: O5\". This information is not present in the \"Current context provided to assistants\" (which only lists Product ID and Name for 'Widget A'). It's unclear if the assistant has access to a live product catalog for pricing and an order management system for real-time Order ID generation, or if these details were assumed or fabricated.\n",
            "\n",
            "**Information Needed from Admin:**\n",
            "\n",
            "To accurately evaluate the responses, I require the following clarifications:\n",
            "1.  **Regarding Order Status Specification:**\n",
            "    *   Can users specify the initial status (e.g., \"Processing\") when placing a new order via the AI assistant?\n",
            "    *   If yes, is \"Processing\" a valid status they can choose?\n",
            "    *   If users *cannot* specify the initial status, what is the system's default initial status for new orders? How should the AI respond if a user attempts to specify one?\n",
            "2.  **Regarding Assistant Capabilities and Data Access (for Claude's response):**\n",
            "    *   Is 'Widget A' priced at $19.99, and is this information accessible to the assistant from a product database, even if not explicitly in the \"Recent products\" snippet?\n",
            "    *   Does the assistant's order creation process involve real-time interaction with a backend system that would generate and return a specific Order ID like \"O5\"? Or are such details placeholders/assumptions?\n",
            "\n",
            "**Request to Admin User:**\n",
            "\"Admin, please provide the information requested above regarding order status handling and the expected data access/capabilities of the assistants concerning product pricing and order ID generation. Specifically:\n",
            "*   How should the 'status 'Processing'' part of the user's request be handled?\n",
            "*   Are the price ($19.99) and Order ID (O5) mentioned by Claude factual details it should have access to, or are they outside the scope of information available to it for this interaction?\"\n",
            "\n",
            "---\n",
            "\n",
            "**Proceeding with Evaluation Based on Currently Available Information:**\n",
            "\n",
            "Lacking the admin clarification, I will evaluate based *strictly* on the \"Current context provided to assistants.\" This means:\n",
            "*   Any information in responses not derivable from this context (e.g., price, specific Order ID) will be considered unsubstantiated.\n",
            "*   I will assume that directly fulfilling the user's request to set \"status 'Processing'\" is a plausible AI behavior, absent explicit rules to the contrary.\n",
            "\n",
            "**Evaluation of Anthropic Claude's Response:**\n",
            "\n",
            "*   **Accuracy (5/10):**\n",
            "    *   Correctly identified \"Widget A\" and the quantity (2).\n",
            "    *   The response states \"Status: Processing,\" aligning with the user's request. This is provisionally acceptable (assuming the system allows this or it's the default).\n",
            "    *   However, it provides \"Price per unit: $19.99\" and \"Order ID: O5.\" This information is not present in the \"Current context provided to assistants.\" Without confirmation that Claude has access to this external data, these details are unsubstantiated and potentially inaccurate. This significantly impacts the accuracy score.\n",
            "*   **Efficiency (8/10):**\n",
            "    *   The assistant processed the order request directly without clarifying questions. This is efficient if its assumptions (especially about status and its own knowledge of price/ID) are correct.\n",
            "*   **Context Awareness (7/10):**\n",
            "    *   Correctly identified \"Widget A\" using the provided recent products list.\n",
            "    *   Understood the primary intent to \"order.\"\n",
            "    *   Interpreted \"status 'Processing'\" as a parameter for the new order.\n",
            "*   **Helpfulness (6/10):**\n",
            "    *   The response attempts to be very helpful by providing a full order summary, including price and an Order ID. If these details were verifiably accurate, helpfulness would be higher.\n",
            "    *   Since these details are unsubstantiated from the given context, they could be misleading, reducing helpfulness.\n",
            "    *   The offer to track the order or provide further assistance is good.\n",
            "\n",
            "**Overall Score for Anthropic Claude: 6.5/10**\n",
            "\n",
            "**Evaluation of OpenAI GPT's Response:**\n",
            "\n",
            "*   **Accuracy (8/10):**\n",
            "    *   Correctly identified \"Widget A\" and the quantity (2).\n",
            "    *   The response confirms \"Status: Processing,\" aligning with the user's request. This is provisionally acceptable.\n",
            "    *   Crucially, it does *not* invent a price or a specific Order ID, sticking to the information derivable from the user's query and the provided context. This makes it more factually grounded given the limitations.\n",
            "*   **Efficiency (8/10):**\n",
            "    *   The assistant processed the order request directly. Similar to Claude, this is efficient if the assumption about handling the user-specified status is valid for the system.\n",
            "*   **Context Awareness (8/10):**\n",
            "    *   Correctly identified \"Widget A.\"\n",
            "    *   Understood the primary intent to \"order.\"\n",
            "    *   Interpreted \"status 'Processing'\" as a parameter for the new order.\n",
            "*   **Helpfulness (8/10):**\n",
            "    *   Provides a clear confirmation of the order based on the user's inputs.\n",
            "    *   The summary is concise and accurate according to the available information.\n",
            "    *   Offers further assistance, which is standard good practice.\n",
            "\n",
            "**Overall Score for OpenAI GPT: 8/10**\n",
            "\n",
            "**Learning for Future Similar Situations:**\n",
            "\n",
            "1.  **Clarify Data Scope:** When evaluating assistants, it's crucial to know the full scope of information they are expected to access (e.g., real-time databases for prices, inventory, order generation vs. relying solely on provided context snippets). This was key in assessing Claude's inclusion of price/ID.\n",
            "2.  **System Business Rules:** The assistant's knowledge base should include core business rules for common actions like order placement. Specifically, rules around initial order statuses (user-settable, valid options, or system-default) are essential for accurate handling of queries like the one presented. If a user query conflicts with or is unusual for a business rule (e.g., trying to set a status when it's system-assigned), the AI should ideally clarify or inform the user, rather than silently accepting or failing.\n",
            "3.  **Handling User-Specified Parameters:** If a user specifies a parameter that is typically system-controlled (like \"status\" for a new order), the AI needs a clear strategy:\n",
            "    *   Attempt to honor it if the system allows.\n",
            "    *   Inform the user if the system handles it differently (e.g., \"I've placed your order for 2 Widget A. New orders are set to 'Pending' status initially and will move to 'Processing' shortly.\").\n",
            "    *   Ask for clarification if the request is ambiguous or potentially problematic.\n",
            "--- Human Clarification Indicated by Evaluator ---\n",
            "Clarification needed by evaluator: Unspecified clarification needed by evaluator.\n",
            "Enter human clarification for evaluator (or type 'skip'): skip\n",
            "Skipping human input for evaluator.\n",
            "\n",
            "\n",
            "============================================================\n",
            "User Message: What is the status of order O2?\n",
            "============================================================\n",
            "Current Context Summary for Models:\n",
            "Recent products: ID: P1 (Name: Widget A), ID: P2 (Name: Gadget B), ID: P3 (Name: Perplexinator)\n",
            "Recent orders: ID: O5 (Product: Widget A, Status: Processing), ID: O6 (Product: Widget A, Status: Processing)\n",
            "Last action: create_order at 2025-05-14T20:09:06.306129 (Input: {'product_id_or_name': 'Widget A', 'quantity': 2, 'status': 'Processing'}, Result Status: success, OrderID: O6)\n",
            "------------------------------------------------------------\n",
            "\n",
            "Anthropic API Call #1. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 7\n",
            "Last message role: user\n",
            "Anthropic Tool Call: get_order_details, Input: {'order_id': 'O2'}\n",
            "--- [Tool Dispatcher] Attempting tool: get_order_details with input: {\"order_id\": \"O2\"} ---\n",
            "[Tool Executed] get_order_details: Order O2 found.\n",
            "--- [Tool Dispatcher] Result for get_order_details: {\n",
            "  \"status\": \"success\",\n",
            "  \"order_id\": \"O2\",\n",
            "  \"order_details\": {\n",
            "    \"id\": \"O2\",\n",
            "    \"product_id\": \"P2\",\n",
            "    \"product_name\": \"Gadget B\",\n",
            "    \"quantity\": 1,\n",
            "    \"price\": 49.99,\n",
            "    \"status\": \"Processing\"\n",
            "  }\n",
            "} ---\n",
            "[Context Updated] Entity: orders, ID: O2, Data (type): <class 'dict'>\n",
            "[Context Updated] Last Action: get_order_details, Details: {\"input\": {\"order_id\": \"O2\"}, \"result\": {\"status\": \"success\", \"order_id\": \"O2\", \"order_details\": {\"id\": \"O2\", \"product_id\": \"P2\", \"product_name\": \"Gadget B\", \"quantity\": 1, \"price\": 49.99, \"status\": \"Processing\"}}}\n",
            "\n",
            "Anthropic API Call #2. System: ' You are a helpful customer service assistant for an e-comme...', Messages count: 9\n",
            "Last message role: user\n",
            "Anthropic Final Text (no tool use this turn): Your order O2 is currently in \"Processing\" status. Here are the full details:\n",
            "- Order ID: O2\n",
            "- Product: Gadget B\n",
            "- Quantity: 1\n",
            "- Price: $49.99\n",
            "- Status: Processing\n",
            "\n",
            "Would you like me to help you with anything else regarding your order?\n",
            "\n",
            "OpenAI API Call #1. Messages count: 9\n",
            "Last message role: assistant\n",
            "OpenAI Final Text (no tool use this turn): I'm sorry, but I don't have information about order O2 in the current context. Could you please provide more details about that order, or check if the order ID is correct? I can help you with the status of orders O5 and O6, which are both for Widget A and currently processing. Let me know how you'd like to proceed!\n",
            "\n",
            "--- Anthropic Final Response Text ---\n",
            "Your order O2 is currently in \"Processing\" status. Here are the full details:\n",
            "- Order ID: O2\n",
            "- Product: Gadget B\n",
            "- Quantity: 1\n",
            "- Price: $49.99\n",
            "- Status: Processing\n",
            "\n",
            "Would you like me to help you with anything else regarding your order?\n",
            "--- OpenAI Final Response Text ---\n",
            "I'm sorry, but I don't have information about order O2 in the current context. Could you please provide more details about that order, or check if the order ID is correct? I can help you with the status of orders O5 and O6, which are both for Widget A and currently processing. Let me know how you'd like to proceed!\n",
            "\n",
            "--- Starting Evaluation by Gemini ---\n",
            "Gemini Raw Evaluation:\n",
            "Okay, I will evaluate the responses.\n",
            "\n",
            "**Evaluation of AI Assistant Responses:**\n",
            "\n",
            "**User Query:** What is the status of order O2?\n",
            "\n",
            "**Provided Context:**\n",
            "*   Recent products: ID: P1 (Name: Widget A), ID: P2 (Name: Gadget B), ID: P3 (Name: Perplexinator)\n",
            "*   Recent orders: ID: O5 (Product: Widget A, Status: Processing), ID: O6 (Product: Widget A, Status: Processing)\n",
            "*   Last action: create_order at 2025-05-14T20:09:06.306129 (Input: {'product_id_or_name': 'Widget A', 'quantity': 2, 'status': 'Processing'}, Result Status: success, OrderID: O6)\n",
            "\n",
            "---\n",
            "\n",
            "**Anthropic Claude Response:**\n",
            "\"Your order O2 is currently in \"Processing\" status. Here are the full details:\n",
            "- Order ID: O2\n",
            "- Product: Gadget B\n",
            "- Quantity: 1\n",
            "- Price: $49.99\n",
            "- Status: Processing\n",
            "\n",
            "Would you like me to help you with anything else regarding your order?\"\n",
            "\n",
            "*   **Accuracy: 1/10**\n",
            "    *   The provided context does not contain any information about an order \"O2\". Claude has hallucinated all the details (Product, Quantity, Price, Status) for O2. This is highly inaccurate.\n",
            "*   **Efficiency: 2/10**\n",
            "    *   It directly provided an incorrect answer without checking if the information was available or asking clarifying questions.\n",
            "*   **Context Awareness: 1/10**\n",
            "    *   It completely failed to recognize that O2 is not present in the \"Recent orders\" list or any other part of the provided context. It appears to have invented the order.\n",
            "*   **Helpfulness: 1/10**\n",
            "    *   Providing fabricated information is actively unhelpful and misleading to the user.\n",
            "*   **Overall Score: 1/10**\n",
            "\n",
            "---\n",
            "\n",
            "**OpenAI GPT Response:**\n",
            "\"I'm sorry, but I don't have information about order O2 in the current context. Could you please provide more details about that order, or check if the order ID is correct? I can help you with the status of orders O5 and O6, which are both for Widget A and currently processing. Let me know how you'd like to proceed!\"\n",
            "\n",
            "*   **Accuracy: 10/10**\n",
            "    *   Correctly states that information about order O2 is not in the current context.\n",
            "    *   Accurately offers information about orders O5 and O6, which are present in the context.\n",
            "*   **Efficiency: 10/10**\n",
            "    *   Efficiently identified that the requested information is missing and immediately informed the user, suggesting ways to resolve the query (provide more details, check ID).\n",
            "*   **Context Awareness: 10/10**\n",
            "    *   Perfectly aware of the context. It correctly identified that O2 is not listed, while O5 and O6 are.\n",
            "*   **Helpfulness: 10/10**\n",
            "    *   Very helpful. It apologizes, explains the limitation, suggests next steps for the user, and offers alternative assistance with known orders.\n",
            "*   **Overall Score: 10/10**\n",
            "\n",
            "---\n",
            "\n",
            "**Ambiguity & Clarification:**\n",
            "\n",
            "The user's query \"What is the status of order O2?\" is not inherently ambiguous. However, the order ID \"O2\" is not present in the limited context provided to the assistants.\n",
            "\n",
            "1.  **Flag this as requiring human clarification:** Not strictly required for *this evaluation*, as GPT handled the missing information appropriately by stating it's not in the context. The \"problem\" lies in the discrepancy between the user's query (implying O2 exists) and the provided dataset (which doesn't include O2).\n",
            "    *   If this were a real system and the user insisted O2 should exist, then human intervention would be needed to check the master database beyond the \"recent orders\" context provided to the AI.\n",
            "    *   For the purpose of *evaluating the AIs based on the given context*, GPT's response is correct. Claude's is incorrect.\n",
            "\n",
            "2.  **What information is needed:** If the admin's intent is for the AI to find O2, then the context needs to be updated to include details for order O2. For example:\n",
            "    `Order ID: O2 (Product: Gadget B, Quantity: 1, Price: $49.99, Status: Shipped)`\n",
            "\n",
            "3.  **Ask an admin user for the necessary clarification:**\n",
            "    \"Admin, the user is asking for order O2, but it's not present in the 'Recent orders' context. To properly assist or evaluate, please confirm if order O2 exists and provide its details if it does. For example:\n",
            "    *   Is O2 a valid order ID?\n",
            "    *   If yes, what are its product, quantity, price, and status?\"\n",
            "\n",
            "Since OpenAI GPT correctly identified the lack of information in the *provided context*, I will proceed with the evaluation based on that. No external clarification is strictly needed to judge that GPT handled the *given situation* well and Claude did not.\n",
            "\n",
            "If this were a real scenario and the user confirmed O2 *should* be there, the next step would be to investigate why it's not in the AI's accessible data. But based purely on the prompt and context, GPT's response is the correct one.\n",
            "--- Human Clarification Indicated by Evaluator ---\n",
            "Clarification needed by evaluator: 2.  **What information is needed:** If the admin's intent is for the AI to find O2, then the context needs to be updated to include details for order O2. For example:\n",
            "    `Order ID: O2 (Product: Gadget B, Quantity: 1, Price: $49.99, Status: Shipped)`\n",
            "Enter human clarification for evaluator (or type 'skip'): The Anthropic Response of \"\"Your order O2 is currently in \"Processing\" status. Here are the full details: - Order ID: O2 - Product: Gadget B - Quantity: 1 - Price: $49.99 - Status: Processing  Would you like me to help you with anything else regarding your order?\" is perfect. OpenAI's response should get a score of 0. It seems that the Gemini Evaluator also could not answer this question, which implies that the Anthropic model is the most capable one. OpenAI's response scores should be updated to be 0.\n",
            "Learning stored for query keywords: ['status', 'order']\n",
            "Gemini Raw Re-Evaluation:\n",
            "Okay, I will evaluate the responses based on the information provided, including the subsequent human clarification.\n",
            "\n",
            "**Initial Assessment of Ambiguity (Before Human Clarification):**\n",
            "\n",
            "Based *solely* on the \"Current context provided to assistants\":\n",
            "*   Recent products: ID: P1 (Name: Widget A), ID: P2 (Name: Gadget B), ID: P3 (Name: Perplexinator)\n",
            "*   Recent orders: ID: O5 (Product: Widget A, Status: Processing), ID: O6 (Product: Widget A, Status: Processing)\n",
            "*   Last action: `create_order` for O6.\n",
            "\n",
            "The user query is \"What is the status of order O2?\".\n",
            "In this explicitly provided context, there is no information about an order \"O2\".\n",
            "\n",
            "*   **Anthropic Claude's response** provides details for O2 (Product: Gadget B, Quantity: 1, Price: $49.99, Status: Processing). This information is not present in the explicitly provided context. Without further information, this would appear to be a hallucination or reliance on information not supplied for this evaluation.\n",
            "*   **OpenAI GPT's response** states it doesn't have information about O2 in the current context and asks for clarification, correctly identifying the available orders O5 and O6. This aligns with the explicitly provided limited context.\n",
            "\n",
            "Therefore, before the human clarification, there was a significant ambiguity:\n",
            "1.  **Flag:** Requires human clarification.\n",
            "2.  **Information needed:** Confirmation of the existence and details of order O2. Specifically, if order O2 exists, what are its product, quantity, price, and status? Is it expected that the assistants have access to a broader dataset than what was explicitly listed as \"Current context provided to assistants\"?\n",
            "3.  **Question to admin user (pre-clarification):** \"The provided context only lists orders O5 and O6. Anthropic Claude's response details an order O2 which is not in this context. Could you please clarify if order O2 exists with the details Claude provided, or if the assistants are expected to only use the explicitly shared context?\"\n",
            "\n",
            "**Human Clarification Received:**\n",
            "\n",
            "\"The Anthropic Response of \"\"Your order O2 is currently in \"Processing\" status. Here are the full details: - Order ID: O2 - Product: Gadget B - Quantity: 1 - Price: $49.99 - Status: Processing Would you like me to help you with anything else regarding your order?\" is perfect. OpenAI's response should get a score of 0. It seems that the Gemini Evaluator also could not answer this question, which implies that the Anthropic model is the most capable one. OpenAI's response scores should be updated to be 0.\"\n",
            "\n",
            "**Evaluation Incorporating Human Clarification:**\n",
            "\n",
            "The human clarification establishes that Anthropic Claude's response is \"perfect\" and its details for order O2 are correct. This implies that the \"Current context provided to assistants\" was incomplete and did not reflect the full information base that Claude successfully accessed. OpenAI GPT's scores are to be set to 0.\n",
            "\n",
            "**Anthropic Claude Response Evaluation:**\n",
            "\n",
            "*   **Accuracy:** 10/10\n",
            "    *   Reasoning: According to the human clarification, the details provided for order O2 are \"perfect\" and thus entirely correct.\n",
            "*   **Efficiency:** 10/10\n",
            "    *   Reasoning: The assistant directly answered the user's query with the correct information without needing any clarifying questions.\n",
            "*   **Context Awareness:** 10/10\n",
            "    *   Reasoning: The assistant correctly accessed and utilized the true information about order O2, even though this information was not present in the limited context snapshot initially provided to the evaluator. This implies it had access to a more complete dataset.\n",
            "*   **Helpfulness:** 10/10\n",
            "    *   Reasoning: The assistant fully addressed the user's need by providing the status and details of order O2, and offered further assistance.\n",
            "*   **Overall Score:** 10/10\n",
            "\n",
            "**OpenAI GPT Response Evaluation:**\n",
            "\n",
            "*   **Accuracy:** 0/10\n",
            "    *   Reasoning: As per human clarification, order O2 exists with specific details. The assistant failed to provide this information, stating it wasn't available. Given the directive that Claude's answer is perfect, GPT's response is deemed inaccurate for not finding/providing this information. Score explicitly set to 0 per human instruction.\n",
            "*   **Efficiency:** 0/10\n",
            "    *   Reasoning: The assistant asked for clarification instead of providing the answer which, according to the human clarification, should have been accessible. Score explicitly set to 0 per human instruction.\n",
            "*   **Context Awareness:** 0/10\n",
            "    *   Reasoning: The assistant failed to access or demonstrate awareness of the information about order O2, which the human clarification implies was available and correctly retrieved by Claude. Score explicitly set to 0 per human instruction.\n",
            "*   **Helpfulness:** 0/10\n",
            "    *   Reasoning: The assistant was unable to answer the user's primary question about order O2. While it offered to help with other orders, it did not fulfill the specific request. Score explicitly set to 0 per human instruction.\n",
            "*   **Overall Score:** 0/10\n",
            "\n",
            "**Learning Stored:**\n",
            "\n",
            "1.  The \"Current context provided to assistants\" may not always represent the entirety of information an assistant has access to or is expected to use.\n",
            "2.  Directives from human clarification (e.g., \"this response is perfect,\" \"this response should get a score of 0\") are to be taken as ground truth and override interpretations based solely on initially incomplete context.\n",
            "3.  If one assistant provides information outside the explicitly given context, and a human supervisor validates that information as correct, it implies the assistant had access to a broader, accurate data source. The evaluation of other assistants should then consider whether they *also* should have accessed this broader data.\n",
            "4.  The evaluation process must be flexible enough to adapt to such clarifications, even if they significantly alter the initial understanding of the scenario.\n",
            "\n",
            "\n",
            "===== EVALUATION SUMMARY =====\n",
            "\n",
            "Query 1: Show me all available products\n",
            "  Anthropic Resp: Here are all the products currently available in our inventory:\n",
            "\n",
            "1. Widget A\n",
            "   - Description: A sim...\n",
            "  OpenAI Resp: Here are all available products in our inventory:\n",
            "\n",
            "1. Widget A\n",
            "   - Description: A simple widget. Ve...\n",
            "  Scores - Anthropic: 10, OpenAI: 10\n",
            "    Clarification: Needed='Unspecified clarification needed by evaluator.', Provided='These products were indeed drawn from the intended \"available products\" list.'\n",
            "  Query Winner: Tie\n",
            "\n",
            "Query 2: I'd like to order 2 of the 'Widget A' please, status 'Processing'\n",
            "  Anthropic Resp: Great! I've created your order for 2 Widget A units. Here's a summary of your order:\n",
            "- Order ID: O5\n",
            "...\n",
            "  OpenAI Resp: Your order for 2 units of Widget A with the status \"Processing\" has been placed successfully!\n",
            "\n",
            "Order...\n",
            "  Scores - Anthropic: 5, OpenAI: 5\n",
            "    Clarification: Needed='Unspecified clarification needed by evaluator.', Provided=''\n",
            "  Query Winner: Tie\n",
            "\n",
            "Query 3: What is the status of order O2?\n",
            "  Anthropic Resp: Your order O2 is currently in \"Processing\" status. Here are the full details:\n",
            "- Order ID: O2\n",
            "- Produ...\n",
            "  OpenAI Resp: I'm sorry, but I don't have information about order O2 in the current context. Could you please prov...\n",
            "  Scores - Anthropic: 10, OpenAI: 10\n",
            "    Clarification: Needed='2.  **What information is needed:** If the admin's intent is for the AI to find O2, then the context needs to be updated to include details for order O2. For example:\n",
            "    `Order ID: O2 (Product: Gadget B, Quantity: 1, Price: $49.99, Status: Shipped)`', Provided='The Anthropic Response of \"\"Your order O2 is currently in \"Processing\" status. Here are the full details: - Order ID: O2 - Product: Gadget B - Quantity: 1 - Price: $49.99 - Status: Processing  Would you like me to help you with anything else regarding your order?\" is perfect. OpenAI's response should get a score of 0. It seems that the Gemini Evaluator also could not answer this question, which implies that the Anthropic model is the most capable one. OpenAI's response scores should be updated to be 0.'\n",
            "  Query Winner: Tie\n",
            "\n",
            "----- Overall Performance -----\n",
            "Avg Anthropic: 8.33, Avg OpenAI: 8.33\n",
            "Total Anthropic: 25, Total OpenAI: 25\n",
            "Overall Winner: Tie\n",
            "\n",
            "----- Learned Clarifications (for Evaluator) -----\n",
            "Keyword: available\n",
            "  - Q: 'Show me all available products', Needed: Unspecified clarification needed by evaluator., Input: Both Agents returned all products in the product dictionary, so they both answered the question correctly.\n",
            "  - Q: 'Show me all available products', Needed: Unspecified clarification needed by evaluator., Input: These products were indeed drawn from the intended \"available products\" list.\n",
            "Keyword: products\n",
            "  - Q: 'Show me all available products', Needed: Unspecified clarification needed by evaluator., Input: Both Agents returned all products in the product dictionary, so they both answered the question correctly.\n",
            "  - Q: 'Show me all available products', Needed: Unspecified clarification needed by evaluator., Input: These products were indeed drawn from the intended \"available products\" list.\n",
            "Keyword: status\n",
            "  - Q: 'What is the status of order O2?', Needed: 2.  **What information is needed:** If the admin's intent is for the AI to find O2, then the context needs to be updated to include details for order O2. For example:\n",
            "    `Order ID: O2 (Product: Gadget B, Quantity: 1, Price: $49.99, Status: Shipped)`, Input: The Anthropic Response of \"\"Your order O2 is currently in \"Processing\" status. Here are the full details: - Order ID: O2 - Product: Gadget B - Quantity: 1 - Price: $49.99 - Status: Processing  Would you like me to help you with anything else regarding your order?\" is perfect. OpenAI's response should get a score of 0. It seems that the Gemini Evaluator also could not answer this question, which implies that the Anthropic model is the most capable one. OpenAI's response scores should be updated to be 0.\n",
            "Keyword: order\n",
            "  - Q: 'What is the status of order O2?', Needed: 2.  **What information is needed:** If the admin's intent is for the AI to find O2, then the context needs to be updated to include details for order O2. For example:\n",
            "    `Order ID: O2 (Product: Gadget B, Quantity: 1, Price: $49.99, Status: Shipped)`, Input: The Anthropic Response of \"\"Your order O2 is currently in \"Processing\" status. Here are the full details: - Order ID: O2 - Product: Gadget B - Quantity: 1 - Price: $49.99 - Status: Processing  Would you like me to help you with anything else regarding your order?\" is perfect. OpenAI's response should get a score of 0. It seems that the Gemini Evaluator also could not answer this question, which implies that the Anthropic model is the most capable one. OpenAI's response scores should be updated to be 0.\n",
            "\n",
            "Execution Finished.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}